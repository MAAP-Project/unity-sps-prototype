2022-03-21T09:49:18.407-0700 [INFO]  Terraform version: 1.1.7
2022-03-21T09:49:18.407-0700 [INFO]  Go runtime version: go1.17.2
2022-03-21T09:49:18.407-0700 [INFO]  CLI args: []string{"/usr/local/Cellar/tfenv/2.2.3/versions/1.1.7/terraform", "apply", "-no-color"}
2022-03-21T09:49:18.409-0700 [INFO]  CLI command args: []string{"apply", "-no-color"}
2022-03-21T09:49:19.144-0700 [INFO]  backend/local: starting Apply operation
2022-03-21T09:49:19.158-0700 [INFO]  provider: configuring client automatic mTLS
2022-03-21T09:49:19.220-0700 [INFO]  provider.terraform-provider-helm_v2.4.1_x5: configuring server automatic mTLS: timestamp=2022-03-21T09:49:19.220-0700
2022-03-21T09:49:19.337-0700 [INFO]  provider: configuring client automatic mTLS
2022-03-21T09:49:19.441-0700 [INFO]  provider.terraform-provider-kubernetes_v2.8.0_x5: configuring server automatic mTLS: timestamp=2022-03-21T09:49:19.441-0700
2022-03-21T09:49:19.626-0700 [INFO]  ReferenceTransformer: reference not found: "path.module"
2022-03-21T09:49:19.631-0700 [INFO]  ReferenceTransformer: reference not found: "path.module"
2022-03-21T09:49:19.631-0700 [INFO]  ReferenceTransformer: reference not found: "path.module"
2022-03-21T09:49:19.631-0700 [INFO]  ReferenceTransformer: reference not found: "path.module"
2022-03-21T09:49:19.631-0700 [INFO]  ReferenceTransformer: reference not found: "path.module"
2022-03-21T09:49:19.631-0700 [INFO]  ReferenceTransformer: reference not found: "path.module"
2022-03-21T09:49:19.631-0700 [INFO]  ReferenceTransformer: reference not found: "path.module"
2022-03-21T09:49:19.631-0700 [INFO]  ReferenceTransformer: reference not found: "path.module"
2022-03-21T09:49:19.631-0700 [INFO]  ReferenceTransformer: reference not found: "path.module"
2022-03-21T09:49:19.632-0700 [INFO]  ReferenceTransformer: reference not found: "path.module"
2022-03-21T09:49:19.632-0700 [INFO]  ReferenceTransformer: reference not found: "path.module"
2022-03-21T09:49:19.632-0700 [INFO]  ReferenceTransformer: reference not found: "path.module"
2022-03-21T09:49:19.632-0700 [INFO]  ReferenceTransformer: reference not found: "path.module"
2022-03-21T09:49:19.632-0700 [INFO]  ReferenceTransformer: reference not found: "path.module"
2022-03-21T09:49:19.632-0700 [INFO]  ReferenceTransformer: reference not found: "path.module"
2022-03-21T09:49:19.632-0700 [INFO]  ReferenceTransformer: reference not found: "path.module"
2022-03-21T09:49:19.633-0700 [INFO]  ReferenceTransformer: reference not found: "path.module"
2022-03-21T09:49:19.639-0700 [INFO]  provider: configuring client automatic mTLS
2022-03-21T09:49:19.705-0700 [INFO]  provider.terraform-provider-helm_v2.4.1_x5: configuring server automatic mTLS: timestamp=2022-03-21T09:49:19.704-0700
2022-03-21T09:49:19.805-0700 [INFO]  provider: configuring client automatic mTLS
2022-03-21T09:49:19.905-0700 [INFO]  provider.terraform-provider-kubernetes_v2.8.0_x5: configuring server automatic mTLS: timestamp=2022-03-21T09:49:19.905-0700
2022-03-21T09:49:20.155-0700 [INFO]  backend/local: apply calling Plan
2022-03-21T09:49:20.158-0700 [INFO]  ReferenceTransformer: reference not found: "path.module"
2022-03-21T09:49:20.158-0700 [INFO]  ReferenceTransformer: reference not found: "path.module"
2022-03-21T09:49:20.158-0700 [INFO]  ReferenceTransformer: reference not found: "path.module"
2022-03-21T09:49:20.159-0700 [INFO]  ReferenceTransformer: reference not found: "path.module"
2022-03-21T09:49:20.160-0700 [INFO]  ReferenceTransformer: reference not found: "path.module"
2022-03-21T09:49:20.160-0700 [INFO]  ReferenceTransformer: reference not found: "path.module"
2022-03-21T09:49:20.161-0700 [INFO]  ReferenceTransformer: reference not found: "path.module"
2022-03-21T09:49:20.161-0700 [INFO]  ReferenceTransformer: reference not found: "path.module"
2022-03-21T09:49:20.162-0700 [INFO]  ReferenceTransformer: reference not found: "path.module"
2022-03-21T09:49:20.162-0700 [INFO]  ReferenceTransformer: reference not found: "path.module"
2022-03-21T09:49:20.164-0700 [INFO]  ReferenceTransformer: reference not found: "path.module"
2022-03-21T09:49:20.164-0700 [INFO]  ReferenceTransformer: reference not found: "path.module"
2022-03-21T09:49:20.164-0700 [INFO]  ReferenceTransformer: reference not found: "path.module"
2022-03-21T09:49:20.164-0700 [INFO]  ReferenceTransformer: reference not found: "path.module"
2022-03-21T09:49:20.164-0700 [INFO]  ReferenceTransformer: reference not found: "path.module"
2022-03-21T09:49:20.166-0700 [INFO]  ReferenceTransformer: reference not found: "path.module"
2022-03-21T09:49:20.166-0700 [INFO]  ReferenceTransformer: reference not found: "path.module"
2022-03-21T09:49:20.170-0700 [INFO]  provider: configuring client automatic mTLS
2022-03-21T09:49:20.241-0700 [INFO]  provider.terraform-provider-kubernetes_v2.8.0_x5: configuring server automatic mTLS: timestamp=2022-03-21T09:49:20.241-0700
2022-03-21T09:49:20.312-0700 [INFO]  provider: configuring client automatic mTLS
2022-03-21T09:49:20.379-0700 [INFO]  provider.terraform-provider-helm_v2.4.1_x5: configuring server automatic mTLS: timestamp=2022-03-21T09:49:20.379-0700
2022-03-21T09:49:20.471-0700 [WARN]  ValidateProviderConfig from "provider[\"registry.terraform.io/hashicorp/helm\"]" changed the config value, but that value is unused
2022-03-21T09:49:20.472-0700 [INFO]  provider.terraform-provider-helm_v2.4.1_x5: 2022/03/21 09:49:20 [DEBUG] Experiments enabled: []: timestamp=2022-03-21T09:49:20.472-0700
2022-03-21T09:49:20.473-0700 [INFO]  ReferenceTransformer: reference not found: "path.module"
2022-03-21T09:49:20.474-0700 [INFO]  ReferenceTransformer: reference not found: "path.module"
2022-03-21T09:49:20.481-0700 [INFO]  provider.terraform-provider-helm_v2.4.1_x5: 2022/03/21 09:49:20 [DEBUG] [resourceDiff: grq2-es] Start: timestamp=2022-03-21T09:49:20.480-0700
2022-03-21T09:49:20.482-0700 [INFO]  provider.terraform-provider-helm_v2.4.1_x5: 2022/03/21 09:49:20 [DEBUG] [resourceDiff: mozart-es] Start: timestamp=2022-03-21T09:49:20.481-0700
2022-03-21T09:49:20.484-0700 [WARN]  ValidateProviderConfig from "provider[\"registry.terraform.io/hashicorp/kubernetes\"]" changed the config value, but that value is unused
2022-03-21T09:49:20.489-0700 [INFO]  ReferenceTransformer: reference not found: "path.module"
2022-03-21T09:49:20.490-0700 [INFO]  ReferenceTransformer: reference not found: "path.module"
2022-03-21T09:49:20.492-0700 [INFO]  ReferenceTransformer: reference not found: "path.module"
2022-03-21T09:49:20.496-0700 [WARN]  Provider "registry.terraform.io/hashicorp/kubernetes" produced an invalid plan for kubernetes_config_map.supervisord-user-rules, but we are tolerating it because it is using the legacy plugin SDK.
    The following problems may be the cause of any confusing errors from downstream operations:
      - .metadata[0].namespace: planned value cty.StringVal("default") for a non-computed attribute
2022-03-21T09:49:20.501-0700 [INFO]  ReferenceTransformer: reference not found: "path.module"
2022-03-21T09:49:20.505-0700 [INFO]  ReferenceTransformer: reference not found: "path.module"
2022-03-21T09:49:20.505-0700 [INFO]  ReferenceTransformer: reference not found: "path.module"
2022-03-21T09:49:20.505-0700 [INFO]  ReferenceTransformer: reference not found: "path.module"
2022-03-21T09:49:20.505-0700 [INFO]  ReferenceTransformer: reference not found: "path.module"
2022-03-21T09:49:20.505-0700 [INFO]  ReferenceTransformer: reference not found: "path.module"
2022-03-21T09:49:20.505-0700 [INFO]  ReferenceTransformer: reference not found: "path.module"
2022-03-21T09:49:20.507-0700 [INFO]  ReferenceTransformer: reference not found: "path.module"
2022-03-21T09:49:20.508-0700 [INFO]  ReferenceTransformer: reference not found: "path.module"
2022-03-21T09:49:20.515-0700 [WARN]  Provider "registry.terraform.io/hashicorp/kubernetes" produced an invalid plan for kubernetes_config_map.grq2-settings, but we are tolerating it because it is using the legacy plugin SDK.
    The following problems may be the cause of any confusing errors from downstream operations:
      - .metadata[0].namespace: planned value cty.StringVal("default") for a non-computed attribute
2022-03-21T09:49:20.524-0700 [WARN]  Provider "registry.terraform.io/hashicorp/kubernetes" produced an invalid plan for kubernetes_config_map.aws-credentials, but we are tolerating it because it is using the legacy plugin SDK.
    The following problems may be the cause of any confusing errors from downstream operations:
      - .metadata[0].namespace: planned value cty.StringVal("default") for a non-computed attribute
2022-03-21T09:49:20.527-0700 [INFO]  ReferenceTransformer: reference not found: "path.module"
2022-03-21T09:49:20.530-0700 [INFO]  ReferenceTransformer: reference not found: "path.module"
2022-03-21T09:49:20.530-0700 [INFO]  ReferenceTransformer: reference not found: "path.module"
2022-03-21T09:49:20.568-0700 [WARN]  Provider "registry.terraform.io/hashicorp/kubernetes" produced an invalid plan for kubernetes_deployment.mozart, but we are tolerating it because it is using the legacy plugin SDK.
    The following problems may be the cause of any confusing errors from downstream operations:
      - .wait_for_rollout: planned value cty.True for a non-computed attribute
      - .metadata[0].namespace: planned value cty.StringVal("default") for a non-computed attribute
      - .spec[0].min_ready_seconds: planned value cty.NumberIntVal(0) for a non-computed attribute
      - .spec[0].paused: planned value cty.False for a non-computed attribute
      - .spec[0].progress_deadline_seconds: planned value cty.NumberIntVal(600) for a non-computed attribute
      - .spec[0].revision_history_limit: planned value cty.NumberIntVal(10) for a non-computed attribute
      - .spec[0].strategy: attribute representing nested block must not be unknown itself; set nested attribute values to unknown instead
      - .spec[0].template[0].spec[0].enable_service_links: planned value cty.True for a non-computed attribute
      - .spec[0].template[0].spec[0].host_ipc: planned value cty.False for a non-computed attribute
      - .spec[0].template[0].spec[0].host_pid: planned value cty.False for a non-computed attribute
      - .spec[0].template[0].spec[0].restart_policy: planned value cty.StringVal("Always") for a non-computed attribute
      - .spec[0].template[0].spec[0].share_process_namespace: planned value cty.False for a non-computed attribute
      - .spec[0].template[0].spec[0].dns_policy: planned value cty.StringVal("ClusterFirst") for a non-computed attribute
      - .spec[0].template[0].spec[0].automount_service_account_token: planned value cty.True for a non-computed attribute
      - .spec[0].template[0].spec[0].host_network: planned value cty.False for a non-computed attribute
      - .spec[0].template[0].spec[0].termination_grace_period_seconds: planned value cty.NumberIntVal(30) for a non-computed attribute
      - .spec[0].template[0].spec[0].container[0].stdin_once: planned value cty.False for a non-computed attribute
      - .spec[0].template[0].spec[0].container[0].termination_message_path: planned value cty.StringVal("/dev/termination-log") for a non-computed attribute
      - .spec[0].template[0].spec[0].container[0].tty: planned value cty.False for a non-computed attribute
      - .spec[0].template[0].spec[0].container[0].stdin: planned value cty.False for a non-computed attribute
      - .spec[0].template[0].spec[0].container[0].resources: attribute representing nested block must not be unknown itself; set nested attribute values to unknown instead
      - .spec[0].template[0].spec[0].container[0].port[0].protocol: planned value cty.StringVal("TCP") for a non-computed attribute
      - .spec[0].template[0].spec[0].container[0].volume_mount[0].mount_propagation: planned value cty.StringVal("None") for a non-computed attribute
      - .spec[0].template[0].spec[0].container[0].volume_mount[1].mount_propagation: planned value cty.StringVal("None") for a non-computed attribute
      - .spec[0].template[0].spec[0].container[0].volume_mount[2].mount_propagation: planned value cty.StringVal("None") for a non-computed attribute
      - .spec[0].template[0].spec[0].image_pull_secrets: attribute representing nested block must not be unknown itself; set nested attribute values to unknown instead
      - .spec[0].template[0].spec[0].readiness_gate: attribute representing nested block must not be unknown itself; set nested attribute values to unknown instead
      - .spec[0].template[0].spec[0].volume[0].config_map[0].default_mode: planned value cty.StringVal("0644") for a non-computed attribute
      - .spec[0].template[0].spec[0].volume[1].config_map[0].default_mode: planned value cty.StringVal("0644") for a non-computed attribute
      - .spec[0].template[0].spec[0].volume[2].config_map[0].default_mode: planned value cty.StringVal("0644") for a non-computed attribute
2022-03-21T09:49:20.574-0700 [WARN]  Provider "registry.terraform.io/hashicorp/kubernetes" produced an invalid plan for kubernetes_deployment.hysds-ui, but we are tolerating it because it is using the legacy plugin SDK.
    The following problems may be the cause of any confusing errors from downstream operations:
      - .wait_for_rollout: planned value cty.True for a non-computed attribute
      - .metadata[0].namespace: planned value cty.StringVal("default") for a non-computed attribute
      - .spec[0].revision_history_limit: planned value cty.NumberIntVal(10) for a non-computed attribute
      - .spec[0].min_ready_seconds: planned value cty.NumberIntVal(0) for a non-computed attribute
      - .spec[0].paused: planned value cty.False for a non-computed attribute
      - .spec[0].progress_deadline_seconds: planned value cty.NumberIntVal(600) for a non-computed attribute
      - .spec[0].strategy: attribute representing nested block must not be unknown itself; set nested attribute values to unknown instead
      - .spec[0].template[0].spec[0].dns_policy: planned value cty.StringVal("ClusterFirst") for a non-computed attribute
      - .spec[0].template[0].spec[0].automount_service_account_token: planned value cty.True for a non-computed attribute
      - .spec[0].template[0].spec[0].termination_grace_period_seconds: planned value cty.NumberIntVal(30) for a non-computed attribute
      - .spec[0].template[0].spec[0].host_network: planned value cty.False for a non-computed attribute
      - .spec[0].template[0].spec[0].host_ipc: planned value cty.False for a non-computed attribute
      - .spec[0].template[0].spec[0].host_pid: planned value cty.False for a non-computed attribute
      - .spec[0].template[0].spec[0].share_process_namespace: planned value cty.False for a non-computed attribute
      - .spec[0].template[0].spec[0].enable_service_links: planned value cty.True for a non-computed attribute
      - .spec[0].template[0].spec[0].volume: attribute representing nested block must not be unknown itself; set nested attribute values to unknown instead
      - .spec[0].template[0].spec[0].image_pull_secrets: attribute representing nested block must not be unknown itself; set nested attribute values to unknown instead
      - .spec[0].template[0].spec[0].readiness_gate: attribute representing nested block must not be unknown itself; set nested attribute values to unknown instead
      - .spec[0].template[0].spec[0].container[0].stdin: planned value cty.False for a non-computed attribute
      - .spec[0].template[0].spec[0].container[0].stdin_once: planned value cty.False for a non-computed attribute
      - .spec[0].template[0].spec[0].container[0].termination_message_path: planned value cty.StringVal("/dev/termination-log") for a non-computed attribute
      - .spec[0].template[0].spec[0].container[0].tty: planned value cty.False for a non-computed attribute
      - .spec[0].template[0].spec[0].container[0].port[0].protocol: planned value cty.StringVal("TCP") for a non-computed attribute
      - .spec[0].template[0].spec[0].container[0].resources: attribute representing nested block must not be unknown itself; set nested attribute values to unknown instead
2022-03-21T09:49:20.576-0700 [WARN]  Provider "registry.terraform.io/hashicorp/kubernetes" produced an invalid plan for kubernetes_service.hysds-ui_service, but we are tolerating it because it is using the legacy plugin SDK.
    The following problems may be the cause of any confusing errors from downstream operations:
      - .wait_for_load_balancer: planned value cty.True for a non-computed attribute
      - .metadata[0].namespace: planned value cty.StringVal("default") for a non-computed attribute
      - .spec[0].publish_not_ready_addresses: planned value cty.False for a non-computed attribute
2022-03-21T09:49:20.581-0700 [WARN]  Provider "registry.terraform.io/hashicorp/kubernetes" produced an invalid plan for kubernetes_config_map.netrc, but we are tolerating it because it is using the legacy plugin SDK.
    The following problems may be the cause of any confusing errors from downstream operations:
      - .metadata[0].namespace: planned value cty.StringVal("default") for a non-computed attribute
2022-03-21T09:49:20.582-0700 [WARN]  Provider "registry.terraform.io/hashicorp/kubernetes" produced an invalid plan for kubernetes_service.redis_service, but we are tolerating it because it is using the legacy plugin SDK.
    The following problems may be the cause of any confusing errors from downstream operations:
      - .wait_for_load_balancer: planned value cty.True for a non-computed attribute
      - .metadata[0].namespace: planned value cty.StringVal("default") for a non-computed attribute
      - .spec[0].publish_not_ready_addresses: planned value cty.False for a non-computed attribute
      - .spec[0].port[0].protocol: planned value cty.StringVal("TCP") for a non-computed attribute
2022-03-21T09:49:20.583-0700 [WARN]  Provider "registry.terraform.io/hashicorp/kubernetes" produced an invalid plan for kubernetes_service.rabbitmq_service, but we are tolerating it because it is using the legacy plugin SDK.
    The following problems may be the cause of any confusing errors from downstream operations:
      - .wait_for_load_balancer: planned value cty.True for a non-computed attribute
      - .metadata[0].namespace: planned value cty.StringVal("default") for a non-computed attribute
      - .spec[0].publish_not_ready_addresses: planned value cty.False for a non-computed attribute
2022-03-21T09:49:20.604-0700 [WARN]  Provider "registry.terraform.io/hashicorp/kubernetes" produced an invalid plan for kubernetes_persistent_volume_claim.minio-pv-claim, but we are tolerating it because it is using the legacy plugin SDK.
    The following problems may be the cause of any confusing errors from downstream operations:
      - .wait_until_bound: planned value cty.True for a non-computed attribute
      - .metadata[0].namespace: planned value cty.StringVal("default") for a non-computed attribute
2022-03-21T09:49:20.605-0700 [WARN]  Provider "registry.terraform.io/hashicorp/kubernetes" produced an invalid plan for kubernetes_service.rabbitmq_mgmt_service, but we are tolerating it because it is using the legacy plugin SDK.
    The following problems may be the cause of any confusing errors from downstream operations:
      - .wait_for_load_balancer: planned value cty.True for a non-computed attribute
      - .metadata[0].namespace: planned value cty.StringVal("default") for a non-computed attribute
      - .spec[0].publish_not_ready_addresses: planned value cty.False for a non-computed attribute
      - .spec[0].port[0].protocol: planned value cty.StringVal("TCP") for a non-computed attribute
2022-03-21T09:49:20.636-0700 [WARN]  Provider "registry.terraform.io/hashicorp/kubernetes" produced an invalid plan for kubernetes_service.grq2_service, but we are tolerating it because it is using the legacy plugin SDK.
    The following problems may be the cause of any confusing errors from downstream operations:
      - .wait_for_load_balancer: planned value cty.True for a non-computed attribute
      - .spec[0].publish_not_ready_addresses: planned value cty.False for a non-computed attribute
      - .spec[0].port[0].protocol: planned value cty.StringVal("TCP") for a non-computed attribute
      - .metadata[0].namespace: planned value cty.StringVal("default") for a non-computed attribute
2022-03-21T09:49:20.639-0700 [WARN]  Provider "registry.terraform.io/hashicorp/kubernetes" produced an invalid plan for kubernetes_deployment.orchestrator, but we are tolerating it because it is using the legacy plugin SDK.
    The following problems may be the cause of any confusing errors from downstream operations:
      - .wait_for_rollout: planned value cty.True for a non-computed attribute
      - .metadata[0].namespace: planned value cty.StringVal("default") for a non-computed attribute
      - .spec[0].min_ready_seconds: planned value cty.NumberIntVal(0) for a non-computed attribute
      - .spec[0].paused: planned value cty.False for a non-computed attribute
      - .spec[0].progress_deadline_seconds: planned value cty.NumberIntVal(600) for a non-computed attribute
      - .spec[0].revision_history_limit: planned value cty.NumberIntVal(10) for a non-computed attribute
      - .spec[0].strategy: attribute representing nested block must not be unknown itself; set nested attribute values to unknown instead
      - .spec[0].template[0].spec[0].share_process_namespace: planned value cty.False for a non-computed attribute
      - .spec[0].template[0].spec[0].enable_service_links: planned value cty.True for a non-computed attribute
      - .spec[0].template[0].spec[0].host_ipc: planned value cty.False for a non-computed attribute
      - .spec[0].template[0].spec[0].host_pid: planned value cty.False for a non-computed attribute
      - .spec[0].template[0].spec[0].restart_policy: planned value cty.StringVal("Always") for a non-computed attribute
      - .spec[0].template[0].spec[0].dns_policy: planned value cty.StringVal("ClusterFirst") for a non-computed attribute
      - .spec[0].template[0].spec[0].automount_service_account_token: planned value cty.True for a non-computed attribute
      - .spec[0].template[0].spec[0].host_network: planned value cty.False for a non-computed attribute
      - .spec[0].template[0].spec[0].termination_grace_period_seconds: planned value cty.NumberIntVal(30) for a non-computed attribute
      - .spec[0].template[0].spec[0].readiness_gate: attribute representing nested block must not be unknown itself; set nested attribute values to unknown instead
      - .spec[0].template[0].spec[0].volume[0].config_map[0].default_mode: planned value cty.StringVal("0644") for a non-computed attribute
      - .spec[0].template[0].spec[0].volume[1].config_map[0].default_mode: planned value cty.StringVal("0644") for a non-computed attribute
      - .spec[0].template[0].spec[0].image_pull_secrets: attribute representing nested block must not be unknown itself; set nested attribute values to unknown instead
      - .spec[0].template[0].spec[0].container[0].stdin: planned value cty.False for a non-computed attribute
      - .spec[0].template[0].spec[0].container[0].termination_message_path: planned value cty.StringVal("/dev/termination-log") for a non-computed attribute
      - .spec[0].template[0].spec[0].container[0].tty: planned value cty.False for a non-computed attribute
      - .spec[0].template[0].spec[0].container[0].stdin_once: planned value cty.False for a non-computed attribute
      - .spec[0].template[0].spec[0].container[0].resources: attribute representing nested block must not be unknown itself; set nested attribute values to unknown instead
      - .spec[0].template[0].spec[0].container[0].volume_mount[0].mount_propagation: planned value cty.StringVal("None") for a non-computed attribute
      - .spec[0].template[0].spec[0].container[0].volume_mount[1].mount_propagation: planned value cty.StringVal("None") for a non-computed attribute
      - .spec[0].template[0].spec[0].container[0].volume_mount[2].mount_propagation: planned value cty.StringVal("None") for a non-computed attribute
2022-03-21T09:49:20.661-0700 [WARN]  Provider "registry.terraform.io/hashicorp/kubernetes" produced an invalid plan for kubernetes_deployment.user-rules, but we are tolerating it because it is using the legacy plugin SDK.
    The following problems may be the cause of any confusing errors from downstream operations:
      - .wait_for_rollout: planned value cty.True for a non-computed attribute
      - .metadata[0].namespace: planned value cty.StringVal("default") for a non-computed attribute
      - .spec[0].min_ready_seconds: planned value cty.NumberIntVal(0) for a non-computed attribute
      - .spec[0].paused: planned value cty.False for a non-computed attribute
      - .spec[0].progress_deadline_seconds: planned value cty.NumberIntVal(600) for a non-computed attribute
      - .spec[0].revision_history_limit: planned value cty.NumberIntVal(10) for a non-computed attribute
      - .spec[0].strategy: attribute representing nested block must not be unknown itself; set nested attribute values to unknown instead
      - .spec[0].template[0].spec[0].restart_policy: planned value cty.StringVal("Always") for a non-computed attribute
      - .spec[0].template[0].spec[0].share_process_namespace: planned value cty.False for a non-computed attribute
      - .spec[0].template[0].spec[0].enable_service_links: planned value cty.True for a non-computed attribute
      - .spec[0].template[0].spec[0].host_ipc: planned value cty.False for a non-computed attribute
      - .spec[0].template[0].spec[0].host_pid: planned value cty.False for a non-computed attribute
      - .spec[0].template[0].spec[0].dns_policy: planned value cty.StringVal("ClusterFirst") for a non-computed attribute
      - .spec[0].template[0].spec[0].automount_service_account_token: planned value cty.True for a non-computed attribute
      - .spec[0].template[0].spec[0].host_network: planned value cty.False for a non-computed attribute
      - .spec[0].template[0].spec[0].termination_grace_period_seconds: planned value cty.NumberIntVal(30) for a non-computed attribute
      - .spec[0].template[0].spec[0].readiness_gate: attribute representing nested block must not be unknown itself; set nested attribute values to unknown instead
      - .spec[0].template[0].spec[0].volume[0].config_map[0].default_mode: planned value cty.StringVal("0644") for a non-computed attribute
      - .spec[0].template[0].spec[0].volume[1].config_map[0].default_mode: planned value cty.StringVal("0644") for a non-computed attribute
      - .spec[0].template[0].spec[0].image_pull_secrets: attribute representing nested block must not be unknown itself; set nested attribute values to unknown instead
      - .spec[0].template[0].spec[0].container[0].tty: planned value cty.False for a non-computed attribute
      - .spec[0].template[0].spec[0].container[0].stdin_once: planned value cty.False for a non-computed attribute
      - .spec[0].template[0].spec[0].container[0].termination_message_path: planned value cty.StringVal("/dev/termination-log") for a non-computed attribute
      - .spec[0].template[0].spec[0].container[0].stdin: planned value cty.False for a non-computed attribute
      - .spec[0].template[0].spec[0].container[0].resources: attribute representing nested block must not be unknown itself; set nested attribute values to unknown instead
      - .spec[0].template[0].spec[0].container[0].volume_mount[0].mount_propagation: planned value cty.StringVal("None") for a non-computed attribute
      - .spec[0].template[0].spec[0].container[0].volume_mount[1].mount_propagation: planned value cty.StringVal("None") for a non-computed attribute
      - .spec[0].template[0].spec[0].container[0].volume_mount[2].mount_propagation: planned value cty.StringVal("None") for a non-computed attribute
2022-03-21T09:49:20.673-0700 [WARN]  Provider "registry.terraform.io/hashicorp/kubernetes" produced an invalid plan for kubernetes_config_map.logstash-configs, but we are tolerating it because it is using the legacy plugin SDK.
    The following problems may be the cause of any confusing errors from downstream operations:
      - .metadata[0].namespace: planned value cty.StringVal("default") for a non-computed attribute
2022-03-21T09:49:20.678-0700 [WARN]  Provider "registry.terraform.io/hashicorp/kubernetes" produced an invalid plan for kubernetes_config_map.celeryconfig, but we are tolerating it because it is using the legacy plugin SDK.
    The following problems may be the cause of any confusing errors from downstream operations:
      - .metadata[0].namespace: planned value cty.StringVal("default") for a non-computed attribute
2022-03-21T09:49:20.698-0700 [WARN]  Provider "registry.terraform.io/hashicorp/kubernetes" produced an invalid plan for kubernetes_deployment.grq2, but we are tolerating it because it is using the legacy plugin SDK.
    The following problems may be the cause of any confusing errors from downstream operations:
      - .wait_for_rollout: planned value cty.True for a non-computed attribute
      - .metadata[0].namespace: planned value cty.StringVal("default") for a non-computed attribute
      - .spec[0].revision_history_limit: planned value cty.NumberIntVal(10) for a non-computed attribute
      - .spec[0].min_ready_seconds: planned value cty.NumberIntVal(0) for a non-computed attribute
      - .spec[0].paused: planned value cty.False for a non-computed attribute
      - .spec[0].progress_deadline_seconds: planned value cty.NumberIntVal(600) for a non-computed attribute
      - .spec[0].strategy: attribute representing nested block must not be unknown itself; set nested attribute values to unknown instead
      - .spec[0].template[0].spec[0].dns_policy: planned value cty.StringVal("ClusterFirst") for a non-computed attribute
      - .spec[0].template[0].spec[0].automount_service_account_token: planned value cty.True for a non-computed attribute
      - .spec[0].template[0].spec[0].host_network: planned value cty.False for a non-computed attribute
      - .spec[0].template[0].spec[0].termination_grace_period_seconds: planned value cty.NumberIntVal(30) for a non-computed attribute
      - .spec[0].template[0].spec[0].restart_policy: planned value cty.StringVal("Always") for a non-computed attribute
      - .spec[0].template[0].spec[0].share_process_namespace: planned value cty.False for a non-computed attribute
      - .spec[0].template[0].spec[0].enable_service_links: planned value cty.True for a non-computed attribute
      - .spec[0].template[0].spec[0].host_ipc: planned value cty.False for a non-computed attribute
      - .spec[0].template[0].spec[0].host_pid: planned value cty.False for a non-computed attribute
      - .spec[0].template[0].spec[0].volume[0].config_map[0].default_mode: planned value cty.StringVal("0644") for a non-computed attribute
      - .spec[0].template[0].spec[0].volume[1].config_map[0].default_mode: planned value cty.StringVal("0644") for a non-computed attribute
      - .spec[0].template[0].spec[0].volume[2].config_map[0].default_mode: planned value cty.StringVal("0644") for a non-computed attribute
      - .spec[0].template[0].spec[0].image_pull_secrets: attribute representing nested block must not be unknown itself; set nested attribute values to unknown instead
      - .spec[0].template[0].spec[0].readiness_gate: attribute representing nested block must not be unknown itself; set nested attribute values to unknown instead
      - .spec[0].template[0].spec[0].container[0].termination_message_path: planned value cty.StringVal("/dev/termination-log") for a non-computed attribute
      - .spec[0].template[0].spec[0].container[0].tty: planned value cty.False for a non-computed attribute
      - .spec[0].template[0].spec[0].container[0].stdin_once: planned value cty.False for a non-computed attribute
      - .spec[0].template[0].spec[0].container[0].stdin: planned value cty.False for a non-computed attribute
      - .spec[0].template[0].spec[0].container[0].resources: attribute representing nested block must not be unknown itself; set nested attribute values to unknown instead
      - .spec[0].template[0].spec[0].container[0].port[0].protocol: planned value cty.StringVal("TCP") for a non-computed attribute
      - .spec[0].template[0].spec[0].container[0].volume_mount[0].mount_propagation: planned value cty.StringVal("None") for a non-computed attribute
      - .spec[0].template[0].spec[0].container[0].volume_mount[1].mount_propagation: planned value cty.StringVal("None") for a non-computed attribute
      - .spec[0].template[0].spec[0].container[0].volume_mount[2].mount_propagation: planned value cty.StringVal("None") for a non-computed attribute
2022-03-21T09:49:20.701-0700 [WARN]  Provider "registry.terraform.io/hashicorp/kubernetes" produced an invalid plan for kubernetes_deployment.redis, but we are tolerating it because it is using the legacy plugin SDK.
    The following problems may be the cause of any confusing errors from downstream operations:
      - .wait_for_rollout: planned value cty.True for a non-computed attribute
      - .metadata[0].namespace: planned value cty.StringVal("default") for a non-computed attribute
      - .spec[0].min_ready_seconds: planned value cty.NumberIntVal(0) for a non-computed attribute
      - .spec[0].paused: planned value cty.False for a non-computed attribute
      - .spec[0].progress_deadline_seconds: planned value cty.NumberIntVal(600) for a non-computed attribute
      - .spec[0].revision_history_limit: planned value cty.NumberIntVal(10) for a non-computed attribute
      - .spec[0].strategy: attribute representing nested block must not be unknown itself; set nested attribute values to unknown instead
      - .spec[0].template[0].spec[0].host_network: planned value cty.False for a non-computed attribute
      - .spec[0].template[0].spec[0].termination_grace_period_seconds: planned value cty.NumberIntVal(30) for a non-computed attribute
      - .spec[0].template[0].spec[0].restart_policy: planned value cty.StringVal("Always") for a non-computed attribute
      - .spec[0].template[0].spec[0].share_process_namespace: planned value cty.False for a non-computed attribute
      - .spec[0].template[0].spec[0].enable_service_links: planned value cty.True for a non-computed attribute
      - .spec[0].template[0].spec[0].host_ipc: planned value cty.False for a non-computed attribute
      - .spec[0].template[0].spec[0].host_pid: planned value cty.False for a non-computed attribute
      - .spec[0].template[0].spec[0].dns_policy: planned value cty.StringVal("ClusterFirst") for a non-computed attribute
      - .spec[0].template[0].spec[0].automount_service_account_token: planned value cty.True for a non-computed attribute
      - .spec[0].template[0].spec[0].volume: attribute representing nested block must not be unknown itself; set nested attribute values to unknown instead
      - .spec[0].template[0].spec[0].image_pull_secrets: attribute representing nested block must not be unknown itself; set nested attribute values to unknown instead
      - .spec[0].template[0].spec[0].readiness_gate: attribute representing nested block must not be unknown itself; set nested attribute values to unknown instead
      - .spec[0].template[0].spec[0].container[0].stdin: planned value cty.False for a non-computed attribute
      - .spec[0].template[0].spec[0].container[0].termination_message_path: planned value cty.StringVal("/dev/termination-log") for a non-computed attribute
      - .spec[0].template[0].spec[0].container[0].tty: planned value cty.False for a non-computed attribute
      - .spec[0].template[0].spec[0].container[0].stdin_once: planned value cty.False for a non-computed attribute
      - .spec[0].template[0].spec[0].container[0].port[0].protocol: planned value cty.StringVal("TCP") for a non-computed attribute
      - .spec[0].template[0].spec[0].container[0].resources: attribute representing nested block must not be unknown itself; set nested attribute values to unknown instead
2022-03-21T09:49:20.718-0700 [WARN]  Provider "registry.terraform.io/hashicorp/kubernetes" produced an invalid plan for kubernetes_service.mozart_service, but we are tolerating it because it is using the legacy plugin SDK.
    The following problems may be the cause of any confusing errors from downstream operations:
      - .wait_for_load_balancer: planned value cty.True for a non-computed attribute
      - .metadata[0].namespace: planned value cty.StringVal("default") for a non-computed attribute
      - .spec[0].publish_not_ready_addresses: planned value cty.False for a non-computed attribute
      - .spec[0].port[0].protocol: planned value cty.StringVal("TCP") for a non-computed attribute
2022-03-21T09:49:20.720-0700 [WARN]  Provider "registry.terraform.io/hashicorp/kubernetes" produced an invalid plan for kubernetes_config_map.supervisord-job-worker, but we are tolerating it because it is using the legacy plugin SDK.
    The following problems may be the cause of any confusing errors from downstream operations:
      - .metadata[0].namespace: planned value cty.StringVal("default") for a non-computed attribute
2022-03-21T09:49:20.723-0700 [WARN]  Provider "registry.terraform.io/hashicorp/kubernetes" produced an invalid plan for kubernetes_config_map.datasets, but we are tolerating it because it is using the legacy plugin SDK.
    The following problems may be the cause of any confusing errors from downstream operations:
      - .metadata[0].namespace: planned value cty.StringVal("default") for a non-computed attribute
2022-03-21T09:49:20.724-0700 [WARN]  Provider "registry.terraform.io/hashicorp/kubernetes" produced an invalid plan for kubernetes_service.minio_service, but we are tolerating it because it is using the legacy plugin SDK.
    The following problems may be the cause of any confusing errors from downstream operations:
      - .wait_for_load_balancer: planned value cty.True for a non-computed attribute
      - .metadata[0].namespace: planned value cty.StringVal("default") for a non-computed attribute
      - .spec[0].publish_not_ready_addresses: planned value cty.False for a non-computed attribute
2022-03-21T09:49:20.728-0700 [WARN]  Provider "registry.terraform.io/hashicorp/kubernetes" produced an invalid plan for kubernetes_config_map.mozart-settings, but we are tolerating it because it is using the legacy plugin SDK.
    The following problems may be the cause of any confusing errors from downstream operations:
      - .metadata[0].namespace: planned value cty.StringVal("default") for a non-computed attribute
2022-03-21T09:49:20.732-0700 [WARN]  Provider "registry.terraform.io/hashicorp/kubernetes" produced an invalid plan for kubernetes_config_map.supervisord-orchestrator, but we are tolerating it because it is using the legacy plugin SDK.
    The following problems may be the cause of any confusing errors from downstream operations:
      - .metadata[0].namespace: planned value cty.StringVal("default") for a non-computed attribute
2022-03-21T09:49:20.736-0700 [WARN]  Provider "registry.terraform.io/hashicorp/kubernetes" produced an invalid plan for kubernetes_deployment.minio, but we are tolerating it because it is using the legacy plugin SDK.
    The following problems may be the cause of any confusing errors from downstream operations:
      - .wait_for_rollout: planned value cty.True for a non-computed attribute
      - .metadata[0].namespace: planned value cty.StringVal("default") for a non-computed attribute
      - .spec[0].min_ready_seconds: planned value cty.NumberIntVal(0) for a non-computed attribute
      - .spec[0].paused: planned value cty.False for a non-computed attribute
      - .spec[0].progress_deadline_seconds: planned value cty.NumberIntVal(600) for a non-computed attribute
      - .spec[0].revision_history_limit: planned value cty.NumberIntVal(10) for a non-computed attribute
      - .spec[0].strategy[0].rolling_update: attribute representing nested block must not be unknown itself; set nested attribute values to unknown instead
      - .spec[0].template[0].spec[0].automount_service_account_token: planned value cty.True for a non-computed attribute
      - .spec[0].template[0].spec[0].host_network: planned value cty.False for a non-computed attribute
      - .spec[0].template[0].spec[0].termination_grace_period_seconds: planned value cty.NumberIntVal(30) for a non-computed attribute
      - .spec[0].template[0].spec[0].enable_service_links: planned value cty.True for a non-computed attribute
      - .spec[0].template[0].spec[0].host_ipc: planned value cty.False for a non-computed attribute
      - .spec[0].template[0].spec[0].host_pid: planned value cty.False for a non-computed attribute
      - .spec[0].template[0].spec[0].restart_policy: planned value cty.StringVal("Always") for a non-computed attribute
      - .spec[0].template[0].spec[0].share_process_namespace: planned value cty.False for a non-computed attribute
      - .spec[0].template[0].spec[0].dns_policy: planned value cty.StringVal("ClusterFirst") for a non-computed attribute
      - .spec[0].template[0].spec[0].image_pull_secrets: attribute representing nested block must not be unknown itself; set nested attribute values to unknown instead
      - .spec[0].template[0].spec[0].readiness_gate: attribute representing nested block must not be unknown itself; set nested attribute values to unknown instead
      - .spec[0].template[0].spec[0].volume[0].persistent_volume_claim[0].read_only: planned value cty.False for a non-computed attribute
      - .spec[0].template[0].spec[0].container[0].stdin: planned value cty.False for a non-computed attribute
      - .spec[0].template[0].spec[0].container[0].stdin_once: planned value cty.False for a non-computed attribute
      - .spec[0].template[0].spec[0].container[0].termination_message_path: planned value cty.StringVal("/dev/termination-log") for a non-computed attribute
      - .spec[0].template[0].spec[0].container[0].tty: planned value cty.False for a non-computed attribute
      - .spec[0].template[0].spec[0].container[0].volume_mount[0].mount_propagation: planned value cty.StringVal("None") for a non-computed attribute
      - .spec[0].template[0].spec[0].container[0].port[0].protocol: planned value cty.StringVal("TCP") for a non-computed attribute
      - .spec[0].template[0].spec[0].container[0].port[1].protocol: planned value cty.StringVal("TCP") for a non-computed attribute
      - .spec[0].template[0].spec[0].container[0].resources: attribute representing nested block must not be unknown itself; set nested attribute values to unknown instead
2022-03-21T09:49:20.747-0700 [WARN]  Provider "registry.terraform.io/hashicorp/kubernetes" produced an invalid plan for kubernetes_stateful_set.rabbitmq_statefulset, but we are tolerating it because it is using the legacy plugin SDK.
    The following problems may be the cause of any confusing errors from downstream operations:
      - .wait_for_rollout: planned value cty.True for a non-computed attribute
      - .metadata[0].namespace: planned value cty.StringVal("default") for a non-computed attribute
      - .spec[0].template[0].spec[0].restart_policy: planned value cty.StringVal("Always") for a non-computed attribute
      - .spec[0].template[0].spec[0].share_process_namespace: planned value cty.False for a non-computed attribute
      - .spec[0].template[0].spec[0].termination_grace_period_seconds: planned value cty.NumberIntVal(30) for a non-computed attribute
      - .spec[0].template[0].spec[0].enable_service_links: planned value cty.True for a non-computed attribute
      - .spec[0].template[0].spec[0].host_network: planned value cty.False for a non-computed attribute
      - .spec[0].template[0].spec[0].host_pid: planned value cty.False for a non-computed attribute
      - .spec[0].template[0].spec[0].automount_service_account_token: planned value cty.True for a non-computed attribute
      - .spec[0].template[0].spec[0].dns_policy: planned value cty.StringVal("ClusterFirst") for a non-computed attribute
      - .spec[0].template[0].spec[0].host_ipc: planned value cty.False for a non-computed attribute
      - .spec[0].template[0].spec[0].image_pull_secrets: attribute representing nested block must not be unknown itself; set nested attribute values to unknown instead
      - .spec[0].template[0].spec[0].container[0].stdin: planned value cty.False for a non-computed attribute
      - .spec[0].template[0].spec[0].container[0].termination_message_path: planned value cty.StringVal("/dev/termination-log") for a non-computed attribute
      - .spec[0].template[0].spec[0].container[0].stdin_once: planned value cty.False for a non-computed attribute
      - .spec[0].template[0].spec[0].container[0].tty: planned value cty.False for a non-computed attribute
      - .spec[0].template[0].spec[0].container[0].resources: attribute representing nested block must not be unknown itself; set nested attribute values to unknown instead
      - .spec[0].template[0].spec[0].container[0].volume_mount[0].mount_propagation: planned value cty.StringVal("None") for a non-computed attribute
      - .spec[0].template[0].spec[0].container[0].volume_mount[0].read_only: planned value cty.False for a non-computed attribute
      - .spec[0].template[0].spec[0].readiness_gate: attribute representing nested block must not be unknown itself; set nested attribute values to unknown instead
2022-03-21T09:49:20.765-0700 [WARN]  Provider "registry.terraform.io/hashicorp/kubernetes" produced an invalid plan for kubernetes_deployment.logstash, but we are tolerating it because it is using the legacy plugin SDK.
    The following problems may be the cause of any confusing errors from downstream operations:
      - .wait_for_rollout: planned value cty.True for a non-computed attribute
      - .spec[0].min_ready_seconds: planned value cty.NumberIntVal(0) for a non-computed attribute
      - .spec[0].paused: planned value cty.False for a non-computed attribute
      - .spec[0].progress_deadline_seconds: planned value cty.NumberIntVal(600) for a non-computed attribute
      - .spec[0].revision_history_limit: planned value cty.NumberIntVal(10) for a non-computed attribute
      - .spec[0].strategy: attribute representing nested block must not be unknown itself; set nested attribute values to unknown instead
      - .spec[0].template[0].spec[0].dns_policy: planned value cty.StringVal("ClusterFirst") for a non-computed attribute
      - .spec[0].template[0].spec[0].automount_service_account_token: planned value cty.True for a non-computed attribute
      - .spec[0].template[0].spec[0].host_network: planned value cty.False for a non-computed attribute
      - .spec[0].template[0].spec[0].termination_grace_period_seconds: planned value cty.NumberIntVal(30) for a non-computed attribute
      - .spec[0].template[0].spec[0].enable_service_links: planned value cty.True for a non-computed attribute
      - .spec[0].template[0].spec[0].host_ipc: planned value cty.False for a non-computed attribute
      - .spec[0].template[0].spec[0].host_pid: planned value cty.False for a non-computed attribute
      - .spec[0].template[0].spec[0].restart_policy: planned value cty.StringVal("Always") for a non-computed attribute
      - .spec[0].template[0].spec[0].share_process_namespace: planned value cty.False for a non-computed attribute
      - .spec[0].template[0].spec[0].container[0].tty: planned value cty.False for a non-computed attribute
      - .spec[0].template[0].spec[0].container[0].stdin_once: planned value cty.False for a non-computed attribute
      - .spec[0].template[0].spec[0].container[0].termination_message_path: planned value cty.StringVal("/dev/termination-log") for a non-computed attribute
      - .spec[0].template[0].spec[0].container[0].stdin: planned value cty.False for a non-computed attribute
      - .spec[0].template[0].spec[0].container[0].resources: attribute representing nested block must not be unknown itself; set nested attribute values to unknown instead
      - .spec[0].template[0].spec[0].container[0].port[0].protocol: planned value cty.StringVal("TCP") for a non-computed attribute
      - .spec[0].template[0].spec[0].container[0].volume_mount[0].mount_propagation: planned value cty.StringVal("None") for a non-computed attribute
      - .spec[0].template[0].spec[0].container[0].volume_mount[1].mount_propagation: planned value cty.StringVal("None") for a non-computed attribute
      - .spec[0].template[0].spec[0].container[0].volume_mount[2].mount_propagation: planned value cty.StringVal("None") for a non-computed attribute
      - .spec[0].template[0].spec[0].container[0].volume_mount[3].mount_propagation: planned value cty.StringVal("None") for a non-computed attribute
      - .spec[0].template[0].spec[0].container[0].volume_mount[4].mount_propagation: planned value cty.StringVal("None") for a non-computed attribute
      - .spec[0].template[0].spec[0].container[0].volume_mount[5].mount_propagation: planned value cty.StringVal("None") for a non-computed attribute
      - .spec[0].template[0].spec[0].readiness_gate: attribute representing nested block must not be unknown itself; set nested attribute values to unknown instead
      - .spec[0].template[0].spec[0].volume[0].config_map[0].default_mode: planned value cty.StringVal("0644") for a non-computed attribute
      - .spec[0].template[0].spec[0].volume[1].config_map[0].default_mode: planned value cty.StringVal("0644") for a non-computed attribute
      - .spec[0].template[0].spec[0].volume[2].config_map[0].default_mode: planned value cty.StringVal("0644") for a non-computed attribute
      - .spec[0].template[0].spec[0].volume[3].config_map[0].default_mode: planned value cty.StringVal("0644") for a non-computed attribute
      - .spec[0].template[0].spec[0].volume[4].config_map[0].default_mode: planned value cty.StringVal("0644") for a non-computed attribute
      - .spec[0].template[0].spec[0].volume[5].config_map[0].default_mode: planned value cty.StringVal("0644") for a non-computed attribute
      - .spec[0].template[0].spec[0].image_pull_secrets: attribute representing nested block must not be unknown itself; set nested attribute values to unknown instead
      - .metadata[0].namespace: planned value cty.StringVal("default") for a non-computed attribute
2022-03-21T09:49:20.804-0700 [WARN]  Provider "registry.terraform.io/hashicorp/kubernetes" produced an invalid plan for kubernetes_deployment.factotum-job-worker, but we are tolerating it because it is using the legacy plugin SDK.
    The following problems may be the cause of any confusing errors from downstream operations:
      - .wait_for_rollout: planned value cty.True for a non-computed attribute
      - .metadata[0].namespace: planned value cty.StringVal("default") for a non-computed attribute
      - .spec[0].min_ready_seconds: planned value cty.NumberIntVal(0) for a non-computed attribute
      - .spec[0].paused: planned value cty.False for a non-computed attribute
      - .spec[0].progress_deadline_seconds: planned value cty.NumberIntVal(600) for a non-computed attribute
      - .spec[0].revision_history_limit: planned value cty.NumberIntVal(10) for a non-computed attribute
      - .spec[0].strategy: attribute representing nested block must not be unknown itself; set nested attribute values to unknown instead
      - .spec[0].template[0].spec[0].host_network: planned value cty.False for a non-computed attribute
      - .spec[0].template[0].spec[0].termination_grace_period_seconds: planned value cty.NumberIntVal(30) for a non-computed attribute
      - .spec[0].template[0].spec[0].share_process_namespace: planned value cty.False for a non-computed attribute
      - .spec[0].template[0].spec[0].enable_service_links: planned value cty.True for a non-computed attribute
      - .spec[0].template[0].spec[0].host_ipc: planned value cty.False for a non-computed attribute
      - .spec[0].template[0].spec[0].host_pid: planned value cty.False for a non-computed attribute
      - .spec[0].template[0].spec[0].restart_policy: planned value cty.StringVal("Always") for a non-computed attribute
      - .spec[0].template[0].spec[0].dns_policy: planned value cty.StringVal("ClusterFirst") for a non-computed attribute
      - .spec[0].template[0].spec[0].automount_service_account_token: planned value cty.True for a non-computed attribute
      - .spec[0].template[0].spec[0].container[0].stdin: planned value cty.False for a non-computed attribute
      - .spec[0].template[0].spec[0].container[0].stdin_once: planned value cty.False for a non-computed attribute
      - .spec[0].template[0].spec[0].container[0].termination_message_path: planned value cty.StringVal("/dev/termination-log") for a non-computed attribute
      - .spec[0].template[0].spec[0].container[0].tty: planned value cty.False for a non-computed attribute
      - .spec[0].template[0].spec[0].container[0].resources: attribute representing nested block must not be unknown itself; set nested attribute values to unknown instead
      - .spec[0].template[0].spec[0].container[0].volume_mount[0].mount_propagation: planned value cty.StringVal("None") for a non-computed attribute
      - .spec[0].template[0].spec[0].container[0].volume_mount[1].mount_propagation: planned value cty.StringVal("None") for a non-computed attribute
      - .spec[0].template[0].spec[0].container[0].volume_mount[2].mount_propagation: planned value cty.StringVal("None") for a non-computed attribute
      - .spec[0].template[0].spec[0].container[0].volume_mount[3].mount_propagation: planned value cty.StringVal("None") for a non-computed attribute
      - .spec[0].template[0].spec[0].container[0].volume_mount[4].mount_propagation: planned value cty.StringVal("None") for a non-computed attribute
      - .spec[0].template[0].spec[0].container[0].volume_mount[5].mount_propagation: planned value cty.StringVal("None") for a non-computed attribute
      - .spec[0].template[0].spec[0].readiness_gate: attribute representing nested block must not be unknown itself; set nested attribute values to unknown instead
      - .spec[0].template[0].spec[0].volume[1].config_map[0].default_mode: planned value cty.StringVal("0644") for a non-computed attribute
      - .spec[0].template[0].spec[0].volume[2].config_map[0].default_mode: planned value cty.StringVal("0644") for a non-computed attribute
      - .spec[0].template[0].spec[0].volume[3].config_map[0].default_mode: planned value cty.StringVal("0644") for a non-computed attribute
      - .spec[0].template[0].spec[0].volume[4].config_map[0].default_mode: planned value cty.StringVal("0644") for a non-computed attribute
      - .spec[0].template[0].spec[0].image_pull_secrets: attribute representing nested block must not be unknown itself; set nested attribute values to unknown instead
      - .spec[0].template[0].spec[0].init_container[0].termination_message_path: planned value cty.StringVal("/dev/termination-log") for a non-computed attribute
      - .spec[0].template[0].spec[0].init_container[0].stdin: planned value cty.False for a non-computed attribute
      - .spec[0].template[0].spec[0].init_container[0].stdin_once: planned value cty.False for a non-computed attribute
      - .spec[0].template[0].spec[0].init_container[0].tty: planned value cty.False for a non-computed attribute
      - .spec[0].template[0].spec[0].init_container[0].volume_mount[0].read_only: planned value cty.False for a non-computed attribute
      - .spec[0].template[0].spec[0].init_container[0].volume_mount[0].mount_propagation: planned value cty.StringVal("None") for a non-computed attribute
      - .spec[0].template[0].spec[0].init_container[0].volume_mount[1].read_only: planned value cty.False for a non-computed attribute
      - .spec[0].template[0].spec[0].init_container[0].volume_mount[1].mount_propagation: planned value cty.StringVal("None") for a non-computed attribute
      - .spec[0].template[0].spec[0].init_container[0].resources: attribute representing nested block must not be unknown itself; set nested attribute values to unknown instead
2022-03-21T09:49:21.515-0700 [INFO]  provider.terraform-provider-helm_v2.4.1_x5: 2022/03/21 09:49:21 [DEBUG] [resourceDiff: grq2-es] Got chart: timestamp=2022-03-21T09:49:21.515-0700
2022-03-21T09:49:21.515-0700 [INFO]  provider.terraform-provider-helm_v2.4.1_x5: 2022/03/21 09:49:21 [DEBUG] [resourceDiff: grq2-es] Release validated: timestamp=2022-03-21T09:49:21.515-0700
2022-03-21T09:49:21.515-0700 [INFO]  provider.terraform-provider-helm_v2.4.1_x5: 2022/03/21 09:49:21 [DEBUG] [resourceDiff: grq2-es] Done: timestamp=2022-03-21T09:49:21.515-0700
2022-03-21T09:49:21.517-0700 [WARN]  Provider "registry.terraform.io/hashicorp/helm" produced an invalid plan for helm_release.grq2-es, but we are tolerating it because it is using the legacy plugin SDK.
    The following problems may be the cause of any confusing errors from downstream operations:
      - .wait_for_jobs: planned value cty.False for a non-computed attribute
      - .lint: planned value cty.False for a non-computed attribute
      - .namespace: planned value cty.StringVal("default") for a non-computed attribute
      - .force_update: planned value cty.False for a non-computed attribute
      - .atomic: planned value cty.False for a non-computed attribute
      - .render_subchart_notes: planned value cty.True for a non-computed attribute
      - .recreate_pods: planned value cty.False for a non-computed attribute
      - .dependency_update: planned value cty.False for a non-computed attribute
      - .replace: planned value cty.False for a non-computed attribute
      - .disable_webhooks: planned value cty.False for a non-computed attribute
      - .max_history: planned value cty.NumberIntVal(0) for a non-computed attribute
      - .disable_crd_hooks: planned value cty.False for a non-computed attribute
      - .reuse_values: planned value cty.False for a non-computed attribute
      - .skip_crds: planned value cty.False for a non-computed attribute
      - .cleanup_on_fail: planned value cty.False for a non-computed attribute
      - .disable_openapi_validation: planned value cty.False for a non-computed attribute
      - .reset_values: planned value cty.False for a non-computed attribute
      - .verify: planned value cty.False for a non-computed attribute
      - .create_namespace: planned value cty.False for a non-computed attribute
2022-03-21T09:49:21.952-0700 [INFO]  provider.terraform-provider-helm_v2.4.1_x5: 2022/03/21 09:49:21 [DEBUG] [resourceDiff: mozart-es] Got chart: timestamp=2022-03-21T09:49:21.952-0700
2022-03-21T09:49:21.952-0700 [INFO]  provider.terraform-provider-helm_v2.4.1_x5: 2022/03/21 09:49:21 [DEBUG] [resourceDiff: mozart-es] Release validated: timestamp=2022-03-21T09:49:21.952-0700
2022-03-21T09:49:21.952-0700 [INFO]  provider.terraform-provider-helm_v2.4.1_x5: 2022/03/21 09:49:21 [DEBUG] [resourceDiff: mozart-es] Done: timestamp=2022-03-21T09:49:21.952-0700
2022-03-21T09:49:21.955-0700 [WARN]  Provider "registry.terraform.io/hashicorp/helm" produced an invalid plan for helm_release.mozart-es, but we are tolerating it because it is using the legacy plugin SDK.
    The following problems may be the cause of any confusing errors from downstream operations:
      - .cleanup_on_fail: planned value cty.False for a non-computed attribute
      - .disable_crd_hooks: planned value cty.False for a non-computed attribute
      - .reuse_values: planned value cty.False for a non-computed attribute
      - .skip_crds: planned value cty.False for a non-computed attribute
      - .verify: planned value cty.False for a non-computed attribute
      - .create_namespace: planned value cty.False for a non-computed attribute
      - .disable_openapi_validation: planned value cty.False for a non-computed attribute
      - .reset_values: planned value cty.False for a non-computed attribute
      - .lint: planned value cty.False for a non-computed attribute
      - .namespace: planned value cty.StringVal("default") for a non-computed attribute
      - .wait_for_jobs: planned value cty.False for a non-computed attribute
      - .force_update: planned value cty.False for a non-computed attribute
      - .atomic: planned value cty.False for a non-computed attribute
      - .render_subchart_notes: planned value cty.True for a non-computed attribute
      - .dependency_update: planned value cty.False for a non-computed attribute
      - .recreate_pods: planned value cty.False for a non-computed attribute
      - .disable_webhooks: planned value cty.False for a non-computed attribute
      - .max_history: planned value cty.NumberIntVal(0) for a non-computed attribute
      - .replace: planned value cty.False for a non-computed attribute

Terraform used the selected providers to generate the following execution
plan. Resource actions are indicated with the following symbols:
  + create

Terraform will perform the following actions:

  # helm_release.grq2-es will be created
  + resource "helm_release" "grq2-es" {
      + atomic                     = false
      + chart                      = "elasticsearch"
      + cleanup_on_fail            = false
      + create_namespace           = false
      + dependency_update          = false
      + disable_crd_hooks          = false
      + disable_openapi_validation = false
      + disable_webhooks           = false
      + force_update               = false
      + id                         = (known after apply)
      + lint                       = false
      + manifest                   = (known after apply)
      + max_history                = 0
      + metadata                   = (known after apply)
      + name                       = "grq2-es"
      + namespace                  = "default"
      + recreate_pods              = false
      + render_subchart_notes      = true
      + replace                    = false
      + repository                 = "https://helm.elastic.co"
      + reset_values               = false
      + reuse_values               = false
      + skip_crds                  = false
      + status                     = "deployed"
      + timeout                    = 150
      + values                     = [
          + <<-EOT
                ---
                clusterName: "grq-es"

                # Permit co-located instances for solitary minikube virtual machines.
                antiAffinity: "soft"

                # Shrink default JVM heap.
                esJavaOpts: "-Xmx512m -Xms512m"

                # Allocate smaller chunks of memory per pod.
                resources:
                  requests:
                    cpu: "1000m"
                    memory: "2Gi"
                  limits:
                    cpu: "1000m"
                    memory: "2Gi"

                # Request smaller persistent volumes.
                volumeClaimTemplate:
                  accessModes: ["ReadWriteOnce"]
                  storageClassName: "hostpath"
                  resources:
                    requests:
                      storage: 5Gi

                # elasticsearch:
                masterService: "grq-es"

                # because we're using 1 node the cluster health will be YELLOW instead of GREEN after data is ingested
                clusterHealthCheckParams: "wait_for_status=yellow&timeout=1s"

                replicas: 1

                service:
                  type: "LoadBalancer"

                httpPort: 9201
                transportPort: 9301

                esConfig:
                  elasticsearch.yml: |
                    http.cors.enabled : true
                    http.cors.allow-origin: "*"
                    http.port: 9201

                lifecycle:
                  postStart:
                    exec:
                      command:
                        - bash
                        - -c
                        - |
                          #!/bin/bash
                          ES_URL=http://localhost:9201
                          while [[ "$(curl -s -o /dev/null -w '%{http_code}\n' $ES_URL)" != "200" ]]; do sleep 1; done

                          grq_es_template=$(curl -s https://raw.githubusercontent.com/hysds/grq2/develop/config/es_template.json)
                          template=$(echo ${grq_es_template} | sed 's/{{ prefix }}/grq/;s/{{ alias }}/grq/')
                          curl -X PUT "$ES_URL/_template/grq" -H 'Content-Type: application/json' -d "${template}"

                          ingest_pipeline=$(curl -s https://raw.githubusercontent.com/hysds/grq2/develop/config/ingest_pipeline.json)
                          curl -X PUT "$ES_URL/_ingest/pipeline/dataset_pipeline" -H 'Content-Type: application/json' -d "${ingest_pipeline}"
            EOT,
        ]
      + verify                     = false
      + version                    = "7.9.3"
      + wait                       = true
      + wait_for_jobs              = false
    }

  # helm_release.mozart-es will be created
  + resource "helm_release" "mozart-es" {
      + atomic                     = false
      + chart                      = "elasticsearch"
      + cleanup_on_fail            = false
      + create_namespace           = false
      + dependency_update          = false
      + disable_crd_hooks          = false
      + disable_openapi_validation = false
      + disable_webhooks           = false
      + force_update               = false
      + id                         = (known after apply)
      + lint                       = false
      + manifest                   = (known after apply)
      + max_history                = 0
      + metadata                   = (known after apply)
      + name                       = "mozart-es"
      + namespace                  = "default"
      + recreate_pods              = false
      + render_subchart_notes      = true
      + replace                    = false
      + repository                 = "https://helm.elastic.co"
      + reset_values               = false
      + reuse_values               = false
      + skip_crds                  = false
      + status                     = "deployed"
      + timeout                    = 150
      + values                     = [
          + <<-EOT
                ---
                clusterName: "mozart-es"

                # Permit co-located instances for solitary minikube virtual machines.
                antiAffinity: "soft"

                # Shrink default JVM heap.
                esJavaOpts: "-Xmx512m -Xms512m"

                # Allocate smaller chunks of memory per pod.
                resources:
                  requests:
                    cpu: "1000m"
                    memory: "2Gi"
                  limits:
                    cpu: "1000m"
                    memory: "2Gi"

                # Request smaller persistent volumes.
                volumeClaimTemplate:
                  accessModes: ["ReadWriteOnce"]
                  storageClassName: "hostpath"
                  resources:
                    requests:
                      storage: 5Gi

                # elasticsearch:
                masterService: "mozart-es"

                # because we're using 1 node the cluster health will be YELLOW instead of GREEN after data is ingested
                clusterHealthCheckParams: "wait_for_status=yellow&timeout=1s"

                replicas: 1

                service:
                  type: "LoadBalancer"

                httpPort: 9200
                transportPort: 9300

                esConfig:
                  elasticsearch.yml: |
                    http.cors.enabled : true
                    http.cors.allow-origin: "*"

                lifecycle:
                  postStart:
                    exec:
                      command:
                        - bash
                        - -c
                        - |
                          #!/bin/bash
                          ES_URL=http://localhost:9200
                          while [[ "$(curl -s -o /dev/null -w '%{http_code}\n' $ES_URL)" != "200" ]]; do sleep 1; done
                          mozart_es_template=$(curl -s https://raw.githubusercontent.com/hysds/mozart/develop/configs/es_template.json)
                          for idx in "containers" "job_specs" "hysds_io"; do
                            template=$(echo ${mozart_es_template} | sed "s/{{ index }}/${idx}/")
                            curl -X PUT "$ES_URL/_template/${idx}" -H 'Content-Type: application/json' -d "${template}" >/dev/null
                          done

                          hysds_io_mozart=$(curl -s https://raw.githubusercontent.com/hysds/mozart/develop/configs/hysds_ios.mapping)
                          curl -X PUT "$ES_URL/_template/hysds_ios-mozart?pretty" -H 'Content-Type: application/json' -d '${hysds_io_mozart}'

                          user_rules_mozart=$(curl -s https://raw.githubusercontent.com/hysds/mozart/develop/configs/user_rules_job.mapping)
                          curl -X PUT "$ES_URL/user_rules-mozart?pretty" -H 'Content-Type: application/json' -d "${user_rules_mozart}"

                          hysds_io_grq=$(curl -s https://raw.githubusercontent.com/hysds/grq2/develop/config/hysds_ios.mapping)
                          curl -X PUT "$ES_URL/hysds_ios-grq?pretty"  -H 'Content-Type: application/json' -d "${hysds_io_grq}"

                          user_rules_grq=$(curl -s https://raw.githubusercontent.com/hysds/grq2/develop/config/user_rules_dataset.mapping)
                          curl -X PUT "$ES_URL/user_rules-grq?pretty" -H 'Content-Type: application/json' -d "${user_rules_grq}"
            EOT,
        ]
      + verify                     = false
      + version                    = "7.9.3"
      + wait                       = true
      + wait_for_jobs              = false
    }

  # kubernetes_config_map.aws-credentials will be created
  + resource "kubernetes_config_map" "aws-credentials" {
      + data = {
          + "aws-credentials" = <<-EOT
                [default]
                aws_access_key_id = hysds
                aws_secret_access_key = password
            EOT
        }
      + id   = (known after apply)

      + metadata {
          + generation       = (known after apply)
          + name             = "aws-credentials"
          + namespace        = "default"
          + resource_version = (known after apply)
          + uid              = (known after apply)
        }
    }

  # kubernetes_config_map.celeryconfig will be created
  + resource "kubernetes_config_map" "celeryconfig" {
      + data = {
          + "celeryconfig.py" = <<-EOT
                broker_url = "amqp://guest:guest@rabbitmq:5672//"
                result_backend = "redis://redis:6379"

                task_serializer = "msgpack"
                result_serializer = "msgpack"
                accept_content = ["msgpack"]

                task_acks_late = True
                result_expires = 86400
                worker_prefetch_multiplier = 1

                event_serializer = "msgpack"
                worker_send_task_events = True
                task_send_sent_event = True
                task_track_started = True

                task_queue_max_priority = 10

                task_reject_on_worker_lost = True

                broker_heartbeat = 120
                broker_heartbeat_checkrate = 2

                broker_pool_limit = None
                broker_transport_options = { "confirm_publish": True }

                imports = [
                    "hysds.task_worker",
                    "hysds.job_worker",
                    "hysds.orchestrator",
                ]

                CELERY_SEND_TASK_ERROR_EMAILS = False
                ADMINS = (
                    ('{{ ADMIN_NAME }}', '{{ ADMIN_EMAIL }}'),
                )
                SERVER_EMAIL = '{{ HOST_STRING }}'

                HYSDS_HANDLE_SIGNALS = False
                HYSDS_JOB_STATUS_EXPIRES = 86400

                BACKOFF_MAX_VALUE = 64
                BACKOFF_MAX_TRIES = 10

                HARD_TIME_LIMIT_GAP = 300

                PYMONITOREDRUNNER_CFG = {
                    "rabbitmq": {
                        "hostname": "{{ MOZART_RABBIT_PVT_IP }}",
                        "port": 5672,
                        "queue": "stdouterr"
                    },

                    "StreamObserverFileWriter": {
                        "stdout_filepath": "_stdout.txt",
                        "stderr_filepath": "_stderr.txt"
                    },

                    "StreamObserverMessenger": {
                        "send_interval": 1
                    }
                }

                MOZART_URL = "https://mozart:8888/mozart/"
                MOZART_REST_URL = "http://mozart:8888/api/v0.1"
                JOBS_ES_URL = "http://mozart-es:9200"
                JOBS_PROCESSED_QUEUE = "jobs_processed"
                USER_RULES_JOB_QUEUE = "user_rules_job"
                ON_DEMAND_JOB_QUEUE = "on_demand_job"
                USER_RULES_JOB_INDEX = "user_rules-mozart"
                STATUS_ALIAS = "job_status"

                TOSCA_URL = "https://{{ GRQ_PVT_IP }}/search/"
                GRQ_URL = "http://grq2:8878"
                GRQ_REST_URL = "http://grq2:8878/api/v0.1"
                GRQ_UPDATE_URL = "http://grq2:8878/api/v0.1/grq/dataset/index"


                GRQ_AWS_ES = False
                GRQ_ES_HOST = "grq-es"
                GRQ_ES_PORT = 9201
                GRQ_ES_PROTOCOL = "http"
                GRQ_ES_URL = '%s://%s:%d' % (GRQ_ES_PROTOCOL, GRQ_ES_HOST, GRQ_ES_PORT)


                DATASET_PROCESSED_QUEUE = "dataset_processed"
                USER_RULES_DATASET_QUEUE = "user_rules_dataset"
                ON_DEMAND_DATASET_QUEUE = "on_demand_dataset"
                USER_RULES_DATASET_INDEX = "user_rules-grq"
                DATASET_ALIAS = "grq"

                HYSDS_IOS_MOZART = "hysds_ios-mozart"
                HYSDS_IOS_GRQ = "hysds_ios-grq"

                USER_RULES_TRIGGER_QUEUE = "user_rules_trigger"

                PROCESS_EVENTS_TASKS_QUEUE = "process_events_tasks"

                METRICS_ES_URL = "http://{{ METRICS_ES_PVT_IP }}:9200"

                # REDIS_JOB_STATUS_URL = "redis://:{{ MOZART_REDIS_PASSWORD }}@{{ MOZART_REDIS_PVT_IP }}"
                REDIS_JOB_STATUS_URL = "redis://redis:6379"
                REDIS_JOB_STATUS_KEY = "logstash"
                REDIS_JOB_INFO_URL = "redis://redis:6379"
                REDIS_JOB_INFO_KEY = "logstash"
                REDIS_INSTANCE_METRICS_URL = "redis://:{{ METRICS_REDIS_PASSWORD }}@{{ METRICS_REDIS_PVT_IP }}"
                REDIS_INSTANCE_METRICS_KEY = "logstash"
                # REDIS_UNIX_DOMAIN_SOCKET = "unix://:{{ MOZART_REDIS_PASSWORD }}@/tmp/redis.sock"
                REDIS_UNIX_DOMAIN_SOCKET = "unix://:/tmp/redis.sock"

                WORKER_CONTIGUOUS_FAILURE_THRESHOLD = 10
                WORKER_CONTIGUOUS_FAILURE_TIME = 5.

                # ROOT_WORK_DIR = "/data/work"
                ROOT_WORK_DIR = "/private/tmp/data/work"
                WEBDAV_URL = None
                WEBDAV_PORT = 8085

                WORKER_MOUNT_BLACKLIST = [
                    "/dev",
                    "/etc",
                    "/lib",
                    "/proc",
                    "/usr",
                    "/var",
                ]

                CONTAINER_REGISTRY = "{{ CONTAINER_REGISTRY }}"

                AWS_REGION = "{{ AWS_REGION }}"
            EOT
        }
      + id   = (known after apply)

      + metadata {
          + generation       = (known after apply)
          + name             = "celeryconfig"
          + namespace        = "default"
          + resource_version = (known after apply)
          + uid              = (known after apply)
        }
    }

  # kubernetes_config_map.datasets will be created
  + resource "kubernetes_config_map" "datasets" {
      + data = {
          + "datasets.json" = jsonencode(
                {
                  + datasets = [
                      + {
                          + alt_match_pattern = null
                          + browse            = {
                              + location        = "s3://minio:9000/datasets/browse/{id}"
                              + s3-profile-name = "default"
                              + urls            = [
                                  + "http://localhost:9001/buckets/datasets/browse/products/{id}",
                                  + "s3://minio:9000/datasets/browse/{id}",
                                ]
                            }
                          + extractor         = null
                          + ipath             = "ariamh::data/area_of_interest"
                          + level             = "L0"
                          + match_pattern     = "/(?P<id>AOI_.+)$"
                          + publish           = {
                              + location        = "s3://minio:9000/datasets/products/{id}"
                              + s3-profile-name = "default"
                              + urls            = [
                                  + "http://localhost:9001/buckets/datasets/browse/products/{id}",
                                  + "s3://minio:9000/datasets/products/{id}",
                                ]
                            }
                          + type              = "area_of_interest"
                        },
                      + {
                          + alt_match_pattern = null
                          + browse            = {
                              + location        = "s3://minio:9000/datasets/browse/hello_world/{version}/{year}/{month}/{day}/{id}"
                              + s3-profile-name = "default"
                              + urls            = [
                                  + "http://localhost:9001/buckets/datasets/browse/products/hello_world/{version}/{year}/{month}/{day}/{id}",
                                  + "s3://minio:9000/datasets/browse/hello_world/{version}/{year}/{month}/{day}/{id}",
                                ]
                            }
                          + extractor         = null
                          + ipath             = "hysds::data/hello_world"
                          + level             = "NA"
                          + match_pattern     = "/(?P<id>hello_world-product-(?P<year>\\d{4})(?P<month>\\d{2})(?P<day>\\d{2})T.*)$"
                          + publish           = {
                              + location        = "s3://minio:9000/datasets/products/hello_world/{version}/{year}/{month}/{day}/{id}"
                              + s3-profile-name = "default"
                              + urls            = [
                                  + "http://localhost:9001/buckets/datasets/browse/products/hello_world/{version}/{year}/{month}/{day}/{id}",
                                  + "s3://minio:9000/datasets/products/hello_world/{version}/{year}/{month}/{day}/{id}",
                                ]
                            }
                          + type              = "hello_world"
                        },
                    ]
                }
            )
        }
      + id   = (known after apply)

      + metadata {
          + generation       = (known after apply)
          + name             = "datasets"
          + namespace        = "default"
          + resource_version = (known after apply)
          + uid              = (known after apply)
        }
    }

  # kubernetes_config_map.grq2-settings will be created
  + resource "kubernetes_config_map" "grq2-settings" {
      + data = {
          + "settings.cfg" = <<-EOT
                # ElasticSearch URL
                AWS_ES = False
                ES_PROTOCOL = "http"
                ES_HOST = "grq-es"
                ES_PORT = 9201
                # ES_URL = "{{ GRQ_ES_PROTOCOL or 'http' }}://{{ GRQ_ES_PVT_IP }}:{{ GRQ_ES_PORT or 9200}}"
                ES_URL = "http://grq-es:9201"

                # Mozart Elasticsearch URL
                MOZART_ES_URL = "http://mozart-es:9200"

                # alias to ElasticSearch GRQ index
                GRQ_INDEX = "grq"

                # ElasticSearch geonames index
                GEONAMES_INDEX = "geonames"

                # Redis URL
                REDIS_URL = "redis://redis:6379/0"

                # ES index for user rules (located in mozart's ES)
                USER_RULES_INDEX = "user_rules-grq"

                # ES index for hysds_ios and job_specs (located in mozart's ES)
                HYSDS_IOS_INDEX = "hysds_ios-grq"
                JOB_SPECS_INDEX = "job_specs"

                AWS_REGION = "{{ AWS_REGION }}"
            EOT
        }
      + id   = (known after apply)

      + metadata {
          + generation       = (known after apply)
          + name             = "grq2-settings"
          + namespace        = "default"
          + resource_version = (known after apply)
          + uid              = (known after apply)
        }
    }

  # kubernetes_config_map.logstash-configs will be created
  + resource "kubernetes_config_map" "logstash-configs" {
      + data = {
          + "event-status"  = jsonencode(
                {
                  + aliases        = {
                      + job_status = {}
                    }
                  + index_patterns = [
                      + "event_status*",
                    ]
                  + mappings       = {
                      + properties = {
                          + event       = {
                              + enabled = false
                              + type    = "object"
                            }
                          + hostname    = {
                              + copy_to      = [
                                  + "text_fields",
                                ]
                              + ignore_above = 256
                              + type         = "keyword"
                            }
                          + resource    = {
                              + copy_to      = [
                                  + "text_fields",
                                ]
                              + ignore_above = 256
                              + type         = "keyword"
                            }
                          + status      = {
                              + copy_to      = [
                                  + "text_fields",
                                ]
                              + ignore_above = 256
                              + type         = "keyword"
                            }
                          + tags        = {
                              + copy_to = [
                                  + "text_fields",
                                ]
                              + fields  = {
                                  + keyword = {
                                      + ignore_above = 256
                                      + type         = "keyword"
                                    }
                                }
                              + type    = "text"
                            }
                          + text_fields = {
                              + type = "text"
                            }
                          + timestamp   = {
                              + type = "date"
                            }
                          + type        = {
                              + copy_to      = [
                                  + "text_fields",
                                ]
                              + ignore_above = 256
                              + type         = "keyword"
                            }
                          + uuid        = {
                              + copy_to      = [
                                  + "text_fields",
                                ]
                              + ignore_above = 256
                              + type         = "keyword"
                            }
                        }
                    }
                  + settings       = {
                      + analysis               = {
                          + analyzer = {
                              + default = {
                                  + filter    = [
                                      + "lowercase",
                                      + "word_delimiter",
                                    ]
                                  + tokenizer = "keyword"
                                }
                            }
                        }
                      + index.refresh_interval = "5s"
                    }
                }
            )
          + "job-status"    = jsonencode(
                {
                  + aliases        = {
                      + job_status = {}
                    }
                  + index_patterns = [
                      + "job_status*",
                    ]
                  + mappings       = {
                      + properties = {
                          + celery_hostname  = {
                              + copy_to      = [
                                  + "text_fields",
                                ]
                              + ignore_above = 256
                              + type         = "keyword"
                            }
                          + celery_pid       = {
                              + type = "integer"
                            }
                          + celery_runtime   = {
                              + type = "double"
                            }
                          + celery_timestamp = {
                              + type = "date"
                            }
                          + context          = {
                              + enabled = false
                              + type    = "object"
                            }
                          + dedup            = {
                              + type = "boolean"
                            }
                          + dedup_job        = {
                              + copy_to      = [
                                  + "text_fields",
                                ]
                              + ignore_above = 256
                              + type         = "keyword"
                            }
                          + dedup_msg        = {
                              + copy_to = [
                                  + "text_fields",
                                ]
                              + type    = "text"
                            }
                          + error            = {
                              + copy_to = [
                                  + "text_fields",
                                ]
                              + fields  = {
                                  + keyword = {
                                      + ignore_above = 256
                                      + type         = "keyword"
                                    }
                                }
                              + type    = "text"
                            }
                          + job              = {
                              + properties = {
                                  + command              = {
                                      + enabled = false
                                      + type    = "object"
                                    }
                                  + container_image_name = {
                                      + copy_to      = [
                                          + "text_fields",
                                        ]
                                      + ignore_above = 256
                                      + type         = "keyword"
                                    }
                                  + container_image_url  = {
                                      + copy_to      = [
                                          + "text_fields",
                                        ]
                                      + ignore_above = 256
                                      + type         = "keyword"
                                    }
                                  + context              = {
                                      + enabled = false
                                      + type    = "object"
                                    }
                                  + delivery_info        = {
                                      + properties = {
                                          + exchange    = {
                                              + copy_to      = [
                                                  + "text_fields",
                                                ]
                                              + ignore_above = 256
                                              + type         = "keyword"
                                            }
                                          + priority    = {
                                              + type = "integer"
                                            }
                                          + redelivered = {
                                              + type = "boolean"
                                            }
                                          + routing_key = {
                                              + copy_to      = [
                                                  + "text_fields",
                                                ]
                                              + ignore_above = 256
                                              + type         = "keyword"
                                            }
                                        }
                                    }
                                  + job_hash             = {
                                      + copy_to      = [
                                          + "text_fields",
                                        ]
                                      + ignore_above = 256
                                      + type         = "keyword"
                                    }
                                  + job_id               = {
                                      + copy_to      = [
                                          + "text_fields",
                                        ]
                                      + ignore_above = 256
                                      + type         = "keyword"
                                    }
                                  + job_info             = {
                                      + properties = {
                                          + cmd_duration        = {
                                              + type = "double"
                                            }
                                          + cmd_end             = {
                                              + type = "date"
                                            }
                                          + cmd_start           = {
                                              + type = "date"
                                            }
                                          + completed_queue     = {
                                              + copy_to      = [
                                                  + "text_fields",
                                                ]
                                              + ignore_above = 256
                                              + type         = "keyword"
                                            }
                                          + context             = {
                                              + enabled = false
                                              + type    = "object"
                                            }
                                          + dedup               = {
                                              + type = "boolean"
                                            }
                                          + dedup_job           = {
                                              + copy_to      = [
                                                  + "text_fields",
                                                ]
                                              + ignore_above = 256
                                              + type         = "keyword"
                                            }
                                          + duration            = {
                                              + type = "double"
                                            }
                                          + error_queue         = {
                                              + copy_to      = [
                                                  + "text_fields",
                                                ]
                                              + ignore_above = 256
                                              + type         = "keyword"
                                            }
                                          + execute_node        = {
                                              + copy_to      = [
                                                  + "text_fields",
                                                ]
                                              + ignore_above = 256
                                              + type         = "keyword"
                                            }
                                          + facts               = {
                                              + properties = {
                                                  + architecture                    = {
                                                      + copy_to      = [
                                                          + "text_fields",
                                                        ]
                                                      + ignore_above = 256
                                                      + type         = "keyword"
                                                    }
                                                  + ec2_ami_id                      = {
                                                      + copy_to      = [
                                                          + "text_fields",
                                                        ]
                                                      + ignore_above = 256
                                                      + type         = "keyword"
                                                    }
                                                  + ec2_instance_type               = {
                                                      + copy_to      = [
                                                          + "text_fields",
                                                        ]
                                                      + ignore_above = 256
                                                      + type         = "keyword"
                                                    }
                                                  + ec2_placement_availability_zone = {
                                                      + copy_to      = [
                                                          + "text_fields",
                                                        ]
                                                      + ignore_above = 256
                                                      + type         = "keyword"
                                                    }
                                                  + is_virtual                      = {
                                                      + copy_to      = [
                                                          + "text_fields",
                                                        ]
                                                      + ignore_above = 256
                                                      + type         = "keyword"
                                                    }
                                                  + memorytotal                     = {
                                                      + copy_to      = [
                                                          + "text_fields",
                                                        ]
                                                      + ignore_above = 256
                                                      + type         = "keyword"
                                                    }
                                                  + physicalprocessorcount          = {
                                                      + copy_to      = [
                                                          + "text_fields",
                                                        ]
                                                      + ignore_above = 256
                                                      + type         = "keyword"
                                                    }
                                                  + processorcount                  = {
                                                      + copy_to      = [
                                                          + "text_fields",
                                                        ]
                                                      + ignore_above = 256
                                                      + type         = "keyword"
                                                    }
                                                  + swapsize                        = {
                                                      + copy_to      = [
                                                          + "text_fields",
                                                        ]
                                                      + ignore_above = 256
                                                      + type         = "keyword"
                                                    }
                                                  + virtual                         = {
                                                      + copy_to      = [
                                                          + "text_fields",
                                                        ]
                                                      + ignore_above = 256
                                                      + type         = "keyword"
                                                    }
                                                }
                                            }
                                          + host                = {
                                              + copy_to      = [
                                                  + "text_fields",
                                                ]
                                              + ignore_above = 256
                                              + type         = "keyword"
                                            }
                                          + id                  = {
                                              + copy_to      = [
                                                  + "text_fields",
                                                ]
                                              + ignore_above = 256
                                              + type         = "keyword"
                                            }
                                          + job_dir             = {
                                              + copy_to      = [
                                                  + "text_fields",
                                                ]
                                              + ignore_above = 256
                                              + type         = "keyword"
                                            }
                                          + job_payload         = {
                                              + properties = {
                                                  + job_type        = {
                                                      + copy_to      = [
                                                          + "text_fields",
                                                        ]
                                                      + ignore_above = 256
                                                      + type         = "keyword"
                                                    }
                                                  + payload_task_id = {
                                                      + copy_to      = [
                                                          + "text_fields",
                                                        ]
                                                      + ignore_above = 256
                                                      + type         = "keyword"
                                                    }
                                                }
                                            }
                                          + job_queue           = {
                                              + copy_to      = [
                                                  + "text_fields",
                                                ]
                                              + ignore_above = 256
                                              + type         = "keyword"
                                            }
                                          + job_status_exchange = {
                                              + copy_to      = [
                                                  + "text_fields",
                                                ]
                                              + ignore_above = 256
                                              + type         = "keyword"
                                            }
                                          + job_url             = {
                                              + copy_to      = [
                                                  + "text_fields",
                                                ]
                                              + ignore_above = 256
                                              + type         = "keyword"
                                            }
                                          + metrics             = {
                                              + properties = {
                                                  + inputs_localized   = {
                                                      + properties = {
                                                          + disk_usage    = {
                                                              + copy_to      = [
                                                                  + "text_fields",
                                                                ]
                                                              + ignore_above = 256
                                                              + type         = "keyword"
                                                            }
                                                          + duration      = {
                                                              + type = "double"
                                                            }
                                                          + path          = {
                                                              + copy_to      = [
                                                                  + "text_fields",
                                                                ]
                                                              + ignore_above = 256
                                                              + type         = "keyword"
                                                            }
                                                          + time_end      = {
                                                              + type = "date"
                                                            }
                                                          + time_start    = {
                                                              + type = "date"
                                                            }
                                                          + transfer_rate = {
                                                              + type = "double"
                                                            }
                                                          + url           = {
                                                              + copy_to      = [
                                                                  + "text_fields",
                                                                ]
                                                              + ignore_above = 256
                                                              + type         = "keyword"
                                                            }
                                                        }
                                                    }
                                                  + job_dir_size       = {
                                                      + copy_to      = [
                                                          + "text_fields",
                                                        ]
                                                      + ignore_above = 256
                                                      + type         = "keyword"
                                                    }
                                                  + product_provenance = {
                                                      + properties = {
                                                          + access_latency         = {
                                                              + type = "double"
                                                            }
                                                          + acquisition_start_time = {
                                                              + type = "date"
                                                            }
                                                          + availability_time      = {
                                                              + type = "date"
                                                            }
                                                          + ground_system_latency  = {
                                                              + type = "double"
                                                            }
                                                          + location               = {
                                                              + strategy = "recursive"
                                                              + type     = "geo_shape"
                                                            }
                                                          + processing_latency     = {
                                                              + type = "double"
                                                            }
                                                          + processing_start_time  = {
                                                              + type = "date"
                                                            }
                                                          + product_type           = {
                                                              + copy_to      = [
                                                                  + "text_fields",
                                                                ]
                                                              + ignore_above = 256
                                                              + type         = "keyword"
                                                            }
                                                          + source_production_time = {
                                                              + type = "date"
                                                            }
                                                          + total_latency          = {
                                                              + type = "double"
                                                            }
                                                        }
                                                    }
                                                  + products_staged    = {
                                                      + properties = {
                                                          + browse_urls    = {
                                                              + copy_to      = [
                                                                  + "text_fields",
                                                                ]
                                                              + ignore_above = 256
                                                              + type         = "keyword"
                                                            }
                                                          + dataset        = {
                                                              + copy_to      = [
                                                                  + "text_fields",
                                                                ]
                                                              + ignore_above = 256
                                                              + type         = "keyword"
                                                            }
                                                          + dataset_level  = {
                                                              + copy_to      = [
                                                                  + "text_fields",
                                                                ]
                                                              + ignore_above = 256
                                                              + type         = "keyword"
                                                            }
                                                          + dataset_type   = {
                                                              + copy_to      = [
                                                                  + "text_fields",
                                                                ]
                                                              + ignore_above = 256
                                                              + type         = "keyword"
                                                            }
                                                          + disk_usage     = {
                                                              + copy_to      = [
                                                                  + "text_fields",
                                                                ]
                                                              + ignore_above = 256
                                                              + type         = "keyword"
                                                            }
                                                          + duration       = {
                                                              + type = "double"
                                                            }
                                                          + id             = {
                                                              + copy_to      = [
                                                                  + "text_fields",
                                                                ]
                                                              + ignore_above = 256
                                                              + type         = "keyword"
                                                            }
                                                          + ipath          = {
                                                              + copy_to      = [
                                                                  + "text_fields",
                                                                ]
                                                              + ignore_above = 256
                                                              + type         = "keyword"
                                                            }
                                                          + path           = {
                                                              + copy_to      = [
                                                                  + "text_fields",
                                                                ]
                                                              + ignore_above = 256
                                                              + type         = "keyword"
                                                            }
                                                          + system_version = {
                                                              + copy_to      = [
                                                                  + "text_fields",
                                                                ]
                                                              + ignore_above = 256
                                                              + type         = "keyword"
                                                            }
                                                          + time_end       = {
                                                              + type = "date"
                                                            }
                                                          + time_start     = {
                                                              + type = "date"
                                                            }
                                                          + transfer_rate  = {
                                                              + type = "double"
                                                            }
                                                          + urls           = {
                                                              + copy_to      = [
                                                                  + "text_fields",
                                                                ]
                                                              + ignore_above = 256
                                                              + type         = "keyword"
                                                            }
                                                        }
                                                    }
                                                }
                                            }
                                          + payload             = {
                                              + enabled = false
                                              + type    = "object"
                                            }
                                          + payload_hash        = {
                                              + copy_to      = [
                                                  + "text_fields",
                                                ]
                                              + ignore_above = 256
                                              + type         = "keyword"
                                            }
                                          + public_ip           = {
                                              + copy_to      = [
                                                  + "text_fields",
                                                ]
                                              + ignore_above = 256
                                              + type         = "keyword"
                                            }
                                          + status              = {
                                              + type = "integer"
                                            }
                                          + time_end            = {
                                              + type = "date"
                                            }
                                          + time_queued         = {
                                              + type = "date"
                                            }
                                          + time_start          = {
                                              + type = "date"
                                            }
                                        }
                                    }
                                  + localize_urls        = {
                                      + enabled = false
                                      + type    = "object"
                                    }
                                  + name                 = {
                                      + copy_to      = [
                                          + "text_fields",
                                        ]
                                      + ignore_above = 256
                                      + type         = "keyword"
                                    }
                                  + params               = {
                                      + enabled = false
                                      + type    = "object"
                                    }
                                  + priority             = {
                                      + type = "integer"
                                    }
                                  + tag                  = {
                                      + copy_to      = [
                                          + "text_fields",
                                        ]
                                      + ignore_above = 256
                                      + type         = "keyword"
                                    }
                                  + task_id              = {
                                      + copy_to      = [
                                          + "text_fields",
                                        ]
                                      + ignore_above = 256
                                      + type         = "keyword"
                                    }
                                  + type                 = {
                                      + copy_to      = [
                                          + "text_fields",
                                        ]
                                      + ignore_above = 256
                                      + type         = "keyword"
                                    }
                                  + username             = {
                                      + copy_to      = [
                                          + "text_fields",
                                        ]
                                      + ignore_above = 256
                                      + type         = "keyword"
                                    }
                                }
                            }
                          + job_id           = {
                              + copy_to      = [
                                  + "text_fields",
                                ]
                              + ignore_above = 256
                              + type         = "keyword"
                            }
                          + msg              = {
                              + copy_to      = [
                                  + "text_fields",
                                ]
                              + ignore_above = 256
                              + type         = "keyword"
                            }
                          + msg_details      = {
                              + copy_to      = [
                                  + "text_fields",
                                ]
                              + ignore_above = 256
                              + type         = "keyword"
                            }
                          + payload_hash     = {
                              + copy_to      = [
                                  + "text_fields",
                                ]
                              + ignore_above = 256
                              + type         = "keyword"
                            }
                          + payload_id       = {
                              + copy_to      = [
                                  + "text_fields",
                                ]
                              + ignore_above = 256
                              + type         = "keyword"
                            }
                          + resource         = {
                              + copy_to      = [
                                  + "text_fields",
                                ]
                              + ignore_above = 256
                              + type         = "keyword"
                            }
                          + short_error      = {
                              + copy_to = [
                                  + "text_fields",
                                ]
                              + fields  = {
                                  + keyword = {
                                      + ignore_above = 256
                                      + type         = "keyword"
                                    }
                                }
                              + type    = "text"
                            }
                          + signum           = {
                              + type = "integer"
                            }
                          + status           = {
                              + copy_to      = [
                                  + "text_fields",
                                ]
                              + ignore_above = 256
                              + type         = "keyword"
                            }
                          + tags             = {
                              + copy_to = [
                                  + "text_fields",
                                ]
                              + fields  = {
                                  + keyword = {
                                      + ignore_above = 256
                                      + type         = "keyword"
                                    }
                                }
                              + type    = "text"
                            }
                          + text_fields      = {
                              + type = "text"
                            }
                          + timestamp        = {
                              + type = "date"
                            }
                          + traceback        = {
                              + copy_to = [
                                  + "text_fields",
                                ]
                              + type    = "text"
                            }
                          + type             = {
                              + copy_to      = [
                                  + "text_fields",
                                ]
                              + ignore_above = 256
                              + type         = "keyword"
                            }
                          + user_tags        = {
                              + copy_to = [
                                  + "text_fields",
                                ]
                              + fields  = {
                                  + keyword = {
                                      + ignore_above = 256
                                      + type         = "keyword"
                                    }
                                }
                              + type    = "text"
                            }
                          + uuid             = {
                              + copy_to      = [
                                  + "text_fields",
                                ]
                              + ignore_above = 256
                              + type         = "keyword"
                            }
                        }
                    }
                  + settings       = {
                      + analysis               = {
                          + analyzer = {
                              + default = {
                                  + filter    = [
                                      + "lowercase",
                                      + "word_delimiter",
                                    ]
                                  + tokenizer = "keyword"
                                }
                            }
                        }
                      + index.refresh_interval = "5s"
                    }
                }
            )
          + "logstash-conf" = <<-EOT
                input {
                  redis {
                    host => "redis"
                    # {% if MOZART_REDIS_PASSWORD != "" %}password => "{{ MOZART_REDIS_PASSWORD }}"{% endif %}
                    # these settings should match the output of the agent
                    data_type => "list"
                    key => "logstash"

                    # We use the 'msgpack' codec here because we expect to read
                    # msgpack events from redis.
                    codec => msgpack
                  }
                }

                filter {
                  if [resource] in ["worker", "task"] {
                    mutate {
                      convert => {
                        "[event][timestamp]" => "string"
                        "[event][local_received]" => "string"
                      }

                      split => ["[event][timestamp]", "."]
                      split => ["[event][local_received]", "."]

                      add_field => [ "[event][timestamp_new]" , "%{[event][timestamp][0]}" ]
                      add_field => [ "[event][local_received_new]" , "%{[event][local_received][0]}" ]

                      remove_field => ["[event][timestamp]", "[event][local_received]"]
                    }

                    mutate {
                      rename => { "[event][timestamp_new]" => "timestamp" }
                      rename => { "[event][local_received_new]" => "local_received" }
                    }
                  }
                }

                output {
                  #stdout { codec => rubydebug }

                  if [resource] == "job" {
                    elasticsearch {
                      hosts => ["mozart-es:9200"]
                      index => "job_status-current"
                      document_id => "%{payload_id}"
                      template => "/usr/share/logstash/job_status.template.json"
                      template_name => "job_status"
                    }
                  } else if [resource] == "worker" {
                    elasticsearch {
                      hosts => ["mozart-es:9200"]
                      index => "worker_status-current"
                      document_id => "%{celery_hostname}"
                      template => "/usr/share/logstash/worker_status.template.json"
                      template_name => "worker_status"
                    }
                  } else if [resource] == "task" {
                    elasticsearch {
                      hosts => ["mozart-es:9200"]
                      index => "task_status-current"
                      document_id => "%{uuid}"
                      template => "/usr/share/logstash/task_status.template.json"
                      template_name => "task_status"
                    }
                  } else if [resource] == "event" {
                    elasticsearch {
                      hosts => ["mozart-es:9200"]
                      index => "event_status-current"
                      document_id => "%{uuid}"
                      template => "/usr/share/logstash/event_status.template.json"
                      template_name => "event_status"
                    }
                  } else {}
                }
            EOT
          + "logstash-yml"  = <<-EOT
                http.host: "0.0.0.0"
                xpack.monitoring.elasticsearch.hosts: ["http://mozart-es:9200"]
            EOT
          + "task-status"   = jsonencode(
                {
                  + aliases        = {
                      + job_status  = {}
                      + task_status = {}
                    }
                  + index_patterns = [
                      + "task_status*",
                    ]
                  + mappings       = {
                      + properties = {
                          + celery_hostname = {
                              + copy_to = [
                                  + "text_fields",
                                ]
                              + type    = "text"
                            }
                          + event           = {
                              + properties = {
                                  + active         = {
                                      + type = "integer"
                                    }
                                  + clock          = {
                                      + type = "integer"
                                    }
                                  + freq           = {
                                      + type = "double"
                                    }
                                  + hostname       = {
                                      + copy_to = [
                                          + "text_fields",
                                        ]
                                      + type    = "text"
                                    }
                                  + loadavg        = {
                                      + type = "double"
                                    }
                                  + local_received = {
                                      + type = "date"
                                    }
                                  + pid            = {
                                      + type = "integer"
                                    }
                                  + processed      = {
                                      + type = "integer"
                                    }
                                  + sw_ident       = {
                                      + copy_to = [
                                          + "text_fields",
                                        ]
                                      + type    = "text"
                                    }
                                  + sw_sys         = {
                                      + copy_to = [
                                          + "text_fields",
                                        ]
                                      + type    = "text"
                                    }
                                  + sw_ver         = {
                                      + copy_to = [
                                          + "text_fields",
                                        ]
                                      + type    = "text"
                                    }
                                  + timestamp      = {
                                      + type = "date"
                                    }
                                  + type           = {
                                      + copy_to = [
                                          + "text_fields",
                                        ]
                                      + type    = "text"
                                    }
                                  + utcoffset      = {
                                      + type = "integer"
                                    }
                                }
                            }
                          + resource        = {
                              + copy_to      = [
                                  + "text_fields",
                                ]
                              + ignore_above = 256
                              + type         = "keyword"
                            }
                          + status          = {
                              + copy_to      = [
                                  + "text_fields",
                                ]
                              + ignore_above = 256
                              + type         = "keyword"
                            }
                          + tags            = {
                              + fields = {
                                  + keyword = {
                                      + ignore_above = 256
                                      + type         = "keyword"
                                    }
                                }
                              + type   = "text"
                            }
                          + text_fields     = {
                              + type = "text"
                            }
                          + type            = {
                              + copy_to      = [
                                  + "text_fields",
                                ]
                              + ignore_above = 256
                              + type         = "keyword"
                            }
                          + uuid            = {
                              + copy_to = [
                                  + "text_fields",
                                ]
                              + type    = "text"
                            }
                        }
                    }
                  + settings       = {
                      + analysis = {
                          + analyzer = {
                              + default = {
                                  + filter    = [
                                      + "lowercase",
                                      + "word_delimiter",
                                    ]
                                  + tokenizer = "keyword"
                                }
                            }
                        }
                    }
                }
            )
          + "worker-status" = jsonencode(
                {
                  + aliases        = {
                      + job_status    = {}
                      + worker_status = {}
                    }
                  + index_patterns = [
                      + "worker_status*",
                    ]
                  + mappings       = {
                      + properties = {
                          + celery_hostname = {
                              + copy_to = [
                                  + "text_fields",
                                ]
                              + type    = "text"
                            }
                          + event           = {
                              + properties = {
                                  + active         = {
                                      + type = "integer"
                                    }
                                  + clock          = {
                                      + type = "integer"
                                    }
                                  + freq           = {
                                      + type = "double"
                                    }
                                  + hostname       = {
                                      + copy_to = [
                                          + "text_fields",
                                        ]
                                      + type    = "text"
                                    }
                                  + loadavg        = {
                                      + type = "double"
                                    }
                                  + local_received = {
                                      + type = "date"
                                    }
                                  + pid            = {
                                      + type = "integer"
                                    }
                                  + processed      = {
                                      + type = "integer"
                                    }
                                  + sw_ident       = {
                                      + copy_to = [
                                          + "text_fields",
                                        ]
                                      + type    = "text"
                                    }
                                  + sw_sys         = {
                                      + copy_to = [
                                          + "text_fields",
                                        ]
                                      + type    = "text"
                                    }
                                  + sw_ver         = {
                                      + copy_to = [
                                          + "text_fields",
                                        ]
                                      + type    = "text"
                                    }
                                  + timestamp      = {
                                      + type = "date"
                                    }
                                  + type           = {
                                      + copy_to = [
                                          + "text_fields",
                                        ]
                                      + type    = "text"
                                    }
                                  + utcoffset      = {
                                      + type = "integer"
                                    }
                                }
                            }
                          + resource        = {
                              + copy_to      = [
                                  + "text_fields",
                                ]
                              + ignore_above = 256
                              + type         = "keyword"
                            }
                          + status          = {
                              + copy_to      = [
                                  + "text_fields",
                                ]
                              + ignore_above = 256
                              + type         = "keyword"
                            }
                          + tags            = {
                              + fields = {
                                  + keyword = {
                                      + ignore_above = 256
                                      + type         = "keyword"
                                    }
                                }
                              + type   = "text"
                            }
                          + text_fields     = {
                              + type = "text"
                            }
                          + type            = {
                              + copy_to      = [
                                  + "text_fields",
                                ]
                              + ignore_above = 256
                              + type         = "keyword"
                            }
                          + uuid            = {
                              + copy_to = [
                                  + "text_fields",
                                ]
                              + type    = "text"
                            }
                        }
                    }
                  + settings       = {
                      + analysis = {
                          + analyzer = {
                              + default = {
                                  + filter    = [
                                      + "lowercase",
                                      + "word_delimiter",
                                    ]
                                  + tokenizer = "keyword"
                                }
                            }
                        }
                    }
                }
            )
        }
      + id   = (known after apply)

      + metadata {
          + generation       = (known after apply)
          + name             = "logstash-configs"
          + namespace        = "default"
          + resource_version = (known after apply)
          + uid              = (known after apply)
        }
    }

  # kubernetes_config_map.mozart-settings will be created
  + resource "kubernetes_config_map" "mozart-settings" {
      + data = {
          + "settings.cfg" = <<-EOT
                # secret key
                SECRET_KEY = "This is a test secret key"

                # ops account
                OPS_USER = "{{ OPS_USER }}"
                OPS_PASSWORD_HASH = "{{ OPS_PASSWORD_HASH }}"

                #LDAP
                LDAP_HOST = "ldap.test.com"
                LDAP_BASEDN = "ou=personnel,dc=dir,dc=test,dc=com"
                LDAP_GROUPS = "{{ LDAP_GROUPS }}"

                # PORT
                PORT = 8888

                # GRQ SERVER
                GRQ_HOST = "{{ GRQ_FQDN }}"
                GRQ_PORT = 80
                TOSCA_URL = "https://{{ GRQ_FQDN }}/search/"

                # Mozart URL
                MOZART_URL = "https://{{ MOZART_FQDN }}/mozart/"

                # Mozart REST API
                MOZART_REST_API = "https://{{ MOZART_PVT_IP }}/mozart/"

                # ElasticSearch host and indices
                ES_URL = "http://mozart-es:9200"
                USER_RULES_INDEX = "user_rules-mozart"
                HYSDS_IOS_INDEX = "hysds_ios-mozart"
                JOB_SPECS_INDEX = "job_specs"
                JOB_STATUS_INDEX = "job_status-current"
                CONTAINERS_INDEX = "containers"

                # key file for fabric
                KEY_FILENAME = "{{ KEY_FILENAME }}"

                # execute node user
                EXECUTE_NODE_USER = "{{ OPS_USER }}"

                # puccini host
                PUCCINI_HOST = "{{ PUCCINI_FQDN }}"
                PUCCINI_USER = "{{ OPS_USER }}"

                # Kibana URL
                KIBANA_JOB_METRICS_URL = "https://{{ METRICS_FQDN }}/metrics/#/dashboard/elasticsearch/Job%20Metrics"
                KIBANA_PROV_METRICS_URL = "https://{{ METRICS_FQDN }}/metrics/#/dashboard/elasticsearch/Provenance%20Metrics"
                KIBANA_INSTANCE_STATS_URL = "https://{{ METRICS_FQDN }}/metrics/#/dashboard/elasticsearch/Worker%20Metrics"

                # Flower URL
                FLOWER_URL = "http://{{ MOZART_FQDN }}:5555"

                # RabbitMQ Admin URL
                RABBITMQ_ADMIN_URL = "http://rabbitmq:15672"
                RABBITMQ_ADMIN_API = "http://rabbitmq:15672"

                # System protected queue
                PROTECTED_QUEUES = ["{{ SYSTEM_JOBS_QUEUE }}"]

                JOB_SUBMISSION_JOB_SPEC = "{{ LIGHTWEIGHT_JOBS_SPEC }}"
                JOB_SUBMISSION_QUEUE = "{{ SYSTEM_JOBS_QUEUE }}"

                # ES plugins
                # ES_HEAD_URL = "http://{{ MOZART_ES_FQDN }}:9200/_plugin/head"
                # ES_KOPF_URL = "http://{{ MOZART_ES_FQDN }}:9200/_plugin/kopf"

                # value needed to generate Jenkins job name
                # VENUE = "{{ VENUE }}"
                VENUE = "unity-demo"

                # jenkins
                # JENKINS_ENABLED = {{ JENKINS_ENABLED or False }}
                JENKINS_ENABLED = False
                JENKINS_HOST = "{{ JENKINS_HOST }}"
                JENKINS_USER = "{{ JENKINS_API_USER }}"
                JENKINS_API_KEY = "{{ JENKINS_API_KEY }}"
            EOT
        }
      + id   = (known after apply)

      + metadata {
          + generation       = (known after apply)
          + name             = "mozart-settings"
          + namespace        = "default"
          + resource_version = (known after apply)
          + uid              = (known after apply)
        }
    }

  # kubernetes_config_map.netrc will be created
  + resource "kubernetes_config_map" "netrc" {
      + data = {
          + ".netrc" = <<-EOT
                machine rabbitmq
                login guest
                password guest
            EOT
        }
      + id   = (known after apply)

      + metadata {
          + generation       = (known after apply)
          + name             = "netrc"
          + namespace        = "default"
          + resource_version = (known after apply)
          + uid              = (known after apply)
        }
    }

  # kubernetes_config_map.supervisord-job-worker will be created
  + resource "kubernetes_config_map" "supervisord-job-worker" {
      + data = {
          + "supervisord.conf" = <<-EOT
                [supervisord]

                [program:factotum-job_worker-small]
                directory=/home/ops/hysds
                environment=HYSDS_ROOT_WORK_DIR="/private/tmp/data/work",
                            HYSDS_DATASETS_CFG="/home/ops/datasets.json"
                command=celery --app=hysds worker --concurrency=1 --loglevel=INFO -Q factotum-job_worker-small -n %(program_name)s.%(process_num)02d.%%h -O fair --without-mingle --without-gossip --heartbeat-interval=60
                process_name=%(program_name)s-%(process_num)02d
                priority=1
                numprocs=1
                numprocs_start=0
                redirect_stderr=true
                stdout_logfile=/home/ops/%(program_name)s-%(process_num)02d.log
                stdout_logfile_maxbytes=20MB
                stdout_logfile_backups=1
                startsecs=10

                [program:factotum-job_worker-large]
                directory=/home/ops/hysds
                environment=HYSDS_ROOT_WORK_DIR="/private/tmp/data/work",
                            HYSDS_DATASETS_CFG="/home/ops/datasets.json"
                command=celery --app=hysds worker --concurrency=1 --loglevel=INFO -Q factotum-job_worker-large -n %(program_name)s.%(process_num)02d.%%h -O fair --without-mingle --without-gossip --heartbeat-interval=60
                process_name=%(program_name)s-%(process_num)02d
                priority=1
                numprocs=1
                numprocs_start=0
                redirect_stderr=true
                stdout_logfile=/home/ops/%(program_name)s-%(process_num)02d.log
                stdout_logfile_maxbytes=20MB
                stdout_logfile_backups=1
                startsecs=10

                [program:system-jobs-queue]
                directory=/home/ops/hysds
                environment=HYSDS_ROOT_WORK_DIR="/private/tmp/data/work",
                            HYSDS_DATASETS_CFG="/home/ops/datasets.json"
                command=celery --app=hysds worker --concurrency=1 --loglevel=INFO -Q system-jobs-queue -n %(program_name)s.%(process_num)02d.%%h -O fair --without-mingle --without-gossip --heartbeat-interval=60
                process_name=%(program_name)s-%(process_num)02d
                priority=1
                numprocs=2
                numprocs_start=0
                redirect_stderr=true
                stdout_logfile=/home/ops/%(program_name)s-%(process_num)02d.log
                stdout_logfile_maxbytes=20MB
                stdout_logfile_backups=1
                startsecs=10
            EOT
        }
      + id   = (known after apply)

      + metadata {
          + generation       = (known after apply)
          + name             = "supervisord-job-worker"
          + namespace        = "default"
          + resource_version = (known after apply)
          + uid              = (known after apply)
        }
    }

  # kubernetes_config_map.supervisord-orchestrator will be created
  + resource "kubernetes_config_map" "supervisord-orchestrator" {
      + data = {
          + "supervisord.conf" = <<-EOT
                [supervisord]

                [program:orchestrator_datasets]
                directory=/home/ops/hysds
                environment=HYSDS_ORCHESTRATOR_CFG="/home/ops/hysds/configs/orchestrator/orchestrator_datasets.json",
                            HYSDS_JOB_CREATORS_DIR="/home/ops/hysds/scripts/job_creators"
                command=celery --app=hysds worker --concurrency=1 --loglevel=INFO -Q dataset_processed -n %(program_name)s.%(process_num)02d.%%h -O fair --without-mingle --without-gossip --heartbeat-interval=60
                process_name=%(program_name)s-%(process_num)02d
                priority=1
                numprocs=2
                numprocs_start=0
                redirect_stderr=true
                stdout_logfile=/home/ops/%(program_name)s-%(process_num)02d.log
                stdout_logfile_maxbytes=20MB
                stdout_logfile_backups=1
                startsecs=10

                [program:orchestrator_jobs]
                directory=/home/ops/hysds
                environment=HYSDS_ORCHESTRATOR_CFG="/home/ops/hysds/configs/orchestrator/orchestrator_jobs.json",
                            HYSDS_JOB_CREATORS_DIR="/home/ops/hysds/scripts/job_creators"
                command=celery --app=hysds worker --concurrency=1 --loglevel=INFO -Q jobs_processed -n %(program_name)s.%(process_num)02d.%%h -O fair --without-mingle --without-gossip --heartbeat-interval=60
                process_name=%(program_name)s-%(process_num)02d
                priority=1
                numprocs=2
                numprocs_start=0
                redirect_stderr=true
                stdout_logfile=/home/ops/%(program_name)s-%(process_num)02d.log
                stdout_logfile_maxbytes=20MB
                stdout_logfile_backups=1
                startsecs=10

                [program:on_demand_job]
                directory=/home/ops/hysds
                command=celery --app=hysds worker --concurrency=1 --loglevel=INFO -Q on_demand_job -n %(program_name)s.%(process_num)02d.%%h -O fair --without-mingle --without-gossip --heartbeat-interval=60
                process_name=%(program_name)s-%(process_num)02d
                priority=1
                numprocs=2
                numprocs_start=0
                redirect_stderr=true
                stdout_logfile=/home/ops/%(program_name)s-%(process_num)02d.log
                stdout_logfile_maxbytes=20MB
                stdout_logfile_backups=1
                startsecs=10

                [program:on_demand_dataset]
                directory=/home/ops/hysds
                command=celery --app=hysds worker --concurrency=1 --loglevel=INFO -Q on_demand_dataset -n %(program_name)s.%(process_num)02d.%%h -O fair --without-mingle --without-gossip --heartbeat-interval=60
                process_name=%(program_name)s-%(process_num)02d
                priority=1
                numprocs=2
                numprocs_start=0
                redirect_stderr=true
                stdout_logfile=/home/ops/%(program_name)s-%(process_num)02d.log
                stdout_logfile_maxbytes=20MB
                stdout_logfile_backups=1
                startsecs=10
            EOT
        }
      + id   = (known after apply)

      + metadata {
          + generation       = (known after apply)
          + name             = "supervisord-orchestrator"
          + namespace        = "default"
          + resource_version = (known after apply)
          + uid              = (known after apply)
        }
    }

  # kubernetes_config_map.supervisord-user-rules will be created
  + resource "kubernetes_config_map" "supervisord-user-rules" {
      + data = {
          + "supervisord.conf" = <<-EOT
                [supervisord]

                [program:user_rules_job]
                directory=/home/ops/hysds
                command=celery --app=hysds worker --concurrency=1 --loglevel=INFO -Q user_rules_job -n %(program_name)s.%(process_num)02d.%%h -O fair --without-mingle --without-gossip --heartbeat-interval=60
                process_name=%(program_name)s-%(process_num)02d
                priority=1
                numprocs=2
                numprocs_start=0
                redirect_stderr=true
                stdout_logfile=/home/ops/%(program_name)s-%(process_num)02d.log
                stdout_logfile_maxbytes=20MB
                stdout_logfile_backups=1
                startsecs=10

                [program:user_rules_dataset]
                directory=/home/ops/hysds
                command=celery --app=hysds worker --concurrency=1 --loglevel=INFO -Q user_rules_dataset -n %(program_name)s.%(process_num)02d.%%h -O fair --without-mingle --without-gossip --heartbeat-interval=60
                process_name=%(program_name)s-%(process_num)02d
                priority=1
                numprocs=2
                numprocs_start=0
                redirect_stderr=true
                stdout_logfile=/home/ops/%(program_name)s-%(process_num)02d.log
                stdout_logfile_maxbytes=20MB
                stdout_logfile_backups=1
                startsecs=10
            EOT
        }
      + id   = (known after apply)

      + metadata {
          + generation       = (known after apply)
          + name             = "supervisord-user-rules"
          + namespace        = "default"
          + resource_version = (known after apply)
          + uid              = (known after apply)
        }
    }

  # kubernetes_deployment.factotum-job-worker will be created
  + resource "kubernetes_deployment" "factotum-job-worker" {
      + id               = (known after apply)
      + wait_for_rollout = true

      + metadata {
          + generation       = (known after apply)
          + labels           = {
              + "app" = "factotum-job-worker"
            }
          + name             = "factotum-job-worker"
          + namespace        = "default"
          + resource_version = (known after apply)
          + uid              = (known after apply)
        }

      + spec {
          + min_ready_seconds         = 0
          + paused                    = false
          + progress_deadline_seconds = 600
          + replicas                  = (known after apply)
          + revision_history_limit    = 10

          + selector {
              + match_labels = {
                  + "app" = "factotum-job-worker"
                }
            }

          + strategy {
              + type = (known after apply)

              + rolling_update {
                  + max_surge       = (known after apply)
                  + max_unavailable = (known after apply)
                }
            }

          + template {
              + metadata {
                  + generation       = (known after apply)
                  + labels           = {
                      + "app" = "factotum-job-worker"
                    }
                  + name             = (known after apply)
                  + resource_version = (known after apply)
                  + uid              = (known after apply)
                }

              + spec {
                  + automount_service_account_token  = true
                  + dns_policy                       = "ClusterFirst"
                  + enable_service_links             = true
                  + host_ipc                         = false
                  + host_network                     = false
                  + host_pid                         = false
                  + hostname                         = (known after apply)
                  + node_name                        = (known after apply)
                  + restart_policy                   = "Always"
                  + service_account_name             = (known after apply)
                  + share_process_namespace          = false
                  + termination_grace_period_seconds = 30

                  + container {
                      + command                    = [
                          + "supervisord",
                          + "--nodaemon",
                        ]
                      + image                      = "factotum:unity-v0.0.1"
                      + image_pull_policy          = (known after apply)
                      + name                       = "factotum-job-worker"
                      + stdin                      = false
                      + stdin_once                 = false
                      + termination_message_path   = "/dev/termination-log"
                      + termination_message_policy = (known after apply)
                      + tty                        = false

                      + resources {
                          + limits   = (known after apply)
                          + requests = (known after apply)
                        }

                      + volume_mount {
                          + mount_path        = "/var/run/docker.sock"
                          + mount_propagation = "None"
                          + name              = "docker-sock"
                          + read_only         = false
                        }
                      + volume_mount {
                          + mount_path        = "/home/ops/factotum/celeryconfig.py"
                          + mount_propagation = "None"
                          + name              = "celeryconfig"
                          + read_only         = false
                          + sub_path          = "celeryconfig.py"
                        }
                      + volume_mount {
                          + mount_path        = "/home/ops/datasets.json"
                          + mount_propagation = "None"
                          + name              = "datasets"
                          + read_only         = false
                          + sub_path          = "datasets.json"
                        }
                      + volume_mount {
                          + mount_path        = "/home/ops/supervisord.conf"
                          + mount_propagation = "None"
                          + name              = "supervisord-job-worker"
                          + read_only         = false
                          + sub_path          = "supervisord.conf"
                        }
                      + volume_mount {
                          + mount_path        = "/home/ops/.aws/credentials"
                          + mount_propagation = "None"
                          + name              = "aws-credentials"
                          + read_only         = false
                          + sub_path          = "aws-credentials"
                        }
                      + volume_mount {
                          + mount_path        = "/private/tmp/data"
                          + mount_propagation = "None"
                          + name              = "data-work"
                          + read_only         = false
                        }
                    }

                  + image_pull_secrets {
                      + name = (known after apply)
                    }

                  + init_container {
                      + command                    = [
                          + "/bin/sh",
                          + "-c",
                          + "chmod 777 /var/run/docker.sock; chown -R 1000:1000 /private/tmp/data;",
                        ]
                      + image                      = "k8s.gcr.io/busybox"
                      + image_pull_policy          = (known after apply)
                      + name                       = "changeume-ownership"
                      + stdin                      = false
                      + stdin_once                 = false
                      + termination_message_path   = "/dev/termination-log"
                      + termination_message_policy = (known after apply)
                      + tty                        = false

                      + resources {
                          + limits   = (known after apply)
                          + requests = (known after apply)
                        }

                      + volume_mount {
                          + mount_path        = "/var/run/docker.sock"
                          + mount_propagation = "None"
                          + name              = "docker-sock"
                          + read_only         = false
                        }
                      + volume_mount {
                          + mount_path        = "/private/tmp/data"
                          + mount_propagation = "None"
                          + name              = "data-work"
                          + read_only         = false
                        }
                    }

                  + readiness_gate {
                      + condition_type = (known after apply)
                    }

                  + volume {
                      + name = "docker-sock"

                      + host_path {
                          + path = "/var/run/docker.sock"
                        }
                    }
                  + volume {
                      + name = "celeryconfig"

                      + config_map {
                          + default_mode = "0644"
                          + name         = "celeryconfig"
                        }
                    }
                  + volume {
                      + name = "datasets"

                      + config_map {
                          + default_mode = "0644"
                          + name         = "datasets"
                        }
                    }
                  + volume {
                      + name = "supervisord-job-worker"

                      + config_map {
                          + default_mode = "0644"
                          + name         = "supervisord-job-worker"
                        }
                    }
                  + volume {
                      + name = "aws-credentials"

                      + config_map {
                          + default_mode = "0644"
                          + name         = "aws-credentials"
                        }
                    }
                  + volume {
                      + name = "data-work"

                      + host_path {
                          + path = "/private/tmp/data"
                        }
                    }
                }
            }
        }
    }

  # kubernetes_deployment.grq2 will be created
  + resource "kubernetes_deployment" "grq2" {
      + id               = (known after apply)
      + wait_for_rollout = true

      + metadata {
          + generation       = (known after apply)
          + labels           = {
              + "app" = "grq2"
            }
          + name             = "grq2"
          + namespace        = "default"
          + resource_version = (known after apply)
          + uid              = (known after apply)
        }

      + spec {
          + min_ready_seconds         = 0
          + paused                    = false
          + progress_deadline_seconds = 600
          + replicas                  = (known after apply)
          + revision_history_limit    = 10

          + selector {
              + match_labels = {
                  + "app" = "grq2"
                }
            }

          + strategy {
              + type = (known after apply)

              + rolling_update {
                  + max_surge       = (known after apply)
                  + max_unavailable = (known after apply)
                }
            }

          + template {
              + metadata {
                  + generation       = (known after apply)
                  + labels           = {
                      + "app" = "grq2"
                    }
                  + name             = (known after apply)
                  + resource_version = (known after apply)
                  + uid              = (known after apply)
                }

              + spec {
                  + automount_service_account_token  = true
                  + dns_policy                       = "ClusterFirst"
                  + enable_service_links             = true
                  + host_ipc                         = false
                  + host_network                     = false
                  + host_pid                         = false
                  + hostname                         = (known after apply)
                  + node_name                        = (known after apply)
                  + restart_policy                   = "Always"
                  + service_account_name             = (known after apply)
                  + share_process_namespace          = false
                  + termination_grace_period_seconds = 30

                  + container {
                      + image                      = "hysds-grq2:unity-v0.0.1"
                      + image_pull_policy          = (known after apply)
                      + name                       = "grq2"
                      + stdin                      = false
                      + stdin_once                 = false
                      + termination_message_path   = "/dev/termination-log"
                      + termination_message_policy = (known after apply)
                      + tty                        = false

                      + port {
                          + container_port = 8878
                          + name           = "grq2"
                          + protocol       = "TCP"
                        }

                      + resources {
                          + limits   = (known after apply)
                          + requests = (known after apply)
                        }

                      + volume_mount {
                          + mount_path        = "/home/ops/grq2/settings.cfg"
                          + mount_propagation = "None"
                          + name              = "grq2-settings"
                          + read_only         = false
                          + sub_path          = "settings.cfg"
                        }
                      + volume_mount {
                          + mount_path        = "/home/ops/grq2/celeryconfig.py"
                          + mount_propagation = "None"
                          + name              = "celeryconfig"
                          + read_only         = false
                          + sub_path          = "celeryconfig.py"
                        }
                      + volume_mount {
                          + mount_path        = "/home/ops/.netrc"
                          + mount_propagation = "None"
                          + name              = "netrc"
                          + read_only         = false
                          + sub_path          = ".netrc"
                        }
                    }

                  + image_pull_secrets {
                      + name = (known after apply)
                    }

                  + readiness_gate {
                      + condition_type = (known after apply)
                    }

                  + volume {
                      + name = "grq2-settings"

                      + config_map {
                          + default_mode = "0644"
                          + name         = "grq2-settings"
                        }
                    }
                  + volume {
                      + name = "celeryconfig"

                      + config_map {
                          + default_mode = "0644"
                          + name         = "celeryconfig"
                        }
                    }
                  + volume {
                      + name = "netrc"

                      + config_map {
                          + default_mode = "0644"
                          + name         = "netrc"
                        }
                    }
                }
            }
        }
    }

  # kubernetes_deployment.hysds-ui will be created
  + resource "kubernetes_deployment" "hysds-ui" {
      + id               = (known after apply)
      + wait_for_rollout = true

      + metadata {
          + generation       = (known after apply)
          + name             = "hysds-ui"
          + namespace        = "default"
          + resource_version = (known after apply)
          + uid              = (known after apply)
        }

      + spec {
          + min_ready_seconds         = 0
          + paused                    = false
          + progress_deadline_seconds = 600
          + replicas                  = (known after apply)
          + revision_history_limit    = 10

          + selector {
              + match_labels = {
                  + "app" = "hysds-ui"
                }
            }

          + strategy {
              + type = (known after apply)

              + rolling_update {
                  + max_surge       = (known after apply)
                  + max_unavailable = (known after apply)
                }
            }

          + template {
              + metadata {
                  + generation       = (known after apply)
                  + labels           = {
                      + "app" = "hysds-ui"
                    }
                  + name             = (known after apply)
                  + resource_version = (known after apply)
                  + uid              = (known after apply)
                }

              + spec {
                  + automount_service_account_token  = true
                  + dns_policy                       = "ClusterFirst"
                  + enable_service_links             = true
                  + host_ipc                         = false
                  + host_network                     = false
                  + host_pid                         = false
                  + hostname                         = (known after apply)
                  + node_name                        = (known after apply)
                  + restart_policy                   = "Always"
                  + service_account_name             = (known after apply)
                  + share_process_namespace          = false
                  + termination_grace_period_seconds = 30

                  + container {
                      + image                      = "hysds-ui:unity-v0.0.1"
                      + image_pull_policy          = (known after apply)
                      + name                       = "hysds-ui"
                      + stdin                      = false
                      + stdin_once                 = false
                      + termination_message_path   = "/dev/termination-log"
                      + termination_message_policy = (known after apply)
                      + tty                        = false

                      + port {
                          + container_port = 80
                          + protocol       = "TCP"
                        }

                      + resources {
                          + limits   = (known after apply)
                          + requests = (known after apply)
                        }
                    }

                  + image_pull_secrets {
                      + name = (known after apply)
                    }

                  + readiness_gate {
                      + condition_type = (known after apply)
                    }

                  + volume {
                      + name = (known after apply)

                      + aws_elastic_block_store {
                          + fs_type   = (known after apply)
                          + partition = (known after apply)
                          + read_only = (known after apply)
                          + volume_id = (known after apply)
                        }

                      + azure_disk {
                          + caching_mode  = (known after apply)
                          + data_disk_uri = (known after apply)
                          + disk_name     = (known after apply)
                          + fs_type       = (known after apply)
                          + kind          = (known after apply)
                          + read_only     = (known after apply)
                        }

                      + azure_file {
                          + read_only        = (known after apply)
                          + secret_name      = (known after apply)
                          + secret_namespace = (known after apply)
                          + share_name       = (known after apply)
                        }

                      + ceph_fs {
                          + monitors    = (known after apply)
                          + path        = (known after apply)
                          + read_only   = (known after apply)
                          + secret_file = (known after apply)
                          + user        = (known after apply)

                          + secret_ref {
                              + name      = (known after apply)
                              + namespace = (known after apply)
                            }
                        }

                      + cinder {
                          + fs_type   = (known after apply)
                          + read_only = (known after apply)
                          + volume_id = (known after apply)
                        }

                      + config_map {
                          + default_mode = (known after apply)
                          + name         = (known after apply)
                          + optional     = (known after apply)

                          + items {
                              + key  = (known after apply)
                              + mode = (known after apply)
                              + path = (known after apply)
                            }
                        }

                      + csi {
                          + driver            = (known after apply)
                          + fs_type           = (known after apply)
                          + read_only         = (known after apply)
                          + volume_attributes = (known after apply)
                          + volume_handle     = (known after apply)

                          + controller_expand_secret_ref {
                              + name      = (known after apply)
                              + namespace = (known after apply)
                            }

                          + controller_publish_secret_ref {
                              + name      = (known after apply)
                              + namespace = (known after apply)
                            }

                          + node_publish_secret_ref {
                              + name      = (known after apply)
                              + namespace = (known after apply)
                            }

                          + node_stage_secret_ref {
                              + name      = (known after apply)
                              + namespace = (known after apply)
                            }
                        }

                      + downward_api {
                          + default_mode = (known after apply)

                          + items {
                              + mode = (known after apply)
                              + path = (known after apply)

                              + field_ref {
                                  + api_version = (known after apply)
                                  + field_path  = (known after apply)
                                }

                              + resource_field_ref {
                                  + container_name = (known after apply)
                                  + divisor        = (known after apply)
                                  + resource       = (known after apply)
                                }
                            }
                        }

                      + empty_dir {
                          + medium     = (known after apply)
                          + size_limit = (known after apply)
                        }

                      + fc {
                          + fs_type      = (known after apply)
                          + lun          = (known after apply)
                          + read_only    = (known after apply)
                          + target_ww_ns = (known after apply)
                        }

                      + flex_volume {
                          + driver    = (known after apply)
                          + fs_type   = (known after apply)
                          + options   = (known after apply)
                          + read_only = (known after apply)

                          + secret_ref {
                              + name      = (known after apply)
                              + namespace = (known after apply)
                            }
                        }

                      + flocker {
                          + dataset_name = (known after apply)
                          + dataset_uuid = (known after apply)
                        }

                      + gce_persistent_disk {
                          + fs_type   = (known after apply)
                          + partition = (known after apply)
                          + pd_name   = (known after apply)
                          + read_only = (known after apply)
                        }

                      + git_repo {
                          + directory  = (known after apply)
                          + repository = (known after apply)
                          + revision   = (known after apply)
                        }

                      + glusterfs {
                          + endpoints_name = (known after apply)
                          + path           = (known after apply)
                          + read_only      = (known after apply)
                        }

                      + host_path {
                          + path = (known after apply)
                          + type = (known after apply)
                        }

                      + iscsi {
                          + fs_type         = (known after apply)
                          + iqn             = (known after apply)
                          + iscsi_interface = (known after apply)
                          + lun             = (known after apply)
                          + read_only       = (known after apply)
                          + target_portal   = (known after apply)
                        }

                      + local {
                          + path = (known after apply)
                        }

                      + nfs {
                          + path      = (known after apply)
                          + read_only = (known after apply)
                          + server    = (known after apply)
                        }

                      + persistent_volume_claim {
                          + claim_name = (known after apply)
                          + read_only  = (known after apply)
                        }

                      + photon_persistent_disk {
                          + fs_type = (known after apply)
                          + pd_id   = (known after apply)
                        }

                      + projected {
                          + default_mode = (known after apply)

                          + sources {
                              + config_map {
                                  + name     = (known after apply)
                                  + optional = (known after apply)

                                  + items {
                                      + key  = (known after apply)
                                      + mode = (known after apply)
                                      + path = (known after apply)
                                    }
                                }

                              + downward_api {
                                  + items {
                                      + mode = (known after apply)
                                      + path = (known after apply)

                                      + field_ref {
                                          + api_version = (known after apply)
                                          + field_path  = (known after apply)
                                        }

                                      + resource_field_ref {
                                          + container_name = (known after apply)
                                          + divisor        = (known after apply)
                                          + resource       = (known after apply)
                                        }
                                    }
                                }

                              + secret {
                                  + name     = (known after apply)
                                  + optional = (known after apply)

                                  + items {
                                      + key  = (known after apply)
                                      + mode = (known after apply)
                                      + path = (known after apply)
                                    }
                                }

                              + service_account_token {
                                  + audience           = (known after apply)
                                  + expiration_seconds = (known after apply)
                                  + path               = (known after apply)
                                }
                            }
                        }

                      + quobyte {
                          + group     = (known after apply)
                          + read_only = (known after apply)
                          + registry  = (known after apply)
                          + user      = (known after apply)
                          + volume    = (known after apply)
                        }

                      + rbd {
                          + ceph_monitors = (known after apply)
                          + fs_type       = (known after apply)
                          + keyring       = (known after apply)
                          + rados_user    = (known after apply)
                          + rbd_image     = (known after apply)
                          + rbd_pool      = (known after apply)
                          + read_only     = (known after apply)

                          + secret_ref {
                              + name      = (known after apply)
                              + namespace = (known after apply)
                            }
                        }

                      + secret {
                          + default_mode = (known after apply)
                          + optional     = (known after apply)
                          + secret_name  = (known after apply)

                          + items {
                              + key  = (known after apply)
                              + mode = (known after apply)
                              + path = (known after apply)
                            }
                        }

                      + vsphere_volume {
                          + fs_type     = (known after apply)
                          + volume_path = (known after apply)
                        }
                    }
                }
            }
        }
    }

  # kubernetes_deployment.logstash will be created
  + resource "kubernetes_deployment" "logstash" {
      + id               = (known after apply)
      + wait_for_rollout = true

      + metadata {
          + generation       = (known after apply)
          + labels           = {
              + "app" = "logstash"
            }
          + name             = "logstash"
          + namespace        = "default"
          + resource_version = (known after apply)
          + uid              = (known after apply)
        }

      + spec {
          + min_ready_seconds         = 0
          + paused                    = false
          + progress_deadline_seconds = 600
          + replicas                  = (known after apply)
          + revision_history_limit    = 10

          + selector {
              + match_labels = {
                  + "app" = "logstash"
                }
            }

          + strategy {
              + type = (known after apply)

              + rolling_update {
                  + max_surge       = (known after apply)
                  + max_unavailable = (known after apply)
                }
            }

          + template {
              + metadata {
                  + generation       = (known after apply)
                  + labels           = {
                      + "app" = "logstash"
                    }
                  + name             = (known after apply)
                  + resource_version = (known after apply)
                  + uid              = (known after apply)
                }

              + spec {
                  + automount_service_account_token  = true
                  + dns_policy                       = "ClusterFirst"
                  + enable_service_links             = true
                  + host_ipc                         = false
                  + host_network                     = false
                  + host_pid                         = false
                  + hostname                         = (known after apply)
                  + node_name                        = (known after apply)
                  + restart_policy                   = "Always"
                  + service_account_name             = (known after apply)
                  + share_process_namespace          = false
                  + termination_grace_period_seconds = 30

                  + container {
                      + args                       = [
                          + "-f",
                          + "/usr/share/logstash/logstash.conf",
                        ]
                      + command                    = [
                          + "bin/logstash",
                        ]
                      + image                      = "logstash:7.9.3"
                      + image_pull_policy          = (known after apply)
                      + name                       = "logstash"
                      + stdin                      = false
                      + stdin_once                 = false
                      + termination_message_path   = "/dev/termination-log"
                      + termination_message_policy = (known after apply)
                      + tty                        = false

                      + port {
                          + container_port = 5044
                          + protocol       = "TCP"
                        }

                      + resources {
                          + limits   = (known after apply)
                          + requests = (known after apply)
                        }

                      + volume_mount {
                          + mount_path        = "/usr/share/logstash/logstash.conf"
                          + mount_propagation = "None"
                          + name              = "logstash-conf"
                          + read_only         = false
                          + sub_path          = "logstash.cfg"
                        }
                      + volume_mount {
                          + mount_path        = "/usr/share/logstash/job_status.template.json"
                          + mount_propagation = "None"
                          + name              = "job-status-mapping"
                          + read_only         = false
                          + sub_path          = "job_status.template.json"
                        }
                      + volume_mount {
                          + mount_path        = "/usr/share/logstash/task_status.template.json"
                          + mount_propagation = "None"
                          + name              = "task-status-mapping"
                          + read_only         = false
                          + sub_path          = "taks_status.template.json"
                        }
                      + volume_mount {
                          + mount_path        = "/usr/share/logstash/event_status.template.json"
                          + mount_propagation = "None"
                          + name              = "event-status-mapping"
                          + read_only         = false
                          + sub_path          = "event_status.template.json"
                        }
                      + volume_mount {
                          + mount_path        = "/usr/share/logstash/worker_status.template.json"
                          + mount_propagation = "None"
                          + name              = "worker-status-mapping"
                          + read_only         = false
                          + sub_path          = "worker_status.template.json"
                        }
                      + volume_mount {
                          + mount_path        = "/usr/share/logstash/config/logstash.yml"
                          + mount_propagation = "None"
                          + name              = "logstash-yml"
                          + read_only         = false
                          + sub_path          = "logstash.yml"
                        }
                    }

                  + image_pull_secrets {
                      + name = (known after apply)
                    }

                  + readiness_gate {
                      + condition_type = (known after apply)
                    }

                  + volume {
                      + name = "logstash-conf"

                      + config_map {
                          + default_mode = "0644"
                          + name         = "logstash-configs"

                          + items {
                              + key  = "logstash-conf"
                              + path = "logstash.conf"
                            }
                        }
                    }
                  + volume {
                      + name = "job-status-mapping"

                      + config_map {
                          + default_mode = "0644"
                          + name         = "logstash-configs"

                          + items {
                              + key  = "job-status"
                              + path = "job_status.template.json"
                            }
                        }
                    }
                  + volume {
                      + name = "task-status-mapping"

                      + config_map {
                          + default_mode = "0644"
                          + name         = "logstash-configs"

                          + items {
                              + key  = "task-status"
                              + path = "taks_status.template.json"
                            }
                        }
                    }
                  + volume {
                      + name = "event-status-mapping"

                      + config_map {
                          + default_mode = "0644"
                          + name         = "logstash-configs"

                          + items {
                              + key  = "event-status"
                              + path = "event_status.template.json"
                            }
                        }
                    }
                  + volume {
                      + name = "worker-status-mapping"

                      + config_map {
                          + default_mode = "0644"
                          + name         = "logstash-configs"

                          + items {
                              + key  = "worker-status"
                              + path = "worker_status.template.json"
                            }
                        }
                    }
                  + volume {
                      + name = "logstash-yml"

                      + config_map {
                          + default_mode = "0644"
                          + name         = "logstash-configs"

                          + items {
                              + key  = "logstash-yml"
                              + path = "logstash.yml"
                            }
                        }
                    }
                }
            }
        }
    }

  # kubernetes_deployment.minio will be created
  + resource "kubernetes_deployment" "minio" {
      + id               = (known after apply)
      + wait_for_rollout = true

      + metadata {
          + generation       = (known after apply)
          + labels           = {
              + "app" = "minio"
            }
          + name             = "minio"
          + namespace        = "default"
          + resource_version = (known after apply)
          + uid              = (known after apply)
        }

      + spec {
          + min_ready_seconds         = 0
          + paused                    = false
          + progress_deadline_seconds = 600
          + replicas                  = (known after apply)
          + revision_history_limit    = 10

          + selector {
              + match_labels = {
                  + "app" = "minio"
                }
            }

          + strategy {
              + type = "Recreate"

              + rolling_update {
                  + max_surge       = (known after apply)
                  + max_unavailable = (known after apply)
                }
            }

          + template {
              + metadata {
                  + generation       = (known after apply)
                  + labels           = {
                      + "app" = "minio"
                    }
                  + name             = (known after apply)
                  + resource_version = (known after apply)
                  + uid              = (known after apply)
                }

              + spec {
                  + automount_service_account_token  = true
                  + dns_policy                       = "ClusterFirst"
                  + enable_service_links             = true
                  + host_ipc                         = false
                  + host_network                     = false
                  + host_pid                         = false
                  + hostname                         = (known after apply)
                  + node_name                        = (known after apply)
                  + restart_policy                   = "Always"
                  + service_account_name             = (known after apply)
                  + share_process_namespace          = false
                  + termination_grace_period_seconds = 30

                  + container {
                      + args                       = [
                          + "server",
                          + "/storage",
                          + "--console-address=:9001",
                        ]
                      + image                      = "minio/minio:latest"
                      + image_pull_policy          = (known after apply)
                      + name                       = "minio"
                      + stdin                      = false
                      + stdin_once                 = false
                      + termination_message_path   = "/dev/termination-log"
                      + termination_message_policy = (known after apply)
                      + tty                        = false

                      + env {
                          + name  = "MINIO_ACCESS_KEY"
                          + value = "hysds"
                        }
                      + env {
                          + name  = "MINIO_SECRET_KEY"
                          + value = "password"
                        }

                      + port {
                          + container_port = 9000
                          + host_port      = 9000
                          + protocol       = "TCP"
                        }
                      + port {
                          + container_port = 9001
                          + host_port      = 9001
                          + protocol       = "TCP"
                        }

                      + resources {
                          + limits   = (known after apply)
                          + requests = (known after apply)
                        }

                      + volume_mount {
                          + mount_path        = "/storage"
                          + mount_propagation = "None"
                          + name              = "storage"
                          + read_only         = false
                        }
                    }

                  + image_pull_secrets {
                      + name = (known after apply)
                    }

                  + readiness_gate {
                      + condition_type = (known after apply)
                    }

                  + volume {
                      + name = "storage"

                      + persistent_volume_claim {
                          + claim_name = "minio-pv-claim"
                          + read_only  = false
                        }
                    }
                }
            }
        }
    }

  # kubernetes_deployment.mozart will be created
  + resource "kubernetes_deployment" "mozart" {
      + id               = (known after apply)
      + wait_for_rollout = true

      + metadata {
          + generation       = (known after apply)
          + labels           = {
              + "app" = "mozart"
            }
          + name             = "mozart"
          + namespace        = "default"
          + resource_version = (known after apply)
          + uid              = (known after apply)
        }

      + spec {
          + min_ready_seconds         = 0
          + paused                    = false
          + progress_deadline_seconds = 600
          + replicas                  = (known after apply)
          + revision_history_limit    = 10

          + selector {
              + match_labels = {
                  + "app" = "mozart"
                }
            }

          + strategy {
              + type = (known after apply)

              + rolling_update {
                  + max_surge       = (known after apply)
                  + max_unavailable = (known after apply)
                }
            }

          + template {
              + metadata {
                  + generation       = (known after apply)
                  + labels           = {
                      + "app" = "mozart"
                    }
                  + name             = (known after apply)
                  + resource_version = (known after apply)
                  + uid              = (known after apply)
                }

              + spec {
                  + automount_service_account_token  = true
                  + dns_policy                       = "ClusterFirst"
                  + enable_service_links             = true
                  + host_ipc                         = false
                  + host_network                     = false
                  + host_pid                         = false
                  + hostname                         = (known after apply)
                  + node_name                        = (known after apply)
                  + restart_policy                   = "Always"
                  + service_account_name             = (known after apply)
                  + share_process_namespace          = false
                  + termination_grace_period_seconds = 30

                  + container {
                      + image                      = "hysds-mozart:unity-v0.0.1"
                      + image_pull_policy          = (known after apply)
                      + name                       = "mozart"
                      + stdin                      = false
                      + stdin_once                 = false
                      + termination_message_path   = "/dev/termination-log"
                      + termination_message_policy = (known after apply)
                      + tty                        = false

                      + port {
                          + container_port = 8888
                          + name           = "mozart"
                          + protocol       = "TCP"
                        }

                      + resources {
                          + limits   = (known after apply)
                          + requests = (known after apply)
                        }

                      + volume_mount {
                          + mount_path        = "/home/ops/mozart/settings.cfg"
                          + mount_propagation = "None"
                          + name              = "mozart-settings"
                          + read_only         = false
                          + sub_path          = "settings.cfg"
                        }
                      + volume_mount {
                          + mount_path        = "/home/ops/mozart/celeryconfig.py"
                          + mount_propagation = "None"
                          + name              = "celeryconfig"
                          + read_only         = false
                          + sub_path          = "celeryconfig.py"
                        }
                      + volume_mount {
                          + mount_path        = "/home/ops/.netrc"
                          + mount_propagation = "None"
                          + name              = "netrc"
                          + read_only         = false
                          + sub_path          = ".netrc"
                        }
                    }

                  + image_pull_secrets {
                      + name = (known after apply)
                    }

                  + readiness_gate {
                      + condition_type = (known after apply)
                    }

                  + volume {
                      + name = "mozart-settings"

                      + config_map {
                          + default_mode = "0644"
                          + name         = "mozart-settings"
                        }
                    }
                  + volume {
                      + name = "celeryconfig"

                      + config_map {
                          + default_mode = "0644"
                          + name         = "celeryconfig"
                        }
                    }
                  + volume {
                      + name = "netrc"

                      + config_map {
                          + default_mode = "0644"
                          + name         = "netrc"
                        }
                    }
                }
            }
        }
    }

  # kubernetes_deployment.orchestrator will be created
  + resource "kubernetes_deployment" "orchestrator" {
      + id               = (known after apply)
      + wait_for_rollout = true

      + metadata {
          + generation       = (known after apply)
          + labels           = {
              + "app" = "orchestrator"
            }
          + name             = "orchestrator"
          + namespace        = "default"
          + resource_version = (known after apply)
          + uid              = (known after apply)
        }

      + spec {
          + min_ready_seconds         = 0
          + paused                    = false
          + progress_deadline_seconds = 600
          + replicas                  = (known after apply)
          + revision_history_limit    = 10

          + selector {
              + match_labels = {
                  + "app" = "orchestrator"
                }
            }

          + strategy {
              + type = (known after apply)

              + rolling_update {
                  + max_surge       = (known after apply)
                  + max_unavailable = (known after apply)
                }
            }

          + template {
              + metadata {
                  + generation       = (known after apply)
                  + labels           = {
                      + "app" = "orchestrator"
                    }
                  + name             = (known after apply)
                  + resource_version = (known after apply)
                  + uid              = (known after apply)
                }

              + spec {
                  + automount_service_account_token  = true
                  + dns_policy                       = "ClusterFirst"
                  + enable_service_links             = true
                  + host_ipc                         = false
                  + host_network                     = false
                  + host_pid                         = false
                  + hostname                         = (known after apply)
                  + node_name                        = (known after apply)
                  + restart_policy                   = "Always"
                  + service_account_name             = (known after apply)
                  + share_process_namespace          = false
                  + termination_grace_period_seconds = 30

                  + container {
                      + command                    = [
                          + "supervisord",
                          + "--nodaemon",
                        ]
                      + image                      = "hysds-core:unity-v0.0.1"
                      + image_pull_policy          = (known after apply)
                      + name                       = "orchestrator"
                      + stdin                      = false
                      + stdin_once                 = false
                      + termination_message_path   = "/dev/termination-log"
                      + termination_message_policy = (known after apply)
                      + tty                        = false

                      + resources {
                          + limits   = (known after apply)
                          + requests = (known after apply)
                        }

                      + volume_mount {
                          + mount_path        = "/home/ops/factotum/celeryconfig.py"
                          + mount_propagation = "None"
                          + name              = "celeryconfig"
                          + read_only         = false
                          + sub_path          = "celeryconfig.py"
                        }
                      + volume_mount {
                          + mount_path        = "/etc/supervisord.conf"
                          + mount_propagation = "None"
                          + name              = "supervisord-orchestrator"
                          + read_only         = false
                          + sub_path          = "supervisord.conf"
                        }
                      + volume_mount {
                          + mount_path        = "/private/tmp/data"
                          + mount_propagation = "None"
                          + name              = "data-work"
                          + read_only         = false
                        }
                    }

                  + image_pull_secrets {
                      + name = (known after apply)
                    }

                  + readiness_gate {
                      + condition_type = (known after apply)
                    }

                  + security_context {
                      + run_as_group = "0"
                      + run_as_user  = "0"
                    }

                  + volume {
                      + name = "celeryconfig"

                      + config_map {
                          + default_mode = "0644"
                          + name         = "celeryconfig"
                        }
                    }
                  + volume {
                      + name = "supervisord-orchestrator"

                      + config_map {
                          + default_mode = "0644"
                          + name         = "supervisord-orchestrator"
                        }
                    }
                  + volume {
                      + name = "data-work"

                      + host_path {
                          + path = "/private/tmp/data"
                        }
                    }
                }
            }
        }
    }

  # kubernetes_deployment.redis will be created
  + resource "kubernetes_deployment" "redis" {
      + id               = (known after apply)
      + wait_for_rollout = true

      + metadata {
          + generation       = (known after apply)
          + labels           = {
              + "app" = "redis"
            }
          + name             = "redis"
          + namespace        = "default"
          + resource_version = (known after apply)
          + uid              = (known after apply)
        }

      + spec {
          + min_ready_seconds         = 0
          + paused                    = false
          + progress_deadline_seconds = 600
          + replicas                  = (known after apply)
          + revision_history_limit    = 10

          + selector {
              + match_labels = {
                  + "app" = "redis"
                }
            }

          + strategy {
              + type = (known after apply)

              + rolling_update {
                  + max_surge       = (known after apply)
                  + max_unavailable = (known after apply)
                }
            }

          + template {
              + metadata {
                  + generation       = (known after apply)
                  + labels           = {
                      + "app" = "redis"
                    }
                  + name             = (known after apply)
                  + resource_version = (known after apply)
                  + uid              = (known after apply)
                }

              + spec {
                  + automount_service_account_token  = true
                  + dns_policy                       = "ClusterFirst"
                  + enable_service_links             = true
                  + host_ipc                         = false
                  + host_network                     = false
                  + host_pid                         = false
                  + hostname                         = (known after apply)
                  + node_name                        = (known after apply)
                  + restart_policy                   = "Always"
                  + service_account_name             = (known after apply)
                  + share_process_namespace          = false
                  + termination_grace_period_seconds = 30

                  + container {
                      + image                      = "redis:latest"
                      + image_pull_policy          = "IfNotPresent"
                      + name                       = "redis"
                      + stdin                      = false
                      + stdin_once                 = false
                      + termination_message_path   = "/dev/termination-log"
                      + termination_message_policy = (known after apply)
                      + tty                        = false

                      + port {
                          + container_port = 6379
                          + protocol       = "TCP"
                        }

                      + resources {
                          + limits   = (known after apply)
                          + requests = (known after apply)
                        }
                    }

                  + image_pull_secrets {
                      + name = (known after apply)
                    }

                  + readiness_gate {
                      + condition_type = (known after apply)
                    }

                  + volume {
                      + name = (known after apply)

                      + aws_elastic_block_store {
                          + fs_type   = (known after apply)
                          + partition = (known after apply)
                          + read_only = (known after apply)
                          + volume_id = (known after apply)
                        }

                      + azure_disk {
                          + caching_mode  = (known after apply)
                          + data_disk_uri = (known after apply)
                          + disk_name     = (known after apply)
                          + fs_type       = (known after apply)
                          + kind          = (known after apply)
                          + read_only     = (known after apply)
                        }

                      + azure_file {
                          + read_only        = (known after apply)
                          + secret_name      = (known after apply)
                          + secret_namespace = (known after apply)
                          + share_name       = (known after apply)
                        }

                      + ceph_fs {
                          + monitors    = (known after apply)
                          + path        = (known after apply)
                          + read_only   = (known after apply)
                          + secret_file = (known after apply)
                          + user        = (known after apply)

                          + secret_ref {
                              + name      = (known after apply)
                              + namespace = (known after apply)
                            }
                        }

                      + cinder {
                          + fs_type   = (known after apply)
                          + read_only = (known after apply)
                          + volume_id = (known after apply)
                        }

                      + config_map {
                          + default_mode = (known after apply)
                          + name         = (known after apply)
                          + optional     = (known after apply)

                          + items {
                              + key  = (known after apply)
                              + mode = (known after apply)
                              + path = (known after apply)
                            }
                        }

                      + csi {
                          + driver            = (known after apply)
                          + fs_type           = (known after apply)
                          + read_only         = (known after apply)
                          + volume_attributes = (known after apply)
                          + volume_handle     = (known after apply)

                          + controller_expand_secret_ref {
                              + name      = (known after apply)
                              + namespace = (known after apply)
                            }

                          + controller_publish_secret_ref {
                              + name      = (known after apply)
                              + namespace = (known after apply)
                            }

                          + node_publish_secret_ref {
                              + name      = (known after apply)
                              + namespace = (known after apply)
                            }

                          + node_stage_secret_ref {
                              + name      = (known after apply)
                              + namespace = (known after apply)
                            }
                        }

                      + downward_api {
                          + default_mode = (known after apply)

                          + items {
                              + mode = (known after apply)
                              + path = (known after apply)

                              + field_ref {
                                  + api_version = (known after apply)
                                  + field_path  = (known after apply)
                                }

                              + resource_field_ref {
                                  + container_name = (known after apply)
                                  + divisor        = (known after apply)
                                  + resource       = (known after apply)
                                }
                            }
                        }

                      + empty_dir {
                          + medium     = (known after apply)
                          + size_limit = (known after apply)
                        }

                      + fc {
                          + fs_type      = (known after apply)
                          + lun          = (known after apply)
                          + read_only    = (known after apply)
                          + target_ww_ns = (known after apply)
                        }

                      + flex_volume {
                          + driver    = (known after apply)
                          + fs_type   = (known after apply)
                          + options   = (known after apply)
                          + read_only = (known after apply)

                          + secret_ref {
                              + name      = (known after apply)
                              + namespace = (known after apply)
                            }
                        }

                      + flocker {
                          + dataset_name = (known after apply)
                          + dataset_uuid = (known after apply)
                        }

                      + gce_persistent_disk {
                          + fs_type   = (known after apply)
                          + partition = (known after apply)
                          + pd_name   = (known after apply)
                          + read_only = (known after apply)
                        }

                      + git_repo {
                          + directory  = (known after apply)
                          + repository = (known after apply)
                          + revision   = (known after apply)
                        }

                      + glusterfs {
                          + endpoints_name = (known after apply)
                          + path           = (known after apply)
                          + read_only      = (known after apply)
                        }

                      + host_path {
                          + path = (known after apply)
                          + type = (known after apply)
                        }

                      + iscsi {
                          + fs_type         = (known after apply)
                          + iqn             = (known after apply)
                          + iscsi_interface = (known after apply)
                          + lun             = (known after apply)
                          + read_only       = (known after apply)
                          + target_portal   = (known after apply)
                        }

                      + local {
                          + path = (known after apply)
                        }

                      + nfs {
                          + path      = (known after apply)
                          + read_only = (known after apply)
                          + server    = (known after apply)
                        }

                      + persistent_volume_claim {
                          + claim_name = (known after apply)
                          + read_only  = (known after apply)
                        }

                      + photon_persistent_disk {
                          + fs_type = (known after apply)
                          + pd_id   = (known after apply)
                        }

                      + projected {
                          + default_mode = (known after apply)

                          + sources {
                              + config_map {
                                  + name     = (known after apply)
                                  + optional = (known after apply)

                                  + items {
                                      + key  = (known after apply)
                                      + mode = (known after apply)
                                      + path = (known after apply)
                                    }
                                }

                              + downward_api {
                                  + items {
                                      + mode = (known after apply)
                                      + path = (known after apply)

                                      + field_ref {
                                          + api_version = (known after apply)
                                          + field_path  = (known after apply)
                                        }

                                      + resource_field_ref {
                                          + container_name = (known after apply)
                                          + divisor        = (known after apply)
                                          + resource       = (known after apply)
                                        }
                                    }
                                }

                              + secret {
                                  + name     = (known after apply)
                                  + optional = (known after apply)

                                  + items {
                                      + key  = (known after apply)
                                      + mode = (known after apply)
                                      + path = (known after apply)
                                    }
                                }

                              + service_account_token {
                                  + audience           = (known after apply)
                                  + expiration_seconds = (known after apply)
                                  + path               = (known after apply)
                                }
                            }
                        }

                      + quobyte {
                          + group     = (known after apply)
                          + read_only = (known after apply)
                          + registry  = (known after apply)
                          + user      = (known after apply)
                          + volume    = (known after apply)
                        }

                      + rbd {
                          + ceph_monitors = (known after apply)
                          + fs_type       = (known after apply)
                          + keyring       = (known after apply)
                          + rados_user    = (known after apply)
                          + rbd_image     = (known after apply)
                          + rbd_pool      = (known after apply)
                          + read_only     = (known after apply)

                          + secret_ref {
                              + name      = (known after apply)
                              + namespace = (known after apply)
                            }
                        }

                      + secret {
                          + default_mode = (known after apply)
                          + optional     = (known after apply)
                          + secret_name  = (known after apply)

                          + items {
                              + key  = (known after apply)
                              + mode = (known after apply)
                              + path = (known after apply)
                            }
                        }

                      + vsphere_volume {
                          + fs_type     = (known after apply)
                          + volume_path = (known after apply)
                        }
                    }
                }
            }
        }
    }

  # kubernetes_deployment.user-rules will be created
  + resource "kubernetes_deployment" "user-rules" {
      + id               = (known after apply)
      + wait_for_rollout = true

      + metadata {
          + generation       = (known after apply)
          + labels           = {
              + "app" = "user-rules"
            }
          + name             = "user-rules"
          + namespace        = "default"
          + resource_version = (known after apply)
          + uid              = (known after apply)
        }

      + spec {
          + min_ready_seconds         = 0
          + paused                    = false
          + progress_deadline_seconds = 600
          + replicas                  = (known after apply)
          + revision_history_limit    = 10

          + selector {
              + match_labels = {
                  + "app" = "user-rules"
                }
            }

          + strategy {
              + type = (known after apply)

              + rolling_update {
                  + max_surge       = (known after apply)
                  + max_unavailable = (known after apply)
                }
            }

          + template {
              + metadata {
                  + generation       = (known after apply)
                  + labels           = {
                      + "app" = "user-rules"
                    }
                  + name             = (known after apply)
                  + resource_version = (known after apply)
                  + uid              = (known after apply)
                }

              + spec {
                  + automount_service_account_token  = true
                  + dns_policy                       = "ClusterFirst"
                  + enable_service_links             = true
                  + host_ipc                         = false
                  + host_network                     = false
                  + host_pid                         = false
                  + hostname                         = (known after apply)
                  + node_name                        = (known after apply)
                  + restart_policy                   = "Always"
                  + service_account_name             = (known after apply)
                  + share_process_namespace          = false
                  + termination_grace_period_seconds = 30

                  + container {
                      + command                    = [
                          + "supervisord",
                          + "--nodaemon",
                        ]
                      + image                      = "hysds-core:unity-v0.0.1"
                      + image_pull_policy          = (known after apply)
                      + name                       = "user-rules"
                      + stdin                      = false
                      + stdin_once                 = false
                      + termination_message_path   = "/dev/termination-log"
                      + termination_message_policy = (known after apply)
                      + tty                        = false

                      + resources {
                          + limits   = (known after apply)
                          + requests = (known after apply)
                        }

                      + volume_mount {
                          + mount_path        = "/home/ops/factotum/celeryconfig.py"
                          + mount_propagation = "None"
                          + name              = "celeryconfig"
                          + read_only         = false
                          + sub_path          = "celeryconfig.py"
                        }
                      + volume_mount {
                          + mount_path        = "/etc/supervisord.conf"
                          + mount_propagation = "None"
                          + name              = "supervisord-user-rules"
                          + read_only         = false
                          + sub_path          = "supervisord.conf"
                        }
                      + volume_mount {
                          + mount_path        = "/private/tmp/data"
                          + mount_propagation = "None"
                          + name              = "data-work"
                          + read_only         = false
                        }
                    }

                  + image_pull_secrets {
                      + name = (known after apply)
                    }

                  + readiness_gate {
                      + condition_type = (known after apply)
                    }

                  + security_context {
                      + run_as_group = "0"
                      + run_as_user  = "0"
                    }

                  + volume {
                      + name = "celeryconfig"

                      + config_map {
                          + default_mode = "0644"
                          + name         = "celeryconfig"
                        }
                    }
                  + volume {
                      + name = "supervisord-user-rules"

                      + config_map {
                          + default_mode = "0644"
                          + name         = "supervisord-user-rules"
                        }
                    }
                  + volume {
                      + name = "data-work"

                      + host_path {
                          + path = "/private/tmp/data"
                        }
                    }
                }
            }
        }
    }

  # kubernetes_persistent_volume_claim.minio-pv-claim will be created
  + resource "kubernetes_persistent_volume_claim" "minio-pv-claim" {
      + id               = (known after apply)
      + wait_until_bound = true

      + metadata {
          + generation       = (known after apply)
          + labels           = {
              + "app" = "minio-storage-claim"
            }
          + name             = "minio-pv-claim"
          + namespace        = "default"
          + resource_version = (known after apply)
          + uid              = (known after apply)
        }

      + spec {
          + access_modes       = [
              + "ReadWriteOnce",
            ]
          + storage_class_name = (known after apply)
          + volume_name        = (known after apply)

          + resources {
              + requests = {
                  + "storage" = "20Gi"
                }
            }
        }
    }

  # kubernetes_service.grq2_service will be created
  + resource "kubernetes_service" "grq2_service" {
      + id                     = (known after apply)
      + status                 = (known after apply)
      + wait_for_load_balancer = true

      + metadata {
          + generation       = (known after apply)
          + name             = "grq2"
          + namespace        = "default"
          + resource_version = (known after apply)
          + uid              = (known after apply)
        }

      + spec {
          + cluster_ip                  = (known after apply)
          + external_traffic_policy     = (known after apply)
          + health_check_node_port      = (known after apply)
          + publish_not_ready_addresses = false
          + selector                    = {
              + "app" = "grq2"
            }
          + session_affinity            = "ClientIP"
          + type                        = "LoadBalancer"

          + port {
              + node_port   = (known after apply)
              + port        = 8878
              + protocol    = "TCP"
              + target_port = "8878"
            }
        }
    }

  # kubernetes_service.hysds-ui_service will be created
  + resource "kubernetes_service" "hysds-ui_service" {
      + id                     = (known after apply)
      + status                 = (known after apply)
      + wait_for_load_balancer = true

      + metadata {
          + generation       = (known after apply)
          + name             = "hysds-ui"
          + namespace        = "default"
          + resource_version = (known after apply)
          + uid              = (known after apply)
        }

      + spec {
          + cluster_ip                  = (known after apply)
          + external_traffic_policy     = (known after apply)
          + health_check_node_port      = (known after apply)
          + publish_not_ready_addresses = false
          + selector                    = {
              + "app" = "hysds-ui"
            }
          + session_affinity            = "ClientIP"
          + type                        = "LoadBalancer"

          + port {
              + node_port   = 31000
              + port        = 3000
              + protocol    = "TCP"
              + target_port = "80"
            }
        }
    }

  # kubernetes_service.minio_service will be created
  + resource "kubernetes_service" "minio_service" {
      + id                     = (known after apply)
      + status                 = (known after apply)
      + wait_for_load_balancer = true

      + metadata {
          + generation       = (known after apply)
          + name             = "minio"
          + namespace        = "default"
          + resource_version = (known after apply)
          + uid              = (known after apply)
        }

      + spec {
          + cluster_ip                  = (known after apply)
          + external_traffic_policy     = (known after apply)
          + health_check_node_port      = (known after apply)
          + publish_not_ready_addresses = false
          + selector                    = {
              + "app" = "minio"
            }
          + session_affinity            = "ClientIP"
          + type                        = "LoadBalancer"

          + port {
              + name        = "minio-api"
              + node_port   = (known after apply)
              + port        = 9000
              + protocol    = "TCP"
              + target_port = "9000"
            }
          + port {
              + name        = "minio-interface"
              + node_port   = (known after apply)
              + port        = 9001
              + protocol    = "TCP"
              + target_port = (known after apply)
            }
        }
    }

  # kubernetes_service.mozart_service will be created
  + resource "kubernetes_service" "mozart_service" {
      + id                     = (known after apply)
      + status                 = (known after apply)
      + wait_for_load_balancer = true

      + metadata {
          + generation       = (known after apply)
          + name             = "mozart"
          + namespace        = "default"
          + resource_version = (known after apply)
          + uid              = (known after apply)
        }

      + spec {
          + cluster_ip                  = (known after apply)
          + external_traffic_policy     = (known after apply)
          + health_check_node_port      = (known after apply)
          + publish_not_ready_addresses = false
          + selector                    = {
              + "app" = "mozart"
            }
          + session_affinity            = "ClientIP"
          + type                        = "LoadBalancer"

          + port {
              + node_port   = (known after apply)
              + port        = 8888
              + protocol    = "TCP"
              + target_port = "8888"
            }
        }
    }

  # kubernetes_service.rabbitmq_mgmt_service will be created
  + resource "kubernetes_service" "rabbitmq_mgmt_service" {
      + id                     = (known after apply)
      + status                 = (known after apply)
      + wait_for_load_balancer = true

      + metadata {
          + generation       = (known after apply)
          + name             = "rabbitmq-mgmt"
          + namespace        = "default"
          + resource_version = (known after apply)
          + uid              = (known after apply)
        }

      + spec {
          + cluster_ip                  = (known after apply)
          + external_traffic_policy     = (known after apply)
          + health_check_node_port      = (known after apply)
          + publish_not_ready_addresses = false
          + selector                    = {
              + "app" = "rabbitmq"
            }
          + session_affinity            = "ClientIP"
          + type                        = "LoadBalancer"

          + port {
              + name        = "cluster-rpc"
              + node_port   = (known after apply)
              + port        = 15672
              + protocol    = "TCP"
              + target_port = "15672"
            }
        }
    }

  # kubernetes_service.rabbitmq_service will be created
  + resource "kubernetes_service" "rabbitmq_service" {
      + id                     = (known after apply)
      + status                 = (known after apply)
      + wait_for_load_balancer = true

      + metadata {
          + generation       = (known after apply)
          + name             = "rabbitmq"
          + namespace        = "default"
          + resource_version = (known after apply)
          + uid              = (known after apply)
        }

      + spec {
          + cluster_ip                  = (known after apply)
          + external_traffic_policy     = (known after apply)
          + health_check_node_port      = (known after apply)
          + publish_not_ready_addresses = false
          + selector                    = {
              + "app" = "rabbitmq"
            }
          + session_affinity            = "ClientIP"
          + type                        = "NodePort"

          + port {
              + name        = "epmd"
              + node_port   = (known after apply)
              + port        = 4369
              + protocol    = "TCP"
              + target_port = "4369"
            }
          + port {
              + name        = "listener"
              + node_port   = (known after apply)
              + port        = 5672
              + protocol    = "TCP"
              + target_port = "5672"
            }
          + port {
              + name        = "cluster-rpc"
              + node_port   = (known after apply)
              + port        = 15672
              + protocol    = "TCP"
              + target_port = "15672"
            }
        }
    }

  # kubernetes_service.redis_service will be created
  + resource "kubernetes_service" "redis_service" {
      + id                     = (known after apply)
      + status                 = (known after apply)
      + wait_for_load_balancer = true

      + metadata {
          + generation       = (known after apply)
          + name             = "redis"
          + namespace        = "default"
          + resource_version = (known after apply)
          + uid              = (known after apply)
        }

      + spec {
          + cluster_ip                  = (known after apply)
          + external_traffic_policy     = (known after apply)
          + health_check_node_port      = (known after apply)
          + publish_not_ready_addresses = false
          + selector                    = {
              + "app" = "redis"
            }
          + session_affinity            = "ClientIP"
          + type                        = "NodePort"

          + port {
              + node_port   = (known after apply)
              + port        = 6379
              + protocol    = "TCP"
              + target_port = "6379"
            }
        }
    }

  # kubernetes_stateful_set.rabbitmq_statefulset will be created
  + resource "kubernetes_stateful_set" "rabbitmq_statefulset" {
      + id               = (known after apply)
      + wait_for_rollout = true

      + metadata {
          + generation       = (known after apply)
          + name             = "rabbitmq"
          + namespace        = "default"
          + resource_version = (known after apply)
          + uid              = (known after apply)
        }

      + spec {
          + pod_management_policy  = (known after apply)
          + replicas               = (known after apply)
          + revision_history_limit = (known after apply)
          + service_name           = "rabbitmq"

          + selector {
              + match_labels = {
                  + "app" = "rabbitmq"
                }
            }

          + template {
              + metadata {
                  + generation       = (known after apply)
                  + labels           = {
                      + "app" = "rabbitmq"
                    }
                  + name             = (known after apply)
                  + resource_version = (known after apply)
                  + uid              = (known after apply)
                }

              + spec {
                  + automount_service_account_token  = true
                  + dns_policy                       = "ClusterFirst"
                  + enable_service_links             = true
                  + host_ipc                         = false
                  + host_network                     = false
                  + host_pid                         = false
                  + hostname                         = (known after apply)
                  + node_name                        = (known after apply)
                  + restart_policy                   = "Always"
                  + service_account_name             = (known after apply)
                  + share_process_namespace          = false
                  + termination_grace_period_seconds = 30

                  + container {
                      + image                      = "rabbitmq:3-management"
                      + image_pull_policy          = (known after apply)
                      + name                       = "rabbitmq"
                      + stdin                      = false
                      + stdin_once                 = false
                      + termination_message_path   = "/dev/termination-log"
                      + termination_message_policy = (known after apply)
                      + tty                        = false

                      + env {
                          + name  = "RABBITMQ_ERLANG_COOKIE"
                          + value = "1WqgH8N2v1qDBDZDbNy8Bg9IkPWLEpu79m6q+0t36lQ="
                        }

                      + resources {
                          + limits   = (known after apply)
                          + requests = (known after apply)
                        }

                      + volume_mount {
                          + mount_path        = "/var/lib/rabbitmq"
                          + mount_propagation = "None"
                          + name              = "rabbitmq-data"
                          + read_only         = false
                        }
                    }

                  + image_pull_secrets {
                      + name = (known after apply)
                    }

                  + readiness_gate {
                      + condition_type = (known after apply)
                    }

                  + volume {
                      + name = "rabbitmq-data"

                      + host_path {
                          + path = "/data/rabbitmq"
                          + type = "DirectoryOrCreate"
                        }
                    }
                }
            }
        }
    }

Plan: 30 to add, 0 to change, 0 to destroy.

Do you want to perform these actions?
  Terraform will perform the actions described above.
  Only 'yes' will be accepted to approve.

  Enter a value:
2022-03-21T09:49:24.740-0700 [INFO]  backend/local: apply calling Apply
2022-03-21T09:49:24.745-0700 [INFO]  ReferenceTransformer: reference not found: "path.module"
2022-03-21T09:49:24.745-0700 [INFO]  ReferenceTransformer: reference not found: "path.module"
2022-03-21T09:49:24.746-0700 [INFO]  ReferenceTransformer: reference not found: "path.module"
2022-03-21T09:49:24.746-0700 [INFO]  ReferenceTransformer: reference not found: "path.module"
2022-03-21T09:49:24.746-0700 [INFO]  ReferenceTransformer: reference not found: "path.module"
2022-03-21T09:49:24.747-0700 [INFO]  ReferenceTransformer: reference not found: "path.module"
2022-03-21T09:49:24.747-0700 [INFO]  ReferenceTransformer: reference not found: "path.module"
2022-03-21T09:49:24.747-0700 [INFO]  ReferenceTransformer: reference not found: "path.module"
2022-03-21T09:49:24.747-0700 [INFO]  ReferenceTransformer: reference not found: "path.module"
2022-03-21T09:49:24.747-0700 [INFO]  ReferenceTransformer: reference not found: "path.module"
2022-03-21T09:49:24.747-0700 [INFO]  ReferenceTransformer: reference not found: "path.module"
2022-03-21T09:49:24.747-0700 [INFO]  ReferenceTransformer: reference not found: "path.module"
2022-03-21T09:49:24.747-0700 [INFO]  ReferenceTransformer: reference not found: "path.module"
2022-03-21T09:49:24.747-0700 [INFO]  ReferenceTransformer: reference not found: "path.module"
2022-03-21T09:49:24.747-0700 [INFO]  ReferenceTransformer: reference not found: "path.module"
2022-03-21T09:49:24.748-0700 [INFO]  ReferenceTransformer: reference not found: "path.module"
2022-03-21T09:49:24.748-0700 [INFO]  ReferenceTransformer: reference not found: "path.module"
2022-03-21T09:49:24.753-0700 [INFO]  provider: configuring client automatic mTLS
2022-03-21T09:49:24.839-0700 [INFO]  provider.terraform-provider-kubernetes_v2.8.0_x5: configuring server automatic mTLS: timestamp=2022-03-21T09:49:24.838-0700
2022-03-21T09:49:24.906-0700 [INFO]  provider: configuring client automatic mTLS
2022-03-21T09:49:24.967-0700 [INFO]  provider.terraform-provider-helm_v2.4.1_x5: configuring server automatic mTLS: timestamp=2022-03-21T09:49:24.964-0700
2022-03-21T09:49:25.065-0700 [WARN]  ValidateProviderConfig from "provider[\"registry.terraform.io/hashicorp/kubernetes\"]" changed the config value, but that value is unused
2022-03-21T09:49:25.106-0700 [WARN]  ValidateProviderConfig from "provider[\"registry.terraform.io/hashicorp/helm\"]" changed the config value, but that value is unused
2022-03-21T09:49:25.110-0700 [INFO]  provider.terraform-provider-helm_v2.4.1_x5: 2022/03/21 09:49:25 [DEBUG] Experiments enabled: []: timestamp=2022-03-21T09:49:25.109-0700
2022-03-21T09:49:25.124-0700 [WARN]  Provider "registry.terraform.io/hashicorp/kubernetes" produced an invalid plan for kubernetes_config_map.supervisord-job-worker, but we are tolerating it because it is using the legacy plugin SDK.
    The following problems may be the cause of any confusing errors from downstream operations:
      - .metadata[0].namespace: planned value cty.StringVal("default") for a non-computed attribute
kubernetes_config_map.supervisord-job-worker: Creating...
2022-03-21T09:49:25.127-0700 [INFO]  Starting apply for kubernetes_config_map.supervisord-job-worker
2022-03-21T09:49:25.132-0700 [WARN]  Provider "registry.terraform.io/hashicorp/kubernetes" produced an invalid plan for kubernetes_config_map.grq2-settings, but we are tolerating it because it is using the legacy plugin SDK.
    The following problems may be the cause of any confusing errors from downstream operations:
      - .metadata[0].namespace: planned value cty.StringVal("default") for a non-computed attribute
kubernetes_config_map.grq2-settings: Creating...
2022-03-21T09:49:25.141-0700 [INFO]  Starting apply for kubernetes_config_map.grq2-settings
2022-03-21T09:49:25.174-0700 [INFO]  provider.terraform-provider-helm_v2.4.1_x5: 2022/03/21 09:49:25 [DEBUG] [resourceDiff: mozart-es] Start: timestamp=2022-03-21T09:49:25.147-0700
2022-03-21T09:49:25.192-0700 [WARN]  Provider "registry.terraform.io/hashicorp/kubernetes" produced an invalid plan for kubernetes_config_map.supervisord-orchestrator, but we are tolerating it because it is using the legacy plugin SDK.
    The following problems may be the cause of any confusing errors from downstream operations:
      - .metadata[0].namespace: planned value cty.StringVal("default") for a non-computed attribute
kubernetes_config_map.supervisord-orchestrator: Creating...
2022-03-21T09:49:25.193-0700 [INFO]  Starting apply for kubernetes_config_map.supervisord-orchestrator
2022-03-21T09:49:25.194-0700 [WARN]  Provider "registry.terraform.io/hashicorp/kubernetes" produced an invalid plan for kubernetes_service.grq2_service, but we are tolerating it because it is using the legacy plugin SDK.
    The following problems may be the cause of any confusing errors from downstream operations:
      - .wait_for_load_balancer: planned value cty.True for a non-computed attribute
      - .metadata[0].namespace: planned value cty.StringVal("default") for a non-computed attribute
      - .spec[0].publish_not_ready_addresses: planned value cty.False for a non-computed attribute
      - .spec[0].port[0].protocol: planned value cty.StringVal("TCP") for a non-computed attribute
kubernetes_service.grq2_service: Creating...
2022-03-21T09:49:25.195-0700 [INFO]  Starting apply for kubernetes_service.grq2_service
2022-03-21T09:49:25.196-0700 [WARN]  Provider "registry.terraform.io/hashicorp/kubernetes" produced an invalid plan for kubernetes_config_map.netrc, but we are tolerating it because it is using the legacy plugin SDK.
    The following problems may be the cause of any confusing errors from downstream operations:
      - .metadata[0].namespace: planned value cty.StringVal("default") for a non-computed attribute
kubernetes_config_map.netrc: Creating...
2022-03-21T09:49:25.197-0700 [INFO]  Starting apply for kubernetes_config_map.netrc
2022-03-21T09:49:25.217-0700 [WARN]  Provider "registry.terraform.io/hashicorp/kubernetes" produced an invalid plan for kubernetes_service.hysds-ui_service, but we are tolerating it because it is using the legacy plugin SDK.
    The following problems may be the cause of any confusing errors from downstream operations:
      - .wait_for_load_balancer: planned value cty.True for a non-computed attribute
      - .metadata[0].namespace: planned value cty.StringVal("default") for a non-computed attribute
      - .spec[0].publish_not_ready_addresses: planned value cty.False for a non-computed attribute
kubernetes_service.hysds-ui_service: Creating...
2022-03-21T09:49:25.221-0700 [INFO]  Starting apply for kubernetes_service.hysds-ui_service
2022-03-21T09:49:25.257-0700 [WARN]  Provider "registry.terraform.io/hashicorp/kubernetes" produced an invalid plan for kubernetes_deployment.grq2, but we are tolerating it because it is using the legacy plugin SDK.
    The following problems may be the cause of any confusing errors from downstream operations:
      - .wait_for_rollout: planned value cty.True for a non-computed attribute
      - .metadata[0].namespace: planned value cty.StringVal("default") for a non-computed attribute
      - .spec[0].progress_deadline_seconds: planned value cty.NumberIntVal(600) for a non-computed attribute
      - .spec[0].revision_history_limit: planned value cty.NumberIntVal(10) for a non-computed attribute
      - .spec[0].min_ready_seconds: planned value cty.NumberIntVal(0) for a non-computed attribute
      - .spec[0].paused: planned value cty.False for a non-computed attribute
      - .spec[0].template[0].spec[0].enable_service_links: planned value cty.True for a non-computed attribute
      - .spec[0].template[0].spec[0].host_ipc: planned value cty.False for a non-computed attribute
      - .spec[0].template[0].spec[0].host_pid: planned value cty.False for a non-computed attribute
      - .spec[0].template[0].spec[0].restart_policy: planned value cty.StringVal("Always") for a non-computed attribute
      - .spec[0].template[0].spec[0].share_process_namespace: planned value cty.False for a non-computed attribute
      - .spec[0].template[0].spec[0].dns_policy: planned value cty.StringVal("ClusterFirst") for a non-computed attribute
      - .spec[0].template[0].spec[0].automount_service_account_token: planned value cty.True for a non-computed attribute
      - .spec[0].template[0].spec[0].host_network: planned value cty.False for a non-computed attribute
      - .spec[0].template[0].spec[0].termination_grace_period_seconds: planned value cty.NumberIntVal(30) for a non-computed attribute
      - .spec[0].template[0].spec[0].container[0].stdin: planned value cty.False for a non-computed attribute
      - .spec[0].template[0].spec[0].container[0].stdin_once: planned value cty.False for a non-computed attribute
      - .spec[0].template[0].spec[0].container[0].termination_message_path: planned value cty.StringVal("/dev/termination-log") for a non-computed attribute
      - .spec[0].template[0].spec[0].container[0].tty: planned value cty.False for a non-computed attribute
      - .spec[0].template[0].spec[0].container[0].resources: attribute representing nested block must not be unknown itself; set nested attribute values to unknown instead
      - .spec[0].template[0].spec[0].container[0].port[0].protocol: planned value cty.StringVal("TCP") for a non-computed attribute
      - .spec[0].template[0].spec[0].container[0].volume_mount[0].mount_propagation: planned value cty.StringVal("None") for a non-computed attribute
      - .spec[0].template[0].spec[0].container[0].volume_mount[1].mount_propagation: planned value cty.StringVal("None") for a non-computed attribute
      - .spec[0].template[0].spec[0].container[0].volume_mount[2].mount_propagation: planned value cty.StringVal("None") for a non-computed attribute
      - .spec[0].template[0].spec[0].readiness_gate: attribute representing nested block must not be unknown itself; set nested attribute values to unknown instead
      - .spec[0].template[0].spec[0].volume[0].config_map[0].default_mode: planned value cty.StringVal("0644") for a non-computed attribute
      - .spec[0].template[0].spec[0].volume[1].config_map[0].default_mode: planned value cty.StringVal("0644") for a non-computed attribute
      - .spec[0].template[0].spec[0].volume[2].config_map[0].default_mode: planned value cty.StringVal("0644") for a non-computed attribute
      - .spec[0].template[0].spec[0].image_pull_secrets: attribute representing nested block must not be unknown itself; set nested attribute values to unknown instead
      - .spec[0].strategy: attribute representing nested block must not be unknown itself; set nested attribute values to unknown instead
kubernetes_deployment.grq2: Creating...
2022-03-21T09:49:25.261-0700 [INFO]  Starting apply for kubernetes_deployment.grq2
2022-03-21T09:49:25.265-0700 [WARN]  Provider "registry.terraform.io/hashicorp/kubernetes" produced an invalid plan for kubernetes_deployment.redis, but we are tolerating it because it is using the legacy plugin SDK.
    The following problems may be the cause of any confusing errors from downstream operations:
      - .wait_for_rollout: planned value cty.True for a non-computed attribute
      - .metadata[0].namespace: planned value cty.StringVal("default") for a non-computed attribute
      - .spec[0].progress_deadline_seconds: planned value cty.NumberIntVal(600) for a non-computed attribute
      - .spec[0].revision_history_limit: planned value cty.NumberIntVal(10) for a non-computed attribute
      - .spec[0].min_ready_seconds: planned value cty.NumberIntVal(0) for a non-computed attribute
      - .spec[0].paused: planned value cty.False for a non-computed attribute
      - .spec[0].strategy: attribute representing nested block must not be unknown itself; set nested attribute values to unknown instead
      - .spec[0].template[0].spec[0].automount_service_account_token: planned value cty.True for a non-computed attribute
      - .spec[0].template[0].spec[0].termination_grace_period_seconds: planned value cty.NumberIntVal(30) for a non-computed attribute
      - .spec[0].template[0].spec[0].host_network: planned value cty.False for a non-computed attribute
      - .spec[0].template[0].spec[0].host_ipc: planned value cty.False for a non-computed attribute
      - .spec[0].template[0].spec[0].host_pid: planned value cty.False for a non-computed attribute
      - .spec[0].template[0].spec[0].restart_policy: planned value cty.StringVal("Always") for a non-computed attribute
      - .spec[0].template[0].spec[0].share_process_namespace: planned value cty.False for a non-computed attribute
      - .spec[0].template[0].spec[0].enable_service_links: planned value cty.True for a non-computed attribute
      - .spec[0].template[0].spec[0].dns_policy: planned value cty.StringVal("ClusterFirst") for a non-computed attribute
      - .spec[0].template[0].spec[0].container[0].stdin_once: planned value cty.False for a non-computed attribute
      - .spec[0].template[0].spec[0].container[0].termination_message_path: planned value cty.StringVal("/dev/termination-log") for a non-computed attribute
      - .spec[0].template[0].spec[0].container[0].tty: planned value cty.False for a non-computed attribute
      - .spec[0].template[0].spec[0].container[0].stdin: planned value cty.False for a non-computed attribute
      - .spec[0].template[0].spec[0].container[0].port[0].protocol: planned value cty.StringVal("TCP") for a non-computed attribute
      - .spec[0].template[0].spec[0].container[0].resources: attribute representing nested block must not be unknown itself; set nested attribute values to unknown instead
      - .spec[0].template[0].spec[0].image_pull_secrets: attribute representing nested block must not be unknown itself; set nested attribute values to unknown instead
      - .spec[0].template[0].spec[0].readiness_gate: attribute representing nested block must not be unknown itself; set nested attribute values to unknown instead
      - .spec[0].template[0].spec[0].volume: attribute representing nested block must not be unknown itself; set nested attribute values to unknown instead
kubernetes_deployment.redis: Creating...
2022-03-21T09:49:25.265-0700 [INFO]  Starting apply for kubernetes_deployment.redis
2022-03-21T09:49:25.358-0700 [WARN]  Provider "registry.terraform.io/hashicorp/kubernetes" produced an invalid plan for kubernetes_deployment.factotum-job-worker, but we are tolerating it because it is using the legacy plugin SDK.
    The following problems may be the cause of any confusing errors from downstream operations:
      - .wait_for_rollout: planned value cty.True for a non-computed attribute
      - .metadata[0].namespace: planned value cty.StringVal("default") for a non-computed attribute
      - .spec[0].min_ready_seconds: planned value cty.NumberIntVal(0) for a non-computed attribute
      - .spec[0].paused: planned value cty.False for a non-computed attribute
      - .spec[0].progress_deadline_seconds: planned value cty.NumberIntVal(600) for a non-computed attribute
      - .spec[0].revision_history_limit: planned value cty.NumberIntVal(10) for a non-computed attribute
      - .spec[0].strategy: attribute representing nested block must not be unknown itself; set nested attribute values to unknown instead
      - .spec[0].template[0].spec[0].restart_policy: planned value cty.StringVal("Always") for a non-computed attribute
      - .spec[0].template[0].spec[0].share_process_namespace: planned value cty.False for a non-computed attribute
      - .spec[0].template[0].spec[0].enable_service_links: planned value cty.True for a non-computed attribute
      - .spec[0].template[0].spec[0].host_ipc: planned value cty.False for a non-computed attribute
      - .spec[0].template[0].spec[0].host_pid: planned value cty.False for a non-computed attribute
      - .spec[0].template[0].spec[0].dns_policy: planned value cty.StringVal("ClusterFirst") for a non-computed attribute
      - .spec[0].template[0].spec[0].automount_service_account_token: planned value cty.True for a non-computed attribute
      - .spec[0].template[0].spec[0].host_network: planned value cty.False for a non-computed attribute
      - .spec[0].template[0].spec[0].termination_grace_period_seconds: planned value cty.NumberIntVal(30) for a non-computed attribute
      - .spec[0].template[0].spec[0].volume[1].config_map[0].default_mode: planned value cty.StringVal("0644") for a non-computed attribute
      - .spec[0].template[0].spec[0].volume[2].config_map[0].default_mode: planned value cty.StringVal("0644") for a non-computed attribute
      - .spec[0].template[0].spec[0].volume[3].config_map[0].default_mode: planned value cty.StringVal("0644") for a non-computed attribute
      - .spec[0].template[0].spec[0].volume[4].config_map[0].default_mode: planned value cty.StringVal("0644") for a non-computed attribute
      - .spec[0].template[0].spec[0].image_pull_secrets: attribute representing nested block must not be unknown itself; set nested attribute values to unknown instead
      - .spec[0].template[0].spec[0].init_container[0].termination_message_path: planned value cty.StringVal("/dev/termination-log") for a non-computed attribute
      - .spec[0].template[0].spec[0].init_container[0].stdin_once: planned value cty.False for a non-computed attribute
      - .spec[0].template[0].spec[0].init_container[0].tty: planned value cty.False for a non-computed attribute
      - .spec[0].template[0].spec[0].init_container[0].stdin: planned value cty.False for a non-computed attribute
      - .spec[0].template[0].spec[0].init_container[0].resources: attribute representing nested block must not be unknown itself; set nested attribute values to unknown instead
      - .spec[0].template[0].spec[0].init_container[0].volume_mount[0].mount_propagation: planned value cty.StringVal("None") for a non-computed attribute
      - .spec[0].template[0].spec[0].init_container[0].volume_mount[0].read_only: planned value cty.False for a non-computed attribute
      - .spec[0].template[0].spec[0].init_container[0].volume_mount[1].mount_propagation: planned value cty.StringVal("None") for a non-computed attribute
      - .spec[0].template[0].spec[0].init_container[0].volume_mount[1].read_only: planned value cty.False for a non-computed attribute
      - .spec[0].template[0].spec[0].readiness_gate: attribute representing nested block must not be unknown itself; set nested attribute values to unknown instead
      - .spec[0].template[0].spec[0].container[0].stdin: planned value cty.False for a non-computed attribute
      - .spec[0].template[0].spec[0].container[0].tty: planned value cty.False for a non-computed attribute
      - .spec[0].template[0].spec[0].container[0].stdin_once: planned value cty.False for a non-computed attribute
      - .spec[0].template[0].spec[0].container[0].termination_message_path: planned value cty.StringVal("/dev/termination-log") for a non-computed attribute
      - .spec[0].template[0].spec[0].container[0].resources: attribute representing nested block must not be unknown itself; set nested attribute values to unknown instead
      - .spec[0].template[0].spec[0].container[0].volume_mount[0].mount_propagation: planned value cty.StringVal("None") for a non-computed attribute
      - .spec[0].template[0].spec[0].container[0].volume_mount[1].mount_propagation: planned value cty.StringVal("None") for a non-computed attribute
      - .spec[0].template[0].spec[0].container[0].volume_mount[2].mount_propagation: planned value cty.StringVal("None") for a non-computed attribute
      - .spec[0].template[0].spec[0].container[0].volume_mount[3].mount_propagation: planned value cty.StringVal("None") for a non-computed attribute
      - .spec[0].template[0].spec[0].container[0].volume_mount[4].mount_propagation: planned value cty.StringVal("None") for a non-computed attribute
      - .spec[0].template[0].spec[0].container[0].volume_mount[5].mount_propagation: planned value cty.StringVal("None") for a non-computed attribute
kubernetes_deployment.factotum-job-worker: Creating...
2022-03-21T09:49:25.360-0700 [INFO]  Starting apply for kubernetes_deployment.factotum-job-worker
2022-03-21T09:49:25.423-0700 [WARN]  Provider "provider[\"registry.terraform.io/hashicorp/kubernetes\"]" produced an unexpected new value for kubernetes_config_map.grq2-settings, but we are tolerating it because it is using the legacy plugin SDK.
    The following problems may be the cause of any confusing errors from downstream operations:
      - .metadata[0].generate_name: was null, but now cty.StringVal("")
kubernetes_config_map.grq2-settings: Creation complete after 0s [id=default/grq2-settings]
2022-03-21T09:49:25.427-0700 [WARN]  Provider "provider[\"registry.terraform.io/hashicorp/kubernetes\"]" produced an unexpected new value for kubernetes_config_map.supervisord-job-worker, but we are tolerating it because it is using the legacy plugin SDK.
    The following problems may be the cause of any confusing errors from downstream operations:
      - .metadata[0].generate_name: was null, but now cty.StringVal("")
kubernetes_config_map.supervisord-job-worker: Creation complete after 0s [id=default/supervisord-job-worker]
2022-03-21T09:49:25.478-0700 [INFO]  provider.terraform-provider-helm_v2.4.1_x5: 2022/03/21 09:49:25 [DEBUG] [resourceDiff: grq2-es] Start: timestamp=2022-03-21T09:49:25.478-0700
2022-03-21T09:49:25.543-0700 [WARN]  Provider "registry.terraform.io/hashicorp/kubernetes" produced an invalid plan for kubernetes_service.rabbitmq_mgmt_service, but we are tolerating it because it is using the legacy plugin SDK.
    The following problems may be the cause of any confusing errors from downstream operations:
      - .wait_for_load_balancer: planned value cty.True for a non-computed attribute
      - .metadata[0].namespace: planned value cty.StringVal("default") for a non-computed attribute
      - .spec[0].publish_not_ready_addresses: planned value cty.False for a non-computed attribute
      - .spec[0].port[0].protocol: planned value cty.StringVal("TCP") for a non-computed attribute
kubernetes_service.rabbitmq_mgmt_service: Creating...
2022-03-21T09:49:25.543-0700 [INFO]  Starting apply for kubernetes_service.rabbitmq_mgmt_service
2022-03-21T09:49:25.580-0700 [WARN]  Provider "provider[\"registry.terraform.io/hashicorp/kubernetes\"]" produced an unexpected new value for kubernetes_config_map.netrc, but we are tolerating it because it is using the legacy plugin SDK.
    The following problems may be the cause of any confusing errors from downstream operations:
      - .metadata[0].generate_name: was null, but now cty.StringVal("")
2022-03-21T09:49:25.580-0700 [WARN]  Provider "provider[\"registry.terraform.io/hashicorp/kubernetes\"]" produced an unexpected new value for kubernetes_config_map.supervisord-orchestrator, but we are tolerating it because it is using the legacy plugin SDK.
    The following problems may be the cause of any confusing errors from downstream operations:
      - .metadata[0].generate_name: was null, but now cty.StringVal("")
kubernetes_config_map.netrc: Creation complete after 1s [id=default/netrc]
kubernetes_config_map.supervisord-orchestrator: Creation complete after 1s [id=default/supervisord-orchestrator]
2022-03-21T09:49:25.594-0700 [WARN]  Provider "registry.terraform.io/hashicorp/kubernetes" produced an invalid plan for kubernetes_service.redis_service, but we are tolerating it because it is using the legacy plugin SDK.
    The following problems may be the cause of any confusing errors from downstream operations:
      - .wait_for_load_balancer: planned value cty.True for a non-computed attribute
      - .metadata[0].namespace: planned value cty.StringVal("default") for a non-computed attribute
      - .spec[0].publish_not_ready_addresses: planned value cty.False for a non-computed attribute
      - .spec[0].port[0].protocol: planned value cty.StringVal("TCP") for a non-computed attribute
kubernetes_service.redis_service: Creating...
2022-03-21T09:49:25.597-0700 [INFO]  Starting apply for kubernetes_service.redis_service
2022-03-21T09:49:25.701-0700 [WARN]  Provider "registry.terraform.io/hashicorp/kubernetes" produced an invalid plan for kubernetes_deployment.logstash, but we are tolerating it because it is using the legacy plugin SDK.
    The following problems may be the cause of any confusing errors from downstream operations:
      - .wait_for_rollout: planned value cty.True for a non-computed attribute
      - .metadata[0].namespace: planned value cty.StringVal("default") for a non-computed attribute
      - .spec[0].paused: planned value cty.False for a non-computed attribute
      - .spec[0].progress_deadline_seconds: planned value cty.NumberIntVal(600) for a non-computed attribute
      - .spec[0].revision_history_limit: planned value cty.NumberIntVal(10) for a non-computed attribute
      - .spec[0].min_ready_seconds: planned value cty.NumberIntVal(0) for a non-computed attribute
      - .spec[0].strategy: attribute representing nested block must not be unknown itself; set nested attribute values to unknown instead
      - .spec[0].template[0].spec[0].host_network: planned value cty.False for a non-computed attribute
      - .spec[0].template[0].spec[0].termination_grace_period_seconds: planned value cty.NumberIntVal(30) for a non-computed attribute
      - .spec[0].template[0].spec[0].restart_policy: planned value cty.StringVal("Always") for a non-computed attribute
      - .spec[0].template[0].spec[0].share_process_namespace: planned value cty.False for a non-computed attribute
      - .spec[0].template[0].spec[0].enable_service_links: planned value cty.True for a non-computed attribute
      - .spec[0].template[0].spec[0].host_ipc: planned value cty.False for a non-computed attribute
      - .spec[0].template[0].spec[0].host_pid: planned value cty.False for a non-computed attribute
      - .spec[0].template[0].spec[0].dns_policy: planned value cty.StringVal("ClusterFirst") for a non-computed attribute
      - .spec[0].template[0].spec[0].automount_service_account_token: planned value cty.True for a non-computed attribute
      - .spec[0].template[0].spec[0].image_pull_secrets: attribute representing nested block must not be unknown itself; set nested attribute values to unknown instead
      - .spec[0].template[0].spec[0].readiness_gate: attribute representing nested block must not be unknown itself; set nested attribute values to unknown instead
      - .spec[0].template[0].spec[0].volume[0].config_map[0].default_mode: planned value cty.StringVal("0644") for a non-computed attribute
      - .spec[0].template[0].spec[0].volume[1].config_map[0].default_mode: planned value cty.StringVal("0644") for a non-computed attribute
      - .spec[0].template[0].spec[0].volume[2].config_map[0].default_mode: planned value cty.StringVal("0644") for a non-computed attribute
      - .spec[0].template[0].spec[0].volume[3].config_map[0].default_mode: planned value cty.StringVal("0644") for a non-computed attribute
      - .spec[0].template[0].spec[0].volume[4].config_map[0].default_mode: planned value cty.StringVal("0644") for a non-computed attribute
      - .spec[0].template[0].spec[0].volume[5].config_map[0].default_mode: planned value cty.StringVal("0644") for a non-computed attribute
      - .spec[0].template[0].spec[0].container[0].stdin_once: planned value cty.False for a non-computed attribute
      - .spec[0].template[0].spec[0].container[0].termination_message_path: planned value cty.StringVal("/dev/termination-log") for a non-computed attribute
      - .spec[0].template[0].spec[0].container[0].tty: planned value cty.False for a non-computed attribute
      - .spec[0].template[0].spec[0].container[0].stdin: planned value cty.False for a non-computed attribute
      - .spec[0].template[0].spec[0].container[0].volume_mount[0].mount_propagation: planned value cty.StringVal("None") for a non-computed attribute
      - .spec[0].template[0].spec[0].container[0].volume_mount[1].mount_propagation: planned value cty.StringVal("None") for a non-computed attribute
      - .spec[0].template[0].spec[0].container[0].volume_mount[2].mount_propagation: planned value cty.StringVal("None") for a non-computed attribute
      - .spec[0].template[0].spec[0].container[0].volume_mount[3].mount_propagation: planned value cty.StringVal("None") for a non-computed attribute
      - .spec[0].template[0].spec[0].container[0].volume_mount[4].mount_propagation: planned value cty.StringVal("None") for a non-computed attribute
      - .spec[0].template[0].spec[0].container[0].volume_mount[5].mount_propagation: planned value cty.StringVal("None") for a non-computed attribute
      - .spec[0].template[0].spec[0].container[0].resources: attribute representing nested block must not be unknown itself; set nested attribute values to unknown instead
      - .spec[0].template[0].spec[0].container[0].port[0].protocol: planned value cty.StringVal("TCP") for a non-computed attribute
kubernetes_deployment.logstash: Creating...
2022-03-21T09:49:25.706-0700 [INFO]  Starting apply for kubernetes_deployment.logstash
2022-03-21T09:49:26.071-0700 [WARN]  Provider "provider[\"registry.terraform.io/hashicorp/kubernetes\"]" produced an unexpected new value for kubernetes_service.redis_service, but we are tolerating it because it is using the legacy plugin SDK.
    The following problems may be the cause of any confusing errors from downstream operations:
      - .metadata[0].generate_name: was null, but now cty.StringVal("")
      - .spec[0].load_balancer_ip: was null, but now cty.StringVal("")
      - .spec[0].external_name: was null, but now cty.StringVal("")
      - .spec[0].port[0].name: was null, but now cty.StringVal("")
kubernetes_service.redis_service: Creation complete after 0s [id=default/redis]
2022-03-21T09:49:26.123-0700 [WARN]  Provider "provider[\"registry.terraform.io/hashicorp/kubernetes\"]" produced an unexpected new value for kubernetes_service.grq2_service, but we are tolerating it because it is using the legacy plugin SDK.
    The following problems may be the cause of any confusing errors from downstream operations:
      - .metadata[0].generate_name: was null, but now cty.StringVal("")
      - .spec[0].external_name: was null, but now cty.StringVal("")
      - .spec[0].load_balancer_ip: was null, but now cty.StringVal("")
      - .spec[0].port[0].name: was null, but now cty.StringVal("")
kubernetes_service.grq2_service: Creation complete after 1s [id=default/grq2]
2022-03-21T09:49:26.129-0700 [WARN]  Provider "registry.terraform.io/hashicorp/kubernetes" produced an invalid plan for kubernetes_deployment.mozart, but we are tolerating it because it is using the legacy plugin SDK.
    The following problems may be the cause of any confusing errors from downstream operations:
      - .wait_for_rollout: planned value cty.True for a non-computed attribute
      - .metadata[0].namespace: planned value cty.StringVal("default") for a non-computed attribute
      - .spec[0].min_ready_seconds: planned value cty.NumberIntVal(0) for a non-computed attribute
      - .spec[0].paused: planned value cty.False for a non-computed attribute
      - .spec[0].progress_deadline_seconds: planned value cty.NumberIntVal(600) for a non-computed attribute
      - .spec[0].revision_history_limit: planned value cty.NumberIntVal(10) for a non-computed attribute
      - .spec[0].strategy: attribute representing nested block must not be unknown itself; set nested attribute values to unknown instead
      - .spec[0].template[0].spec[0].dns_policy: planned value cty.StringVal("ClusterFirst") for a non-computed attribute
      - .spec[0].template[0].spec[0].automount_service_account_token: planned value cty.True for a non-computed attribute
      - .spec[0].template[0].spec[0].termination_grace_period_seconds: planned value cty.NumberIntVal(30) for a non-computed attribute
      - .spec[0].template[0].spec[0].host_network: planned value cty.False for a non-computed attribute
      - .spec[0].template[0].spec[0].host_ipc: planned value cty.False for a non-computed attribute
      - .spec[0].template[0].spec[0].host_pid: planned value cty.False for a non-computed attribute
      - .spec[0].template[0].spec[0].restart_policy: planned value cty.StringVal("Always") for a non-computed attribute
      - .spec[0].template[0].spec[0].share_process_namespace: planned value cty.False for a non-computed attribute
      - .spec[0].template[0].spec[0].enable_service_links: planned value cty.True for a non-computed attribute
      - .spec[0].template[0].spec[0].container[0].stdin: planned value cty.False for a non-computed attribute
      - .spec[0].template[0].spec[0].container[0].stdin_once: planned value cty.False for a non-computed attribute
      - .spec[0].template[0].spec[0].container[0].termination_message_path: planned value cty.StringVal("/dev/termination-log") for a non-computed attribute
      - .spec[0].template[0].spec[0].container[0].tty: planned value cty.False for a non-computed attribute
      - .spec[0].template[0].spec[0].container[0].volume_mount[0].mount_propagation: planned value cty.StringVal("None") for a non-computed attribute
      - .spec[0].template[0].spec[0].container[0].volume_mount[1].mount_propagation: planned value cty.StringVal("None") for a non-computed attribute
      - .spec[0].template[0].spec[0].container[0].volume_mount[2].mount_propagation: planned value cty.StringVal("None") for a non-computed attribute
      - .spec[0].template[0].spec[0].container[0].port[0].protocol: planned value cty.StringVal("TCP") for a non-computed attribute
      - .spec[0].template[0].spec[0].container[0].resources: attribute representing nested block must not be unknown itself; set nested attribute values to unknown instead
      - .spec[0].template[0].spec[0].image_pull_secrets: attribute representing nested block must not be unknown itself; set nested attribute values to unknown instead
      - .spec[0].template[0].spec[0].readiness_gate: attribute representing nested block must not be unknown itself; set nested attribute values to unknown instead
      - .spec[0].template[0].spec[0].volume[0].config_map[0].default_mode: planned value cty.StringVal("0644") for a non-computed attribute
      - .spec[0].template[0].spec[0].volume[1].config_map[0].default_mode: planned value cty.StringVal("0644") for a non-computed attribute
      - .spec[0].template[0].spec[0].volume[2].config_map[0].default_mode: planned value cty.StringVal("0644") for a non-computed attribute
kubernetes_deployment.mozart: Creating...
2022-03-21T09:49:26.139-0700 [INFO]  Starting apply for kubernetes_deployment.mozart
2022-03-21T09:49:26.152-0700 [WARN]  Provider "registry.terraform.io/hashicorp/kubernetes" produced an invalid plan for kubernetes_service.rabbitmq_service, but we are tolerating it because it is using the legacy plugin SDK.
    The following problems may be the cause of any confusing errors from downstream operations:
      - .wait_for_load_balancer: planned value cty.True for a non-computed attribute
      - .metadata[0].namespace: planned value cty.StringVal("default") for a non-computed attribute
      - .spec[0].publish_not_ready_addresses: planned value cty.False for a non-computed attribute
kubernetes_service.rabbitmq_service: Creating...
2022-03-21T09:49:26.152-0700 [INFO]  Starting apply for kubernetes_service.rabbitmq_service
2022-03-21T09:49:26.344-0700 [WARN]  Provider "provider[\"registry.terraform.io/hashicorp/kubernetes\"]" produced an unexpected new value for kubernetes_service.rabbitmq_service, but we are tolerating it because it is using the legacy plugin SDK.
    The following problems may be the cause of any confusing errors from downstream operations:
      - .metadata[0].generate_name: was null, but now cty.StringVal("")
      - .spec[0].external_name: was null, but now cty.StringVal("")
      - .spec[0].load_balancer_ip: was null, but now cty.StringVal("")
kubernetes_service.rabbitmq_service: Creation complete after 0s [id=default/rabbitmq]
2022-03-21T09:49:26.355-0700 [WARN]  Provider "registry.terraform.io/hashicorp/kubernetes" produced an invalid plan for kubernetes_config_map.datasets, but we are tolerating it because it is using the legacy plugin SDK.
    The following problems may be the cause of any confusing errors from downstream operations:
      - .metadata[0].namespace: planned value cty.StringVal("default") for a non-computed attribute
kubernetes_config_map.datasets: Creating...
2022-03-21T09:49:26.355-0700 [INFO]  Starting apply for kubernetes_config_map.datasets
2022-03-21T09:49:26.389-0700 [WARN]  Provider "provider[\"registry.terraform.io/hashicorp/kubernetes\"]" produced an unexpected new value for kubernetes_config_map.datasets, but we are tolerating it because it is using the legacy plugin SDK.
    The following problems may be the cause of any confusing errors from downstream operations:
      - .metadata[0].generate_name: was null, but now cty.StringVal("")
kubernetes_config_map.datasets: Creation complete after 0s [id=default/datasets]
2022-03-21T09:49:26.421-0700 [WARN]  Provider "registry.terraform.io/hashicorp/kubernetes" produced an invalid plan for kubernetes_deployment.hysds-ui, but we are tolerating it because it is using the legacy plugin SDK.
    The following problems may be the cause of any confusing errors from downstream operations:
      - .wait_for_rollout: planned value cty.True for a non-computed attribute
      - .metadata[0].namespace: planned value cty.StringVal("default") for a non-computed attribute
      - .spec[0].paused: planned value cty.False for a non-computed attribute
      - .spec[0].progress_deadline_seconds: planned value cty.NumberIntVal(600) for a non-computed attribute
      - .spec[0].revision_history_limit: planned value cty.NumberIntVal(10) for a non-computed attribute
      - .spec[0].min_ready_seconds: planned value cty.NumberIntVal(0) for a non-computed attribute
      - .spec[0].strategy: attribute representing nested block must not be unknown itself; set nested attribute values to unknown instead
      - .spec[0].template[0].spec[0].enable_service_links: planned value cty.True for a non-computed attribute
      - .spec[0].template[0].spec[0].host_ipc: planned value cty.False for a non-computed attribute
      - .spec[0].template[0].spec[0].host_pid: planned value cty.False for a non-computed attribute
      - .spec[0].template[0].spec[0].share_process_namespace: planned value cty.False for a non-computed attribute
      - .spec[0].template[0].spec[0].dns_policy: planned value cty.StringVal("ClusterFirst") for a non-computed attribute
      - .spec[0].template[0].spec[0].automount_service_account_token: planned value cty.True for a non-computed attribute
      - .spec[0].template[0].spec[0].host_network: planned value cty.False for a non-computed attribute
      - .spec[0].template[0].spec[0].termination_grace_period_seconds: planned value cty.NumberIntVal(30) for a non-computed attribute
      - .spec[0].template[0].spec[0].container[0].stdin: planned value cty.False for a non-computed attribute
      - .spec[0].template[0].spec[0].container[0].tty: planned value cty.False for a non-computed attribute
      - .spec[0].template[0].spec[0].container[0].stdin_once: planned value cty.False for a non-computed attribute
      - .spec[0].template[0].spec[0].container[0].termination_message_path: planned value cty.StringVal("/dev/termination-log") for a non-computed attribute
      - .spec[0].template[0].spec[0].container[0].port[0].protocol: planned value cty.StringVal("TCP") for a non-computed attribute
      - .spec[0].template[0].spec[0].container[0].resources: attribute representing nested block must not be unknown itself; set nested attribute values to unknown instead
      - .spec[0].template[0].spec[0].image_pull_secrets: attribute representing nested block must not be unknown itself; set nested attribute values to unknown instead
      - .spec[0].template[0].spec[0].readiness_gate: attribute representing nested block must not be unknown itself; set nested attribute values to unknown instead
      - .spec[0].template[0].spec[0].volume: attribute representing nested block must not be unknown itself; set nested attribute values to unknown instead
kubernetes_deployment.hysds-ui: Creating...
2022-03-21T09:49:26.421-0700 [INFO]  Starting apply for kubernetes_deployment.hysds-ui
2022-03-21T09:49:26.447-0700 [INFO]  provider.terraform-provider-helm_v2.4.1_x5: 2022/03/21 09:49:26 [DEBUG] [resourceDiff: mozart-es] Got chart: timestamp=2022-03-21T09:49:26.446-0700
2022-03-21T09:49:26.447-0700 [INFO]  provider.terraform-provider-helm_v2.4.1_x5: 2022/03/21 09:49:26 [DEBUG] [resourceDiff: mozart-es] Release validated: timestamp=2022-03-21T09:49:26.446-0700
2022-03-21T09:49:26.447-0700 [INFO]  provider.terraform-provider-helm_v2.4.1_x5: 2022/03/21 09:49:26 [DEBUG] [resourceDiff: mozart-es] Done: timestamp=2022-03-21T09:49:26.446-0700
2022-03-21T09:49:26.450-0700 [WARN]  Provider "registry.terraform.io/hashicorp/helm" produced an invalid plan for helm_release.mozart-es, but we are tolerating it because it is using the legacy plugin SDK.
    The following problems may be the cause of any confusing errors from downstream operations:
      - .replace: planned value cty.False for a non-computed attribute
      - .disable_webhooks: planned value cty.False for a non-computed attribute
      - .max_history: planned value cty.NumberIntVal(0) for a non-computed attribute
      - .disable_crd_hooks: planned value cty.False for a non-computed attribute
      - .reuse_values: planned value cty.False for a non-computed attribute
      - .skip_crds: planned value cty.False for a non-computed attribute
      - .cleanup_on_fail: planned value cty.False for a non-computed attribute
      - .disable_openapi_validation: planned value cty.False for a non-computed attribute
      - .reset_values: planned value cty.False for a non-computed attribute
      - .verify: planned value cty.False for a non-computed attribute
      - .create_namespace: planned value cty.False for a non-computed attribute
      - .wait_for_jobs: planned value cty.False for a non-computed attribute
      - .lint: planned value cty.False for a non-computed attribute
      - .namespace: planned value cty.StringVal("default") for a non-computed attribute
      - .force_update: planned value cty.False for a non-computed attribute
      - .atomic: planned value cty.False for a non-computed attribute
      - .render_subchart_notes: planned value cty.True for a non-computed attribute
      - .recreate_pods: planned value cty.False for a non-computed attribute
      - .dependency_update: planned value cty.False for a non-computed attribute
helm_release.mozart-es: Creating...
2022-03-21T09:49:26.451-0700 [INFO]  Starting apply for helm_release.mozart-es
2022-03-21T09:49:26.453-0700 [INFO]  provider.terraform-provider-helm_v2.4.1_x5: 2022/03/21 09:49:26 [DEBUG] setting computed for "metadata" from ComputedKeys: timestamp=2022-03-21T09:49:26.453-0700
2022-03-21T09:49:26.454-0700 [INFO]  provider.terraform-provider-helm_v2.4.1_x5: 2022/03/21 09:49:26 [DEBUG] [resourceReleaseCreate: mozart-es] Started: timestamp=2022-03-21T09:49:26.454-0700
2022-03-21T09:49:26.454-0700 [INFO]  provider.terraform-provider-helm_v2.4.1_x5: 2022/03/21 09:49:26 [DEBUG] [resourceReleaseCreate: mozart-es] Getting helm configuration: timestamp=2022-03-21T09:49:26.454-0700
2022-03-21T09:49:26.500-0700 [WARN]  Provider "provider[\"registry.terraform.io/hashicorp/kubernetes\"]" produced an unexpected new value for kubernetes_service.hysds-ui_service, but we are tolerating it because it is using the legacy plugin SDK.
    The following problems may be the cause of any confusing errors from downstream operations:
      - .spec[0].load_balancer_ip: was null, but now cty.StringVal("")
      - .spec[0].external_name: was null, but now cty.StringVal("")
      - .spec[0].port[0].name: was null, but now cty.StringVal("")
      - .metadata[0].generate_name: was null, but now cty.StringVal("")
kubernetes_service.hysds-ui_service: Creation complete after 2s [id=default/hysds-ui]
2022-03-21T09:49:26.510-0700 [WARN]  Provider "registry.terraform.io/hashicorp/kubernetes" produced an invalid plan for kubernetes_config_map.aws-credentials, but we are tolerating it because it is using the legacy plugin SDK.
    The following problems may be the cause of any confusing errors from downstream operations:
      - .metadata[0].namespace: planned value cty.StringVal("default") for a non-computed attribute
kubernetes_config_map.aws-credentials: Creating...
2022-03-21T09:49:26.510-0700 [INFO]  Starting apply for kubernetes_config_map.aws-credentials
2022-03-21T09:49:26.572-0700 [WARN]  Provider "provider[\"registry.terraform.io/hashicorp/kubernetes\"]" produced an unexpected new value for kubernetes_config_map.aws-credentials, but we are tolerating it because it is using the legacy plugin SDK.
    The following problems may be the cause of any confusing errors from downstream operations:
      - .metadata[0].generate_name: was null, but now cty.StringVal("")
kubernetes_config_map.aws-credentials: Creation complete after 0s [id=default/aws-credentials]
2022-03-21T09:49:26.581-0700 [WARN]  Provider "registry.terraform.io/hashicorp/kubernetes" produced an invalid plan for kubernetes_service.minio_service, but we are tolerating it because it is using the legacy plugin SDK.
    The following problems may be the cause of any confusing errors from downstream operations:
      - .wait_for_load_balancer: planned value cty.True for a non-computed attribute
      - .spec[0].publish_not_ready_addresses: planned value cty.False for a non-computed attribute
      - .metadata[0].namespace: planned value cty.StringVal("default") for a non-computed attribute
kubernetes_service.minio_service: Creating...
2022-03-21T09:49:26.581-0700 [INFO]  Starting apply for kubernetes_service.minio_service
2022-03-21T09:49:26.591-0700 [WARN]  Provider "provider[\"registry.terraform.io/hashicorp/kubernetes\"]" produced an unexpected new value for kubernetes_service.rabbitmq_mgmt_service, but we are tolerating it because it is using the legacy plugin SDK.
    The following problems may be the cause of any confusing errors from downstream operations:
      - .spec[0].external_name: was null, but now cty.StringVal("")
      - .spec[0].load_balancer_ip: was null, but now cty.StringVal("")
      - .metadata[0].generate_name: was null, but now cty.StringVal("")
kubernetes_service.rabbitmq_mgmt_service: Creation complete after 1s [id=default/rabbitmq-mgmt]
2022-03-21T09:49:26.601-0700 [WARN]  Provider "registry.terraform.io/hashicorp/kubernetes" produced an invalid plan for kubernetes_persistent_volume_claim.minio-pv-claim, but we are tolerating it because it is using the legacy plugin SDK.
    The following problems may be the cause of any confusing errors from downstream operations:
      - .wait_until_bound: planned value cty.True for a non-computed attribute
      - .metadata[0].namespace: planned value cty.StringVal("default") for a non-computed attribute
kubernetes_persistent_volume_claim.minio-pv-claim: Creating...
2022-03-21T09:49:26.604-0700 [INFO]  Starting apply for kubernetes_persistent_volume_claim.minio-pv-claim
2022-03-21T09:49:26.867-0700 [INFO]  provider.terraform-provider-helm_v2.4.1_x5: 2022/03/21 09:49:26 [DEBUG] [resourceDiff: grq2-es] Got chart: timestamp=2022-03-21T09:49:26.867-0700
2022-03-21T09:49:26.867-0700 [INFO]  provider.terraform-provider-helm_v2.4.1_x5: 2022/03/21 09:49:26 [DEBUG] [resourceDiff: grq2-es] Release validated: timestamp=2022-03-21T09:49:26.867-0700
2022-03-21T09:49:26.867-0700 [INFO]  provider.terraform-provider-helm_v2.4.1_x5: 2022/03/21 09:49:26 [DEBUG] [resourceDiff: grq2-es] Done: timestamp=2022-03-21T09:49:26.867-0700
2022-03-21T09:49:26.868-0700 [INFO]  provider.terraform-provider-helm_v2.4.1_x5: 2022/03/21 09:49:26 [DEBUG] [INFO] GetHelmConfiguration start: timestamp=2022-03-21T09:49:26.868-0700
2022-03-21T09:49:26.869-0700 [WARN]  Provider "registry.terraform.io/hashicorp/helm" produced an invalid plan for helm_release.grq2-es, but we are tolerating it because it is using the legacy plugin SDK.
    The following problems may be the cause of any confusing errors from downstream operations:
      - .atomic: planned value cty.False for a non-computed attribute
      - .render_subchart_notes: planned value cty.True for a non-computed attribute
      - .recreate_pods: planned value cty.False for a non-computed attribute
      - .dependency_update: planned value cty.False for a non-computed attribute
      - .replace: planned value cty.False for a non-computed attribute
      - .disable_webhooks: planned value cty.False for a non-computed attribute
      - .max_history: planned value cty.NumberIntVal(0) for a non-computed attribute
      - .disable_crd_hooks: planned value cty.False for a non-computed attribute
      - .reuse_values: planned value cty.False for a non-computed attribute
      - .skip_crds: planned value cty.False for a non-computed attribute
      - .cleanup_on_fail: planned value cty.False for a non-computed attribute
      - .disable_openapi_validation: planned value cty.False for a non-computed attribute
      - .reset_values: planned value cty.False for a non-computed attribute
      - .verify: planned value cty.False for a non-computed attribute
      - .create_namespace: planned value cty.False for a non-computed attribute
      - .wait_for_jobs: planned value cty.False for a non-computed attribute
      - .lint: planned value cty.False for a non-computed attribute
      - .namespace: planned value cty.StringVal("default") for a non-computed attribute
      - .force_update: planned value cty.False for a non-computed attribute
helm_release.grq2-es: Creating...
2022-03-21T09:49:26.869-0700 [INFO]  Starting apply for helm_release.grq2-es
2022-03-21T09:49:26.871-0700 [INFO]  provider.terraform-provider-helm_v2.4.1_x5: 2022/03/21 09:49:26 [DEBUG] Using kubeconfig: /Users/drewm/.kube/config: timestamp=2022-03-21T09:49:26.871-0700
2022-03-21T09:49:26.872-0700 [INFO]  provider.terraform-provider-helm_v2.4.1_x5: 2022/03/21 09:49:26 [INFO] Successfully initialized kubernetes config: timestamp=2022-03-21T09:49:26.872-0700
2022-03-21T09:49:26.872-0700 [INFO]  provider.terraform-provider-helm_v2.4.1_x5: 2022/03/21 09:49:26 [DEBUG] [INFO] GetHelmConfiguration success: timestamp=2022-03-21T09:49:26.872-0700
2022-03-21T09:49:26.872-0700 [INFO]  provider.terraform-provider-helm_v2.4.1_x5: 2022/03/21 09:49:26 [DEBUG] setting computed for "metadata" from ComputedKeys: timestamp=2022-03-21T09:49:26.872-0700
2022-03-21T09:49:26.872-0700 [INFO]  provider.terraform-provider-helm_v2.4.1_x5: 2022/03/21 09:49:26 [DEBUG] [resourceReleaseCreate: mozart-es] Getting chart: timestamp=2022-03-21T09:49:26.872-0700
2022-03-21T09:49:26.873-0700 [INFO]  provider.terraform-provider-helm_v2.4.1_x5: 2022/03/21 09:49:26 [DEBUG] [resourceReleaseCreate: grq2-es] Started: timestamp=2022-03-21T09:49:26.873-0700
2022-03-21T09:49:26.873-0700 [INFO]  provider.terraform-provider-helm_v2.4.1_x5: 2022/03/21 09:49:26 [DEBUG] [resourceReleaseCreate: grq2-es] Getting helm configuration: timestamp=2022-03-21T09:49:26.873-0700
2022-03-21T09:49:26.893-0700 [WARN]  Provider "provider[\"registry.terraform.io/hashicorp/kubernetes\"]" produced an unexpected new value for kubernetes_persistent_volume_claim.minio-pv-claim, but we are tolerating it because it is using the legacy plugin SDK.
    The following problems may be the cause of any confusing errors from downstream operations:
      - .metadata[0].generate_name: was null, but now cty.StringVal("")
kubernetes_persistent_volume_claim.minio-pv-claim: Creation complete after 0s [id=default/minio-pv-claim]
2022-03-21T09:49:26.903-0700 [WARN]  Provider "registry.terraform.io/hashicorp/kubernetes" produced an invalid plan for kubernetes_config_map.logstash-configs, but we are tolerating it because it is using the legacy plugin SDK.
    The following problems may be the cause of any confusing errors from downstream operations:
      - .metadata[0].namespace: planned value cty.StringVal("default") for a non-computed attribute
kubernetes_config_map.logstash-configs: Creating...
2022-03-21T09:49:26.904-0700 [INFO]  Starting apply for kubernetes_config_map.logstash-configs
2022-03-21T09:49:27.041-0700 [WARN]  Provider "provider[\"registry.terraform.io/hashicorp/kubernetes\"]" produced an unexpected new value for kubernetes_config_map.logstash-configs, but we are tolerating it because it is using the legacy plugin SDK.
    The following problems may be the cause of any confusing errors from downstream operations:
      - .metadata[0].generate_name: was null, but now cty.StringVal("")
kubernetes_config_map.logstash-configs: Creation complete after 0s [id=default/logstash-configs]
2022-03-21T09:49:27.096-0700 [WARN]  Provider "registry.terraform.io/hashicorp/kubernetes" produced an invalid plan for kubernetes_deployment.user-rules, but we are tolerating it because it is using the legacy plugin SDK.
    The following problems may be the cause of any confusing errors from downstream operations:
      - .wait_for_rollout: planned value cty.True for a non-computed attribute
      - .metadata[0].namespace: planned value cty.StringVal("default") for a non-computed attribute
      - .spec[0].min_ready_seconds: planned value cty.NumberIntVal(0) for a non-computed attribute
      - .spec[0].paused: planned value cty.False for a non-computed attribute
      - .spec[0].progress_deadline_seconds: planned value cty.NumberIntVal(600) for a non-computed attribute
      - .spec[0].revision_history_limit: planned value cty.NumberIntVal(10) for a non-computed attribute
      - .spec[0].strategy: attribute representing nested block must not be unknown itself; set nested attribute values to unknown instead
      - .spec[0].template[0].spec[0].automount_service_account_token: planned value cty.True for a non-computed attribute
      - .spec[0].template[0].spec[0].host_network: planned value cty.False for a non-computed attribute
      - .spec[0].template[0].spec[0].termination_grace_period_seconds: planned value cty.NumberIntVal(30) for a non-computed attribute
      - .spec[0].template[0].spec[0].restart_policy: planned value cty.StringVal("Always") for a non-computed attribute
      - .spec[0].template[0].spec[0].share_process_namespace: planned value cty.False for a non-computed attribute
      - .spec[0].template[0].spec[0].enable_service_links: planned value cty.True for a non-computed attribute
      - .spec[0].template[0].spec[0].host_ipc: planned value cty.False for a non-computed attribute
      - .spec[0].template[0].spec[0].host_pid: planned value cty.False for a non-computed attribute
      - .spec[0].template[0].spec[0].dns_policy: planned value cty.StringVal("ClusterFirst") for a non-computed attribute
      - .spec[0].template[0].spec[0].container[0].stdin: planned value cty.False for a non-computed attribute
      - .spec[0].template[0].spec[0].container[0].stdin_once: planned value cty.False for a non-computed attribute
      - .spec[0].template[0].spec[0].container[0].termination_message_path: planned value cty.StringVal("/dev/termination-log") for a non-computed attribute
      - .spec[0].template[0].spec[0].container[0].tty: planned value cty.False for a non-computed attribute
      - .spec[0].template[0].spec[0].container[0].resources: attribute representing nested block must not be unknown itself; set nested attribute values to unknown instead
      - .spec[0].template[0].spec[0].container[0].volume_mount[0].mount_propagation: planned value cty.StringVal("None") for a non-computed attribute
      - .spec[0].template[0].spec[0].container[0].volume_mount[1].mount_propagation: planned value cty.StringVal("None") for a non-computed attribute
      - .spec[0].template[0].spec[0].container[0].volume_mount[2].mount_propagation: planned value cty.StringVal("None") for a non-computed attribute
      - .spec[0].template[0].spec[0].readiness_gate: attribute representing nested block must not be unknown itself; set nested attribute values to unknown instead
      - .spec[0].template[0].spec[0].volume[0].config_map[0].default_mode: planned value cty.StringVal("0644") for a non-computed attribute
      - .spec[0].template[0].spec[0].volume[1].config_map[0].default_mode: planned value cty.StringVal("0644") for a non-computed attribute
      - .spec[0].template[0].spec[0].image_pull_secrets: attribute representing nested block must not be unknown itself; set nested attribute values to unknown instead
kubernetes_deployment.user-rules: Creating...
2022-03-21T09:49:27.096-0700 [INFO]  Starting apply for kubernetes_deployment.user-rules
2022-03-21T09:49:27.267-0700 [WARN]  Provider "provider[\"registry.terraform.io/hashicorp/kubernetes\"]" produced an unexpected new value for kubernetes_service.minio_service, but we are tolerating it because it is using the legacy plugin SDK.
    The following problems may be the cause of any confusing errors from downstream operations:
      - .metadata[0].generate_name: was null, but now cty.StringVal("")
      - .spec[0].external_name: was null, but now cty.StringVal("")
      - .spec[0].load_balancer_ip: was null, but now cty.StringVal("")
kubernetes_service.minio_service: Creation complete after 0s [id=default/minio]
2022-03-21T09:49:27.336-0700 [WARN]  Provider "registry.terraform.io/hashicorp/kubernetes" produced an invalid plan for kubernetes_deployment.orchestrator, but we are tolerating it because it is using the legacy plugin SDK.
    The following problems may be the cause of any confusing errors from downstream operations:
      - .wait_for_rollout: planned value cty.True for a non-computed attribute
      - .metadata[0].namespace: planned value cty.StringVal("default") for a non-computed attribute
      - .spec[0].progress_deadline_seconds: planned value cty.NumberIntVal(600) for a non-computed attribute
      - .spec[0].revision_history_limit: planned value cty.NumberIntVal(10) for a non-computed attribute
      - .spec[0].min_ready_seconds: planned value cty.NumberIntVal(0) for a non-computed attribute
      - .spec[0].paused: planned value cty.False for a non-computed attribute
      - .spec[0].strategy: attribute representing nested block must not be unknown itself; set nested attribute values to unknown instead
      - .spec[0].template[0].spec[0].dns_policy: planned value cty.StringVal("ClusterFirst") for a non-computed attribute
      - .spec[0].template[0].spec[0].automount_service_account_token: planned value cty.True for a non-computed attribute
      - .spec[0].template[0].spec[0].termination_grace_period_seconds: planned value cty.NumberIntVal(30) for a non-computed attribute
      - .spec[0].template[0].spec[0].host_network: planned value cty.False for a non-computed attribute
      - .spec[0].template[0].spec[0].restart_policy: planned value cty.StringVal("Always") for a non-computed attribute
      - .spec[0].template[0].spec[0].share_process_namespace: planned value cty.False for a non-computed attribute
      - .spec[0].template[0].spec[0].enable_service_links: planned value cty.True for a non-computed attribute
      - .spec[0].template[0].spec[0].host_ipc: planned value cty.False for a non-computed attribute
      - .spec[0].template[0].spec[0].host_pid: planned value cty.False for a non-computed attribute
      - .spec[0].template[0].spec[0].readiness_gate: attribute representing nested block must not be unknown itself; set nested attribute values to unknown instead
      - .spec[0].template[0].spec[0].volume[0].config_map[0].default_mode: planned value cty.StringVal("0644") for a non-computed attribute
      - .spec[0].template[0].spec[0].volume[1].config_map[0].default_mode: planned value cty.StringVal("0644") for a non-computed attribute
      - .spec[0].template[0].spec[0].image_pull_secrets: attribute representing nested block must not be unknown itself; set nested attribute values to unknown instead
      - .spec[0].template[0].spec[0].container[0].stdin: planned value cty.False for a non-computed attribute
      - .spec[0].template[0].spec[0].container[0].stdin_once: planned value cty.False for a non-computed attribute
      - .spec[0].template[0].spec[0].container[0].termination_message_path: planned value cty.StringVal("/dev/termination-log") for a non-computed attribute
      - .spec[0].template[0].spec[0].container[0].tty: planned value cty.False for a non-computed attribute
      - .spec[0].template[0].spec[0].container[0].resources: attribute representing nested block must not be unknown itself; set nested attribute values to unknown instead
      - .spec[0].template[0].spec[0].container[0].volume_mount[0].mount_propagation: planned value cty.StringVal("None") for a non-computed attribute
      - .spec[0].template[0].spec[0].container[0].volume_mount[1].mount_propagation: planned value cty.StringVal("None") for a non-computed attribute
      - .spec[0].template[0].spec[0].container[0].volume_mount[2].mount_propagation: planned value cty.StringVal("None") for a non-computed attribute
kubernetes_deployment.orchestrator: Creating...
2022-03-21T09:49:27.338-0700 [INFO]  Starting apply for kubernetes_deployment.orchestrator
2022-03-21T09:49:27.634-0700 [INFO]  provider.terraform-provider-helm_v2.4.1_x5: 2022/03/21 09:49:27 [DEBUG] Chart dependencies are up to date.: timestamp=2022-03-21T09:49:27.634-0700
2022-03-21T09:49:27.634-0700 [INFO]  provider.terraform-provider-helm_v2.4.1_x5: 2022/03/21 09:49:27 [DEBUG] [resourceReleaseCreate: mozart-es] Preparing for installation: timestamp=2022-03-21T09:49:27.634-0700
2022-03-21T09:49:27.634-0700 [INFO]  provider.terraform-provider-helm_v2.4.1_x5: 2022/03/21 09:49:27 [DEBUG] [INFO] GetHelmConfiguration start: timestamp=2022-03-21T09:49:27.634-0700
2022-03-21T09:49:27.635-0700 [INFO]  provider.terraform-provider-helm_v2.4.1_x5: 2022/03/21 09:49:27 [DEBUG] Using kubeconfig: /Users/drewm/.kube/config: timestamp=2022-03-21T09:49:27.634-0700
2022-03-21T09:49:27.636-0700 [INFO]  provider.terraform-provider-helm_v2.4.1_x5: 2022/03/21 09:49:27 ---[ values.yaml ]-----------------------------------
antiAffinity: soft
clusterHealthCheckParams: wait_for_status=yellow&timeout=1s
clusterName: mozart-es
esConfig:
  elasticsearch.yml: |
    http.cors.enabled : true
    http.cors.allow-origin: "*"
esJavaOpts: -Xmx512m -Xms512m
httpPort: 9200
lifecycle:
  postStart:
    exec:
      command:
      - bash
      - -c
      - |
        #!/bin/bash
        ES_URL=http://localhost:9200
        while [[ "$(curl -s -o /dev/null -w '%{http_code}\n' $ES_URL)" != "200" ]]; do sleep 1; done
        mozart_es_template=$(curl -s https://raw.githubusercontent.com/hysds/mozart/develop/configs/es_template.json)
        for idx in "containers" "job_specs" "hysds_io"; do
          template=$(echo ${mozart_es_template} | sed "s/{{ index }}/${idx}/")
          curl -X PUT "$ES_URL/_template/${idx}" -H 'Content-Type: application/json' -d "${template}" >/dev/null
        done

        hysds_io_mozart=$(curl -s https://raw.githubusercontent.com/hysds/mozart/develop/configs/hysds_ios.mapping)
        curl -X PUT "$ES_URL/_template/hysds_ios-mozart?pretty" -H 'Content-Type: application/json' -d '${hysds_io_mozart}'

        user_rules_mozart=$(curl -s https://raw.githubusercontent.com/hysds/mozart/develop/configs/user_rules_job.mapping)
        curl -X PUT "$ES_URL/user_rules-mozart?pretty" -H 'Content-Type: application/json' -d "${user_rules_mozart}"

        hysds_io_grq=$(curl -s https://raw.githubusercontent.com/hysds/grq2/develop/config/hysds_ios.mapping)
        curl -X PUT "$ES_URL/hysds_ios-grq?pretty"  -H 'Content-Type: application/json' -d "${hysds_io_grq}"

        user_rules_grq=$(curl -s https://raw.githubusercontent.com/hysds/grq2/develop/config/user_rules_dataset.mapping)
        curl -X PUT "$ES_URL/user_rules-grq?pretty" -H 'Content-Type: application/json' -d "${user_rules_grq}"
masterService: mozart-es
replicas: 1
resources:
  limits:
    cpu: 1000m
    memory: 2Gi
  requests:
    cpu: 1000m
    memory: 2Gi
service:
  type: LoadBalancer
transportPort: 9300
volumeClaimTemplate:
  accessModes:
  - ReadWriteOnce
  resources:
    requests:
      storage: 5Gi
  storageClassName: hostpath: timestamp=2022-03-21T09:49:27.635-0700
2022-03-21T09:49:27.636-0700 [INFO]  provider.terraform-provider-helm_v2.4.1_x5: 2022/03/21 09:49:27 [DEBUG] [resourceReleaseCreate: mozart-es] Installing chart: timestamp=2022-03-21T09:49:27.635-0700
2022-03-21T09:49:27.641-0700 [INFO]  provider.terraform-provider-helm_v2.4.1_x5: 2022/03/21 09:49:27 [INFO] Successfully initialized kubernetes config: timestamp=2022-03-21T09:49:27.639-0700
2022-03-21T09:49:27.642-0700 [INFO]  provider.terraform-provider-helm_v2.4.1_x5: 2022/03/21 09:49:27 [DEBUG] [INFO] GetHelmConfiguration success: timestamp=2022-03-21T09:49:27.639-0700
2022-03-21T09:49:27.642-0700 [INFO]  provider.terraform-provider-helm_v2.4.1_x5: 2022/03/21 09:49:27 [DEBUG] [resourceReleaseCreate: grq2-es] Getting chart: timestamp=2022-03-21T09:49:27.639-0700
2022-03-21T09:49:28.098-0700 [WARN]  unexpected data: registry.terraform.io/hashicorp/helm:stderr="W0321 09:49:28.097583   53247 warnings.go:70] policy/v1beta1 PodDisruptionBudget is deprecated in v1.21+, unavailable in v1.25+; use policy/v1 PodDisruptionBudget"
2022-03-21T09:49:28.163-0700 [INFO]  provider.terraform-provider-helm_v2.4.1_x5: 2022/03/21 09:49:28 [DEBUG] Chart dependencies are up to date.: timestamp=2022-03-21T09:49:28.163-0700
2022-03-21T09:49:28.163-0700 [INFO]  provider.terraform-provider-helm_v2.4.1_x5: 2022/03/21 09:49:28 [DEBUG] [resourceReleaseCreate: grq2-es] Preparing for installation: timestamp=2022-03-21T09:49:28.163-0700
2022-03-21T09:49:28.165-0700 [INFO]  provider.terraform-provider-helm_v2.4.1_x5: 2022/03/21 09:49:28 ---[ values.yaml ]-----------------------------------
antiAffinity: soft
clusterHealthCheckParams: wait_for_status=yellow&timeout=1s
clusterName: grq-es
esConfig:
  elasticsearch.yml: |
    http.cors.enabled : true
    http.cors.allow-origin: "*"
    http.port: 9201
esJavaOpts: -Xmx512m -Xms512m
httpPort: 9201
lifecycle:
  postStart:
    exec:
      command:
      - bash
      - -c
      - |
        #!/bin/bash
        ES_URL=http://localhost:9201
        while [[ "$(curl -s -o /dev/null -w '%{http_code}\n' $ES_URL)" != "200" ]]; do sleep 1; done

        grq_es_template=$(curl -s https://raw.githubusercontent.com/hysds/grq2/develop/config/es_template.json)
        template=$(echo ${grq_es_template} | sed 's/{{ prefix }}/grq/;s/{{ alias }}/grq/')
        curl -X PUT "$ES_URL/_template/grq" -H 'Content-Type: application/json' -d "${template}"

        ingest_pipeline=$(curl -s https://raw.githubusercontent.com/hysds/grq2/develop/config/ingest_pipeline.json)
        curl -X PUT "$ES_URL/_ingest/pipeline/dataset_pipeline" -H 'Content-Type: application/json' -d "${ingest_pipeline}"
masterService: grq-es
replicas: 1
resources:
  limits:
    cpu: 1000m
    memory: 2Gi
  requests:
    cpu: 1000m
    memory: 2Gi
service:
  type: LoadBalancer
transportPort: 9301
volumeClaimTemplate:
  accessModes:
  - ReadWriteOnce
  resources:
    requests:
      storage: 5Gi
  storageClassName: hostpath: timestamp=2022-03-21T09:49:28.165-0700
2022-03-21T09:49:28.165-0700 [INFO]  provider.terraform-provider-helm_v2.4.1_x5: 2022/03/21 09:49:28 [DEBUG] [resourceReleaseCreate: grq2-es] Installing chart: timestamp=2022-03-21T09:49:28.165-0700
2022-03-21T09:49:28.181-0700 [INFO]  provider.terraform-provider-helm_v2.4.1_x5: 2022/03/21 09:49:28 [DEBUG] creating 5 resource(s): timestamp=2022-03-21T09:49:28.181-0700
2022-03-21T09:49:28.229-0700 [WARN]  unexpected data: registry.terraform.io/hashicorp/helm:stderr="W0321 09:49:28.229078   53247 warnings.go:70] policy/v1beta1 PodDisruptionBudget is deprecated in v1.21+, unavailable in v1.25+; use policy/v1 PodDisruptionBudget"
2022-03-21T09:49:28.502-0700 [INFO]  provider.terraform-provider-helm_v2.4.1_x5: 2022/03/21 09:49:28 [DEBUG] beginning wait for 5 resources with timeout of 2m30s: timestamp=2022-03-21T09:49:28.502-0700
2022-03-21T09:49:28.624-0700 [INFO]  provider.terraform-provider-helm_v2.4.1_x5: 2022/03/21 09:49:28 [DEBUG] Service does not have load balancer ingress IP address: default/mozart-es: timestamp=2022-03-21T09:49:28.624-0700
2022-03-21T09:49:28.817-0700 [WARN]  unexpected data: registry.terraform.io/hashicorp/helm:stderr="W0321 09:49:28.817333   53247 warnings.go:70] policy/v1beta1 PodDisruptionBudget is deprecated in v1.21+, unavailable in v1.25+; use policy/v1 PodDisruptionBudget"
2022-03-21T09:49:28.952-0700 [INFO]  provider.terraform-provider-helm_v2.4.1_x5: 2022/03/21 09:49:28 [DEBUG] creating 5 resource(s): timestamp=2022-03-21T09:49:28.952-0700
2022-03-21T09:49:28.964-0700 [WARN]  unexpected data: registry.terraform.io/hashicorp/helm:stderr="W0321 09:49:28.964090   53247 warnings.go:70] policy/v1beta1 PodDisruptionBudget is deprecated in v1.21+, unavailable in v1.25+; use policy/v1 PodDisruptionBudget"
2022-03-21T09:49:29.054-0700 [INFO]  provider.terraform-provider-helm_v2.4.1_x5: 2022/03/21 09:49:29 [DEBUG] beginning wait for 5 resources with timeout of 2m30s: timestamp=2022-03-21T09:49:29.054-0700
2022-03-21T09:49:29.082-0700 [INFO]  provider.terraform-provider-helm_v2.4.1_x5: 2022/03/21 09:49:29 [DEBUG] Service does not have load balancer ingress IP address: default/grq-es: timestamp=2022-03-21T09:49:29.082-0700
2022-03-21T09:49:30.919-0700 [INFO]  provider.terraform-provider-helm_v2.4.1_x5: 2022/03/21 09:49:30 [DEBUG] StatefulSet is not ready: default/mozart-es-master. 0 out of 1 expected pods are ready: timestamp=2022-03-21T09:49:30.919-0700
2022-03-21T09:49:31.104-0700 [INFO]  provider.terraform-provider-helm_v2.4.1_x5: 2022/03/21 09:49:31 [DEBUG] StatefulSet is not ready: default/grq-es-master. 0 out of 1 expected pods are ready: timestamp=2022-03-21T09:49:31.103-0700
2022-03-21T09:49:32.732-0700 [INFO]  provider.terraform-provider-helm_v2.4.1_x5: 2022/03/21 09:49:32 [DEBUG] StatefulSet is not ready: default/mozart-es-master. 0 out of 1 expected pods are ready: timestamp=2022-03-21T09:49:32.732-0700
2022-03-21T09:49:33.150-0700 [INFO]  provider.terraform-provider-helm_v2.4.1_x5: 2022/03/21 09:49:33 [DEBUG] StatefulSet is not ready: default/grq-es-master. 0 out of 1 expected pods are ready: timestamp=2022-03-21T09:49:33.149-0700
2022-03-21T09:49:33.268-0700 [WARN]  Provider "provider[\"registry.terraform.io/hashicorp/kubernetes\"]" produced an unexpected new value for kubernetes_deployment.redis, but we are tolerating it because it is using the legacy plugin SDK.
    The following problems may be the cause of any confusing errors from downstream operations:
      - .metadata[0].generate_name: was null, but now cty.StringVal("")
      - .spec[0].template[0].metadata[0].namespace: was null, but now cty.StringVal("")
      - .spec[0].template[0].metadata[0].generate_name: was null, but now cty.StringVal("")
      - .spec[0].template[0].spec[0].priority_class_name: was null, but now cty.StringVal("")
      - .spec[0].template[0].spec[0].active_deadline_seconds: was null, but now cty.NumberIntVal(0)
      - .spec[0].template[0].spec[0].subdomain: was null, but now cty.StringVal("")
      - .spec[0].template[0].spec[0].container[0].working_dir: was null, but now cty.StringVal("")
      - .spec[0].template[0].spec[0].container[0].port[0].host_port: was null, but now cty.NumberIntVal(0)
      - .spec[0].template[0].spec[0].container[0].port[0].name: was null, but now cty.StringVal("")
      - .spec[0].template[0].spec[0].container[0].port[0].host_ip: was null, but now cty.StringVal("")
kubernetes_deployment.redis: Creation complete after 8s [id=default/redis]
2022-03-21T09:49:33.317-0700 [WARN]  Provider "registry.terraform.io/hashicorp/kubernetes" produced an invalid plan for kubernetes_stateful_set.rabbitmq_statefulset, but we are tolerating it because it is using the legacy plugin SDK.
    The following problems may be the cause of any confusing errors from downstream operations:
      - .wait_for_rollout: planned value cty.True for a non-computed attribute
      - .spec[0].template[0].spec[0].termination_grace_period_seconds: planned value cty.NumberIntVal(30) for a non-computed attribute
      - .spec[0].template[0].spec[0].enable_service_links: planned value cty.True for a non-computed attribute
      - .spec[0].template[0].spec[0].host_network: planned value cty.False for a non-computed attribute
      - .spec[0].template[0].spec[0].restart_policy: planned value cty.StringVal("Always") for a non-computed attribute
      - .spec[0].template[0].spec[0].share_process_namespace: planned value cty.False for a non-computed attribute
      - .spec[0].template[0].spec[0].automount_service_account_token: planned value cty.True for a non-computed attribute
      - .spec[0].template[0].spec[0].dns_policy: planned value cty.StringVal("ClusterFirst") for a non-computed attribute
      - .spec[0].template[0].spec[0].host_ipc: planned value cty.False for a non-computed attribute
      - .spec[0].template[0].spec[0].host_pid: planned value cty.False for a non-computed attribute
      - .spec[0].template[0].spec[0].image_pull_secrets: attribute representing nested block must not be unknown itself; set nested attribute values to unknown instead
      - .spec[0].template[0].spec[0].container[0].stdin_once: planned value cty.False for a non-computed attribute
      - .spec[0].template[0].spec[0].container[0].tty: planned value cty.False for a non-computed attribute
      - .spec[0].template[0].spec[0].container[0].stdin: planned value cty.False for a non-computed attribute
      - .spec[0].template[0].spec[0].container[0].termination_message_path: planned value cty.StringVal("/dev/termination-log") for a non-computed attribute
      - .spec[0].template[0].spec[0].container[0].volume_mount[0].mount_propagation: planned value cty.StringVal("None") for a non-computed attribute
      - .spec[0].template[0].spec[0].container[0].volume_mount[0].read_only: planned value cty.False for a non-computed attribute
      - .spec[0].template[0].spec[0].container[0].resources: attribute representing nested block must not be unknown itself; set nested attribute values to unknown instead
      - .spec[0].template[0].spec[0].readiness_gate: attribute representing nested block must not be unknown itself; set nested attribute values to unknown instead
      - .metadata[0].namespace: planned value cty.StringVal("default") for a non-computed attribute
kubernetes_stateful_set.rabbitmq_statefulset: Creating...
2022-03-21T09:49:33.318-0700 [INFO]  Starting apply for kubernetes_stateful_set.rabbitmq_statefulset
2022-03-21T09:49:34.674-0700 [INFO]  provider.terraform-provider-helm_v2.4.1_x5: 2022/03/21 09:49:34 [DEBUG] StatefulSet is not ready: default/mozart-es-master. 0 out of 1 expected pods are ready: timestamp=2022-03-21T09:49:34.674-0700
kubernetes_deployment.grq2: Still creating... [10s elapsed]
kubernetes_deployment.factotum-job-worker: Still creating... [10s elapsed]
2022-03-21T09:49:35.688-0700 [INFO]  provider.terraform-provider-helm_v2.4.1_x5: 2022/03/21 09:49:35 [DEBUG] StatefulSet is not ready: default/grq-es-master. 0 out of 1 expected pods are ready: timestamp=2022-03-21T09:49:35.688-0700
kubernetes_deployment.logstash: Still creating... [10s elapsed]
kubernetes_deployment.mozart: Still creating... [10s elapsed]
kubernetes_deployment.hysds-ui: Still creating... [10s elapsed]
helm_release.mozart-es: Still creating... [10s elapsed]
helm_release.grq2-es: Still creating... [10s elapsed]
2022-03-21T09:49:36.883-0700 [INFO]  provider.terraform-provider-helm_v2.4.1_x5: 2022/03/21 09:49:36 [DEBUG] StatefulSet is not ready: default/mozart-es-master. 0 out of 1 expected pods are ready: timestamp=2022-03-21T09:49:36.883-0700
kubernetes_deployment.user-rules: Still creating... [10s elapsed]
2022-03-21T09:49:37.258-0700 [INFO]  provider.terraform-provider-helm_v2.4.1_x5: 2022/03/21 09:49:37 [DEBUG] StatefulSet is not ready: default/grq-es-master. 0 out of 1 expected pods are ready: timestamp=2022-03-21T09:49:37.258-0700
kubernetes_deployment.orchestrator: Still creating... [10s elapsed]
2022-03-21T09:49:38.656-0700 [INFO]  provider.terraform-provider-helm_v2.4.1_x5: 2022/03/21 09:49:38 [DEBUG] StatefulSet is not ready: default/mozart-es-master. 0 out of 1 expected pods are ready: timestamp=2022-03-21T09:49:38.656-0700
2022-03-21T09:49:39.197-0700 [INFO]  provider.terraform-provider-helm_v2.4.1_x5: 2022/03/21 09:49:39 [DEBUG] StatefulSet is not ready: default/grq-es-master. 0 out of 1 expected pods are ready: timestamp=2022-03-21T09:49:39.197-0700
2022-03-21T09:49:40.844-0700 [INFO]  provider.terraform-provider-helm_v2.4.1_x5: 2022/03/21 09:49:40 [DEBUG] StatefulSet is not ready: default/mozart-es-master. 0 out of 1 expected pods are ready: timestamp=2022-03-21T09:49:40.844-0700
2022-03-21T09:49:41.367-0700 [INFO]  provider.terraform-provider-helm_v2.4.1_x5: 2022/03/21 09:49:41 [DEBUG] StatefulSet is not ready: default/grq-es-master. 0 out of 1 expected pods are ready: timestamp=2022-03-21T09:49:41.366-0700
2022-03-21T09:49:41.379-0700 [WARN]  Provider "provider[\"registry.terraform.io/hashicorp/kubernetes\"]" produced an unexpected new value for kubernetes_stateful_set.rabbitmq_statefulset, but we are tolerating it because it is using the legacy plugin SDK.
    The following problems may be the cause of any confusing errors from downstream operations:
      - .metadata[0].generate_name: was null, but now cty.StringVal("")
      - .spec[0].template[0].metadata[0].generate_name: was null, but now cty.StringVal("")
      - .spec[0].template[0].spec[0].subdomain: was null, but now cty.StringVal("")
      - .spec[0].template[0].spec[0].priority_class_name: was null, but now cty.StringVal("")
      - .spec[0].template[0].spec[0].active_deadline_seconds: was null, but now cty.NumberIntVal(0)
      - .spec[0].template[0].spec[0].container[0].working_dir: was null, but now cty.StringVal("")
      - .spec[0].template[0].spec[0].container[0].volume_mount[0].sub_path: was null, but now cty.StringVal("")
kubernetes_stateful_set.rabbitmq_statefulset: Creation complete after 8s [id=default/rabbitmq]
2022-03-21T09:49:41.396-0700 [WARN]  Provider "registry.terraform.io/hashicorp/kubernetes" produced an invalid plan for kubernetes_service.mozart_service, but we are tolerating it because it is using the legacy plugin SDK.
    The following problems may be the cause of any confusing errors from downstream operations:
      - .wait_for_load_balancer: planned value cty.True for a non-computed attribute
      - .metadata[0].namespace: planned value cty.StringVal("default") for a non-computed attribute
      - .spec[0].publish_not_ready_addresses: planned value cty.False for a non-computed attribute
      - .spec[0].port[0].protocol: planned value cty.StringVal("TCP") for a non-computed attribute
kubernetes_service.mozart_service: Creating...
2022-03-21T09:49:41.396-0700 [INFO]  Starting apply for kubernetes_service.mozart_service
2022-03-21T09:49:41.688-0700 [WARN]  Provider "provider[\"registry.terraform.io/hashicorp/kubernetes\"]" produced an unexpected new value for kubernetes_deployment.logstash, but we are tolerating it because it is using the legacy plugin SDK.
    The following problems may be the cause of any confusing errors from downstream operations:
      - .metadata[0].generate_name: was null, but now cty.StringVal("")
      - .spec[0].template[0].metadata[0].namespace: was null, but now cty.StringVal("")
      - .spec[0].template[0].metadata[0].generate_name: was null, but now cty.StringVal("")
      - .spec[0].template[0].spec[0].active_deadline_seconds: was null, but now cty.NumberIntVal(0)
      - .spec[0].template[0].spec[0].subdomain: was null, but now cty.StringVal("")
      - .spec[0].template[0].spec[0].priority_class_name: was null, but now cty.StringVal("")
      - .spec[0].template[0].spec[0].volume[0].config_map[0].optional: was null, but now cty.False
      - .spec[0].template[0].spec[0].volume[0].config_map[0].items[0].mode: was null, but now cty.StringVal("")
      - .spec[0].template[0].spec[0].volume[1].config_map[0].optional: was null, but now cty.False
      - .spec[0].template[0].spec[0].volume[1].config_map[0].items[0].mode: was null, but now cty.StringVal("")
      - .spec[0].template[0].spec[0].volume[2].config_map[0].optional: was null, but now cty.False
      - .spec[0].template[0].spec[0].volume[2].config_map[0].items[0].mode: was null, but now cty.StringVal("")
      - .spec[0].template[0].spec[0].volume[3].config_map[0].optional: was null, but now cty.False
      - .spec[0].template[0].spec[0].volume[3].config_map[0].items[0].mode: was null, but now cty.StringVal("")
      - .spec[0].template[0].spec[0].volume[4].config_map[0].optional: was null, but now cty.False
      - .spec[0].template[0].spec[0].volume[4].config_map[0].items[0].mode: was null, but now cty.StringVal("")
      - .spec[0].template[0].spec[0].volume[5].config_map[0].optional: was null, but now cty.False
      - .spec[0].template[0].spec[0].volume[5].config_map[0].items[0].mode: was null, but now cty.StringVal("")
      - .spec[0].template[0].spec[0].container[0].working_dir: was null, but now cty.StringVal("")
      - .spec[0].template[0].spec[0].container[0].port[0].host_ip: was null, but now cty.StringVal("")
      - .spec[0].template[0].spec[0].container[0].port[0].host_port: was null, but now cty.NumberIntVal(0)
      - .spec[0].template[0].spec[0].container[0].port[0].name: was null, but now cty.StringVal("")
kubernetes_deployment.logstash: Creation complete after 16s [id=default/logstash]
2022-03-21T09:49:41.707-0700 [WARN]  Provider "registry.terraform.io/hashicorp/kubernetes" produced an invalid plan for kubernetes_config_map.celeryconfig, but we are tolerating it because it is using the legacy plugin SDK.
    The following problems may be the cause of any confusing errors from downstream operations:
      - .metadata[0].namespace: planned value cty.StringVal("default") for a non-computed attribute
kubernetes_config_map.celeryconfig: Creating...
2022-03-21T09:49:41.707-0700 [INFO]  Starting apply for kubernetes_config_map.celeryconfig
2022-03-21T09:49:41.828-0700 [WARN]  Provider "provider[\"registry.terraform.io/hashicorp/kubernetes\"]" produced an unexpected new value for kubernetes_config_map.celeryconfig, but we are tolerating it because it is using the legacy plugin SDK.
    The following problems may be the cause of any confusing errors from downstream operations:
      - .metadata[0].generate_name: was null, but now cty.StringVal("")
kubernetes_config_map.celeryconfig: Creation complete after 0s [id=default/celeryconfig]
2022-03-21T09:49:41.872-0700 [WARN]  Provider "registry.terraform.io/hashicorp/kubernetes" produced an invalid plan for kubernetes_deployment.minio, but we are tolerating it because it is using the legacy plugin SDK.
    The following problems may be the cause of any confusing errors from downstream operations:
      - .wait_for_rollout: planned value cty.True for a non-computed attribute
      - .spec[0].progress_deadline_seconds: planned value cty.NumberIntVal(600) for a non-computed attribute
      - .spec[0].revision_history_limit: planned value cty.NumberIntVal(10) for a non-computed attribute
      - .spec[0].min_ready_seconds: planned value cty.NumberIntVal(0) for a non-computed attribute
      - .spec[0].paused: planned value cty.False for a non-computed attribute
      - .spec[0].strategy[0].rolling_update: attribute representing nested block must not be unknown itself; set nested attribute values to unknown instead
      - .spec[0].template[0].spec[0].host_network: planned value cty.False for a non-computed attribute
      - .spec[0].template[0].spec[0].termination_grace_period_seconds: planned value cty.NumberIntVal(30) for a non-computed attribute
      - .spec[0].template[0].spec[0].enable_service_links: planned value cty.True for a non-computed attribute
      - .spec[0].template[0].spec[0].host_ipc: planned value cty.False for a non-computed attribute
      - .spec[0].template[0].spec[0].host_pid: planned value cty.False for a non-computed attribute
      - .spec[0].template[0].spec[0].restart_policy: planned value cty.StringVal("Always") for a non-computed attribute
      - .spec[0].template[0].spec[0].share_process_namespace: planned value cty.False for a non-computed attribute
      - .spec[0].template[0].spec[0].dns_policy: planned value cty.StringVal("ClusterFirst") for a non-computed attribute
      - .spec[0].template[0].spec[0].automount_service_account_token: planned value cty.True for a non-computed attribute
      - .spec[0].template[0].spec[0].container[0].stdin: planned value cty.False for a non-computed attribute
      - .spec[0].template[0].spec[0].container[0].stdin_once: planned value cty.False for a non-computed attribute
      - .spec[0].template[0].spec[0].container[0].termination_message_path: planned value cty.StringVal("/dev/termination-log") for a non-computed attribute
      - .spec[0].template[0].spec[0].container[0].tty: planned value cty.False for a non-computed attribute
      - .spec[0].template[0].spec[0].container[0].port[0].protocol: planned value cty.StringVal("TCP") for a non-computed attribute
      - .spec[0].template[0].spec[0].container[0].port[1].protocol: planned value cty.StringVal("TCP") for a non-computed attribute
      - .spec[0].template[0].spec[0].container[0].resources: attribute representing nested block must not be unknown itself; set nested attribute values to unknown instead
      - .spec[0].template[0].spec[0].container[0].volume_mount[0].mount_propagation: planned value cty.StringVal("None") for a non-computed attribute
      - .spec[0].template[0].spec[0].readiness_gate: attribute representing nested block must not be unknown itself; set nested attribute values to unknown instead
      - .spec[0].template[0].spec[0].volume[0].persistent_volume_claim[0].read_only: planned value cty.False for a non-computed attribute
      - .spec[0].template[0].spec[0].image_pull_secrets: attribute representing nested block must not be unknown itself; set nested attribute values to unknown instead
      - .metadata[0].namespace: planned value cty.StringVal("default") for a non-computed attribute
kubernetes_deployment.minio: Creating...
2022-03-21T09:49:41.872-0700 [INFO]  Starting apply for kubernetes_deployment.minio
2022-03-21T09:49:42.017-0700 [WARN]  Provider "provider[\"registry.terraform.io/hashicorp/kubernetes\"]" produced an unexpected new value for kubernetes_service.mozart_service, but we are tolerating it because it is using the legacy plugin SDK.
    The following problems may be the cause of any confusing errors from downstream operations:
      - .metadata[0].generate_name: was null, but now cty.StringVal("")
      - .spec[0].external_name: was null, but now cty.StringVal("")
      - .spec[0].load_balancer_ip: was null, but now cty.StringVal("")
      - .spec[0].port[0].name: was null, but now cty.StringVal("")
kubernetes_service.mozart_service: Creation complete after 1s [id=default/mozart]
2022-03-21T09:49:42.031-0700 [WARN]  Provider "registry.terraform.io/hashicorp/kubernetes" produced an invalid plan for kubernetes_config_map.supervisord-user-rules, but we are tolerating it because it is using the legacy plugin SDK.
    The following problems may be the cause of any confusing errors from downstream operations:
      - .metadata[0].namespace: planned value cty.StringVal("default") for a non-computed attribute
kubernetes_config_map.supervisord-user-rules: Creating...
2022-03-21T09:49:42.031-0700 [INFO]  Starting apply for kubernetes_config_map.supervisord-user-rules
2022-03-21T09:49:42.125-0700 [WARN]  Provider "provider[\"registry.terraform.io/hashicorp/kubernetes\"]" produced an unexpected new value for kubernetes_config_map.supervisord-user-rules, but we are tolerating it because it is using the legacy plugin SDK.
    The following problems may be the cause of any confusing errors from downstream operations:
      - .metadata[0].generate_name: was null, but now cty.StringVal("")
kubernetes_config_map.supervisord-user-rules: Creation complete after 0s [id=default/supervisord-user-rules]
2022-03-21T09:49:42.149-0700 [WARN]  Provider "registry.terraform.io/hashicorp/kubernetes" produced an invalid plan for kubernetes_config_map.mozart-settings, but we are tolerating it because it is using the legacy plugin SDK.
    The following problems may be the cause of any confusing errors from downstream operations:
      - .metadata[0].namespace: planned value cty.StringVal("default") for a non-computed attribute
kubernetes_config_map.mozart-settings: Creating...
2022-03-21T09:49:42.150-0700 [INFO]  Starting apply for kubernetes_config_map.mozart-settings
2022-03-21T09:49:42.520-0700 [WARN]  Provider "provider[\"registry.terraform.io/hashicorp/kubernetes\"]" produced an unexpected new value for kubernetes_deployment.hysds-ui, but we are tolerating it because it is using the legacy plugin SDK.
    The following problems may be the cause of any confusing errors from downstream operations:
      - .spec[0].template[0].metadata[0].generate_name: was null, but now cty.StringVal("")
      - .spec[0].template[0].metadata[0].namespace: was null, but now cty.StringVal("")
      - .spec[0].template[0].spec[0].subdomain: was null, but now cty.StringVal("")
      - .spec[0].template[0].spec[0].priority_class_name: was null, but now cty.StringVal("")
      - .spec[0].template[0].spec[0].active_deadline_seconds: was null, but now cty.NumberIntVal(0)
      - .spec[0].template[0].spec[0].container[0].working_dir: was null, but now cty.StringVal("")
      - .spec[0].template[0].spec[0].container[0].port[0].host_ip: was null, but now cty.StringVal("")
      - .spec[0].template[0].spec[0].container[0].port[0].host_port: was null, but now cty.NumberIntVal(0)
      - .spec[0].template[0].spec[0].container[0].port[0].name: was null, but now cty.StringVal("")
      - .metadata[0].generate_name: was null, but now cty.StringVal("")
kubernetes_deployment.hysds-ui: Creation complete after 17s [id=default/hysds-ui]
2022-03-21T09:49:42.652-0700 [WARN]  Provider "provider[\"registry.terraform.io/hashicorp/kubernetes\"]" produced an unexpected new value for kubernetes_config_map.mozart-settings, but we are tolerating it because it is using the legacy plugin SDK.
    The following problems may be the cause of any confusing errors from downstream operations:
      - .metadata[0].generate_name: was null, but now cty.StringVal("")
kubernetes_config_map.mozart-settings: Creation complete after 1s [id=default/mozart-settings]
2022-03-21T09:49:43.038-0700 [INFO]  provider.terraform-provider-helm_v2.4.1_x5: 2022/03/21 09:49:43 [DEBUG] StatefulSet is not ready: default/mozart-es-master. 0 out of 1 expected pods are ready: timestamp=2022-03-21T09:49:43.038-0700
2022-03-21T09:49:43.125-0700 [INFO]  provider.terraform-provider-helm_v2.4.1_x5: 2022/03/21 09:49:43 [DEBUG] StatefulSet is not ready: default/grq-es-master. 0 out of 1 expected pods are ready: timestamp=2022-03-21T09:49:43.125-0700
2022-03-21T09:49:44.959-0700 [INFO]  provider.terraform-provider-helm_v2.4.1_x5: 2022/03/21 09:49:44 [DEBUG] StatefulSet is not ready: default/mozart-es-master. 0 out of 1 expected pods are ready: timestamp=2022-03-21T09:49:44.959-0700
kubernetes_deployment.grq2: Still creating... [20s elapsed]
2022-03-21T09:49:45.287-0700 [INFO]  provider.terraform-provider-helm_v2.4.1_x5: 2022/03/21 09:49:45 [DEBUG] StatefulSet is not ready: default/grq-es-master. 0 out of 1 expected pods are ready: timestamp=2022-03-21T09:49:45.286-0700
kubernetes_deployment.factotum-job-worker: Still creating... [20s elapsed]
kubernetes_deployment.mozart: Still creating... [20s elapsed]
helm_release.mozart-es: Still creating... [20s elapsed]
helm_release.grq2-es: Still creating... [20s elapsed]
2022-03-21T09:49:47.077-0700 [INFO]  provider.terraform-provider-helm_v2.4.1_x5: 2022/03/21 09:49:47 [DEBUG] StatefulSet is not ready: default/mozart-es-master. 0 out of 1 expected pods are ready: timestamp=2022-03-21T09:49:47.077-0700
kubernetes_deployment.user-rules: Still creating... [20s elapsed]
kubernetes_deployment.orchestrator: Still creating... [20s elapsed]
2022-03-21T09:49:47.544-0700 [INFO]  provider.terraform-provider-helm_v2.4.1_x5: 2022/03/21 09:49:47 [DEBUG] StatefulSet is not ready: default/grq-es-master. 0 out of 1 expected pods are ready: timestamp=2022-03-21T09:49:47.544-0700
2022-03-21T09:49:48.927-0700 [INFO]  provider.terraform-provider-helm_v2.4.1_x5: 2022/03/21 09:49:48 [DEBUG] StatefulSet is not ready: default/mozart-es-master. 0 out of 1 expected pods are ready: timestamp=2022-03-21T09:49:48.927-0700
2022-03-21T09:49:49.484-0700 [INFO]  provider.terraform-provider-helm_v2.4.1_x5: 2022/03/21 09:49:49 [DEBUG] StatefulSet is not ready: default/grq-es-master. 0 out of 1 expected pods are ready: timestamp=2022-03-21T09:49:49.483-0700
2022-03-21T09:49:50.909-0700 [INFO]  provider.terraform-provider-helm_v2.4.1_x5: 2022/03/21 09:49:50 [DEBUG] StatefulSet is not ready: default/mozart-es-master. 0 out of 1 expected pods are ready: timestamp=2022-03-21T09:49:50.909-0700
2022-03-21T09:49:51.215-0700 [INFO]  provider.terraform-provider-helm_v2.4.1_x5: 2022/03/21 09:49:51 [DEBUG] StatefulSet is not ready: default/grq-es-master. 0 out of 1 expected pods are ready: timestamp=2022-03-21T09:49:51.215-0700
kubernetes_deployment.minio: Still creating... [10s elapsed]
2022-03-21T09:49:53.426-0700 [INFO]  provider.terraform-provider-helm_v2.4.1_x5: 2022/03/21 09:49:53 [DEBUG] StatefulSet is not ready: default/mozart-es-master. 0 out of 1 expected pods are ready: timestamp=2022-03-21T09:49:53.426-0700
2022-03-21T09:49:53.426-0700 [INFO]  provider.terraform-provider-helm_v2.4.1_x5: 2022/03/21 09:49:53 [DEBUG] StatefulSet is not ready: default/grq-es-master. 0 out of 1 expected pods are ready: timestamp=2022-03-21T09:49:53.426-0700
2022-03-21T09:49:54.909-0700 [INFO]  provider.terraform-provider-helm_v2.4.1_x5: 2022/03/21 09:49:54 [DEBUG] StatefulSet is not ready: default/mozart-es-master. 0 out of 1 expected pods are ready: timestamp=2022-03-21T09:49:54.909-0700
kubernetes_deployment.grq2: Still creating... [30s elapsed]
kubernetes_deployment.factotum-job-worker: Still creating... [30s elapsed]
2022-03-21T09:49:55.844-0700 [INFO]  provider.terraform-provider-helm_v2.4.1_x5: 2022/03/21 09:49:55 [DEBUG] StatefulSet is not ready: default/grq-es-master. 0 out of 1 expected pods are ready: timestamp=2022-03-21T09:49:55.844-0700
kubernetes_deployment.mozart: Still creating... [30s elapsed]
helm_release.mozart-es: Still creating... [30s elapsed]
helm_release.grq2-es: Still creating... [30s elapsed]
kubernetes_deployment.user-rules: Still creating... [30s elapsed]
kubernetes_deployment.orchestrator: Still creating... [30s elapsed]
2022-03-21T09:49:58.287-0700 [INFO]  provider.terraform-provider-helm_v2.4.1_x5: 2022/03/21 09:49:58 [DEBUG] StatefulSet is not ready: default/mozart-es-master. 0 out of 1 expected pods are ready: timestamp=2022-03-21T09:49:58.285-0700
2022-03-21T09:49:58.731-0700 [INFO]  provider.terraform-provider-helm_v2.4.1_x5: 2022/03/21 09:49:58 [DEBUG] StatefulSet is not ready: default/grq-es-master. 0 out of 1 expected pods are ready: timestamp=2022-03-21T09:49:58.731-0700
2022-03-21T09:49:59.007-0700 [INFO]  provider.terraform-provider-helm_v2.4.1_x5: 2022/03/21 09:49:59 [DEBUG] StatefulSet is not ready: default/mozart-es-master. 0 out of 1 expected pods are ready: timestamp=2022-03-21T09:49:59.007-0700
2022-03-21T09:49:59.700-0700 [INFO]  provider.terraform-provider-helm_v2.4.1_x5: 2022/03/21 09:49:59 [DEBUG] StatefulSet is not ready: default/grq-es-master. 0 out of 1 expected pods are ready: timestamp=2022-03-21T09:49:59.699-0700
2022-03-21T09:50:00.896-0700 [INFO]  provider.terraform-provider-helm_v2.4.1_x5: 2022/03/21 09:50:00 [DEBUG] StatefulSet is not ready: default/mozart-es-master. 0 out of 1 expected pods are ready: timestamp=2022-03-21T09:50:00.896-0700
2022-03-21T09:50:01.189-0700 [INFO]  provider.terraform-provider-helm_v2.4.1_x5: 2022/03/21 09:50:01 [DEBUG] StatefulSet is not ready: default/grq-es-master. 0 out of 1 expected pods are ready: timestamp=2022-03-21T09:50:01.189-0700
2022-03-21T09:50:01.633-0700 [WARN]  Provider "provider[\"registry.terraform.io/hashicorp/kubernetes\"]" produced an unexpected new value for kubernetes_deployment.grq2, but we are tolerating it because it is using the legacy plugin SDK.
    The following problems may be the cause of any confusing errors from downstream operations:
      - .metadata[0].generate_name: was null, but now cty.StringVal("")
      - .spec[0].template[0].metadata[0].generate_name: was null, but now cty.StringVal("")
      - .spec[0].template[0].metadata[0].namespace: was null, but now cty.StringVal("")
      - .spec[0].template[0].spec[0].priority_class_name: was null, but now cty.StringVal("")
      - .spec[0].template[0].spec[0].active_deadline_seconds: was null, but now cty.NumberIntVal(0)
      - .spec[0].template[0].spec[0].subdomain: was null, but now cty.StringVal("")
      - .spec[0].template[0].spec[0].volume[0].config_map[0].optional: was null, but now cty.False
      - .spec[0].template[0].spec[0].volume[1].config_map[0].optional: was null, but now cty.False
      - .spec[0].template[0].spec[0].volume[2].config_map[0].optional: was null, but now cty.False
      - .spec[0].template[0].spec[0].container[0].working_dir: was null, but now cty.StringVal("")
      - .spec[0].template[0].spec[0].container[0].port[0].host_ip: was null, but now cty.StringVal("")
      - .spec[0].template[0].spec[0].container[0].port[0].host_port: was null, but now cty.NumberIntVal(0)
kubernetes_deployment.grq2: Creation complete after 37s [id=default/grq2]
kubernetes_deployment.minio: Still creating... [20s elapsed]
2022-03-21T09:50:02.871-0700 [INFO]  provider.terraform-provider-helm_v2.4.1_x5: 2022/03/21 09:50:02 [DEBUG] StatefulSet is not ready: default/mozart-es-master. 0 out of 1 expected pods are ready: timestamp=2022-03-21T09:50:02.871-0700
2022-03-21T09:50:03.015-0700 [WARN]  Provider "provider[\"registry.terraform.io/hashicorp/kubernetes\"]" produced an unexpected new value for kubernetes_deployment.mozart, but we are tolerating it because it is using the legacy plugin SDK.
    The following problems may be the cause of any confusing errors from downstream operations:
      - .metadata[0].generate_name: was null, but now cty.StringVal("")
      - .spec[0].template[0].metadata[0].namespace: was null, but now cty.StringVal("")
      - .spec[0].template[0].metadata[0].generate_name: was null, but now cty.StringVal("")
      - .spec[0].template[0].spec[0].priority_class_name: was null, but now cty.StringVal("")
      - .spec[0].template[0].spec[0].active_deadline_seconds: was null, but now cty.NumberIntVal(0)
      - .spec[0].template[0].spec[0].subdomain: was null, but now cty.StringVal("")
      - .spec[0].template[0].spec[0].container[0].working_dir: was null, but now cty.StringVal("")
      - .spec[0].template[0].spec[0].container[0].port[0].host_ip: was null, but now cty.StringVal("")
      - .spec[0].template[0].spec[0].container[0].port[0].host_port: was null, but now cty.NumberIntVal(0)
      - .spec[0].template[0].spec[0].volume[0].config_map[0].optional: was null, but now cty.False
      - .spec[0].template[0].spec[0].volume[1].config_map[0].optional: was null, but now cty.False
      - .spec[0].template[0].spec[0].volume[2].config_map[0].optional: was null, but now cty.False
kubernetes_deployment.mozart: Creation complete after 37s [id=default/mozart]
2022-03-21T09:50:03.154-0700 [INFO]  provider.terraform-provider-helm_v2.4.1_x5: 2022/03/21 09:50:03 [DEBUG] StatefulSet is not ready: default/grq-es-master. 0 out of 1 expected pods are ready: timestamp=2022-03-21T09:50:03.154-0700
2022-03-21T09:50:03.827-0700 [WARN]  Provider "provider[\"registry.terraform.io/hashicorp/kubernetes\"]" produced an unexpected new value for kubernetes_deployment.user-rules, but we are tolerating it because it is using the legacy plugin SDK.
    The following problems may be the cause of any confusing errors from downstream operations:
      - .metadata[0].generate_name: was null, but now cty.StringVal("")
      - .spec[0].template[0].metadata[0].namespace: was null, but now cty.StringVal("")
      - .spec[0].template[0].metadata[0].generate_name: was null, but now cty.StringVal("")
      - .spec[0].template[0].spec[0].subdomain: was null, but now cty.StringVal("")
      - .spec[0].template[0].spec[0].priority_class_name: was null, but now cty.StringVal("")
      - .spec[0].template[0].spec[0].active_deadline_seconds: was null, but now cty.NumberIntVal(0)
      - .spec[0].template[0].spec[0].container[0].working_dir: was null, but now cty.StringVal("")
      - .spec[0].template[0].spec[0].container[0].volume_mount[2].sub_path: was null, but now cty.StringVal("")
      - .spec[0].template[0].spec[0].security_context[0].fs_group: was null, but now cty.StringVal("")
      - .spec[0].template[0].spec[0].security_context[0].run_as_non_root: was null, but now cty.False
      - .spec[0].template[0].spec[0].volume[0].config_map[0].optional: was null, but now cty.False
      - .spec[0].template[0].spec[0].volume[1].config_map[0].optional: was null, but now cty.False
      - .spec[0].template[0].spec[0].volume[2].host_path[0].type: was null, but now cty.StringVal("")
kubernetes_deployment.user-rules: Creation complete after 37s [id=default/user-rules]
2022-03-21T09:50:03.964-0700 [WARN]  Provider "provider[\"registry.terraform.io/hashicorp/kubernetes\"]" produced an unexpected new value for kubernetes_deployment.orchestrator, but we are tolerating it because it is using the legacy plugin SDK.
    The following problems may be the cause of any confusing errors from downstream operations:
      - .metadata[0].generate_name: was null, but now cty.StringVal("")
      - .spec[0].template[0].metadata[0].generate_name: was null, but now cty.StringVal("")
      - .spec[0].template[0].metadata[0].namespace: was null, but now cty.StringVal("")
      - .spec[0].template[0].spec[0].priority_class_name: was null, but now cty.StringVal("")
      - .spec[0].template[0].spec[0].active_deadline_seconds: was null, but now cty.NumberIntVal(0)
      - .spec[0].template[0].spec[0].subdomain: was null, but now cty.StringVal("")
      - .spec[0].template[0].spec[0].container[0].working_dir: was null, but now cty.StringVal("")
      - .spec[0].template[0].spec[0].container[0].volume_mount[2].sub_path: was null, but now cty.StringVal("")
      - .spec[0].template[0].spec[0].security_context[0].run_as_non_root: was null, but now cty.False
      - .spec[0].template[0].spec[0].security_context[0].fs_group: was null, but now cty.StringVal("")
      - .spec[0].template[0].spec[0].volume[0].config_map[0].optional: was null, but now cty.False
      - .spec[0].template[0].spec[0].volume[1].config_map[0].optional: was null, but now cty.False
      - .spec[0].template[0].spec[0].volume[2].host_path[0].type: was null, but now cty.StringVal("")
kubernetes_deployment.orchestrator: Creation complete after 37s [id=default/orchestrator]
2022-03-21T09:50:04.850-0700 [INFO]  provider.terraform-provider-helm_v2.4.1_x5: 2022/03/21 09:50:04 [DEBUG] StatefulSet is not ready: default/mozart-es-master. 0 out of 1 expected pods are ready: timestamp=2022-03-21T09:50:04.850-0700
2022-03-21T09:50:05.336-0700 [INFO]  provider.terraform-provider-helm_v2.4.1_x5: 2022/03/21 09:50:05 [DEBUG] StatefulSet is not ready: default/grq-es-master. 0 out of 1 expected pods are ready: timestamp=2022-03-21T09:50:05.336-0700
kubernetes_deployment.factotum-job-worker: Still creating... [40s elapsed]
helm_release.mozart-es: Still creating... [40s elapsed]
2022-03-21T09:50:06.653-0700 [INFO]  provider.terraform-provider-helm_v2.4.1_x5: 2022/03/21 09:50:06 [DEBUG] StatefulSet is not ready: default/mozart-es-master. 0 out of 1 expected pods are ready: timestamp=2022-03-21T09:50:06.653-0700
helm_release.grq2-es: Still creating... [40s elapsed]
2022-03-21T09:50:07.104-0700 [INFO]  provider.terraform-provider-helm_v2.4.1_x5: 2022/03/21 09:50:07 [DEBUG] StatefulSet is not ready: default/grq-es-master. 0 out of 1 expected pods are ready: timestamp=2022-03-21T09:50:07.103-0700
2022-03-21T09:50:08.451-0700 [WARN]  Provider "provider[\"registry.terraform.io/hashicorp/kubernetes\"]" produced an unexpected new value for kubernetes_deployment.minio, but we are tolerating it because it is using the legacy plugin SDK.
    The following problems may be the cause of any confusing errors from downstream operations:
      - .metadata[0].generate_name: was null, but now cty.StringVal("")
      - .spec[0].template[0].spec[0].active_deadline_seconds: was null, but now cty.NumberIntVal(0)
      - .spec[0].template[0].spec[0].subdomain: was null, but now cty.StringVal("")
      - .spec[0].template[0].spec[0].priority_class_name: was null, but now cty.StringVal("")
      - .spec[0].template[0].spec[0].container[0].working_dir: was null, but now cty.StringVal("")
      - .spec[0].template[0].spec[0].container[0].volume_mount[0].sub_path: was null, but now cty.StringVal("")
      - .spec[0].template[0].spec[0].container[0].port[0].name: was null, but now cty.StringVal("")
      - .spec[0].template[0].spec[0].container[0].port[0].host_ip: was null, but now cty.StringVal("")
      - .spec[0].template[0].spec[0].container[0].port[1].host_ip: was null, but now cty.StringVal("")
      - .spec[0].template[0].spec[0].container[0].port[1].name: was null, but now cty.StringVal("")
      - .spec[0].template[0].metadata[0].generate_name: was null, but now cty.StringVal("")
      - .spec[0].template[0].metadata[0].namespace: was null, but now cty.StringVal("")
kubernetes_deployment.minio: Creation complete after 26s [id=default/minio]
2022-03-21T09:50:08.667-0700 [INFO]  provider.terraform-provider-helm_v2.4.1_x5: 2022/03/21 09:50:08 [DEBUG] StatefulSet is not ready: default/mozart-es-master. 0 out of 1 expected pods are ready: timestamp=2022-03-21T09:50:08.667-0700
2022-03-21T09:50:09.162-0700 [INFO]  provider.terraform-provider-helm_v2.4.1_x5: 2022/03/21 09:50:09 [DEBUG] StatefulSet is not ready: default/grq-es-master. 0 out of 1 expected pods are ready: timestamp=2022-03-21T09:50:09.161-0700
2022-03-21T09:50:10.675-0700 [INFO]  provider.terraform-provider-helm_v2.4.1_x5: 2022/03/21 09:50:10 [DEBUG] StatefulSet is not ready: default/mozart-es-master. 0 out of 1 expected pods are ready: timestamp=2022-03-21T09:50:10.675-0700
2022-03-21T09:50:11.197-0700 [INFO]  provider.terraform-provider-helm_v2.4.1_x5: 2022/03/21 09:50:11 [DEBUG] StatefulSet is not ready: default/grq-es-master. 0 out of 1 expected pods are ready: timestamp=2022-03-21T09:50:11.197-0700
2022-03-21T09:50:12.102-0700 [WARN]  Provider "provider[\"registry.terraform.io/hashicorp/kubernetes\"]" produced an unexpected new value for kubernetes_deployment.factotum-job-worker, but we are tolerating it because it is using the legacy plugin SDK.
    The following problems may be the cause of any confusing errors from downstream operations:
      - .metadata[0].generate_name: was null, but now cty.StringVal("")
      - .spec[0].template[0].metadata[0].generate_name: was null, but now cty.StringVal("")
      - .spec[0].template[0].metadata[0].namespace: was null, but now cty.StringVal("")
      - .spec[0].template[0].spec[0].subdomain: was null, but now cty.StringVal("")
      - .spec[0].template[0].spec[0].priority_class_name: was null, but now cty.StringVal("")
      - .spec[0].template[0].spec[0].active_deadline_seconds: was null, but now cty.NumberIntVal(0)
      - .spec[0].template[0].spec[0].init_container[0].working_dir: was null, but now cty.StringVal("")
      - .spec[0].template[0].spec[0].init_container[0].volume_mount[0].sub_path: was null, but now cty.StringVal("")
      - .spec[0].template[0].spec[0].init_container[0].volume_mount[1].sub_path: was null, but now cty.StringVal("")
      - .spec[0].template[0].spec[0].volume[0].host_path[0].type: was null, but now cty.StringVal("")
      - .spec[0].template[0].spec[0].volume[1].config_map[0].optional: was null, but now cty.False
      - .spec[0].template[0].spec[0].volume[2].config_map[0].optional: was null, but now cty.False
      - .spec[0].template[0].spec[0].volume[3].config_map[0].optional: was null, but now cty.False
      - .spec[0].template[0].spec[0].volume[4].config_map[0].optional: was null, but now cty.False
      - .spec[0].template[0].spec[0].volume[5].host_path[0].type: was null, but now cty.StringVal("")
      - .spec[0].template[0].spec[0].container[0].working_dir: was null, but now cty.StringVal("")
      - .spec[0].template[0].spec[0].container[0].volume_mount[0].sub_path: was null, but now cty.StringVal("")
      - .spec[0].template[0].spec[0].container[0].volume_mount[5].sub_path: was null, but now cty.StringVal("")
kubernetes_deployment.factotum-job-worker: Creation complete after 47s [id=default/factotum-job-worker]
2022-03-21T09:50:12.769-0700 [INFO]  provider.terraform-provider-helm_v2.4.1_x5: 2022/03/21 09:50:12 [DEBUG] StatefulSet is not ready: default/mozart-es-master. 0 out of 1 expected pods are ready: timestamp=2022-03-21T09:50:12.769-0700
2022-03-21T09:50:13.163-0700 [INFO]  provider.terraform-provider-helm_v2.4.1_x5: 2022/03/21 09:50:13 [DEBUG] StatefulSet is not ready: default/grq-es-master. 0 out of 1 expected pods are ready: timestamp=2022-03-21T09:50:13.162-0700
2022-03-21T09:50:14.664-0700 [INFO]  provider.terraform-provider-helm_v2.4.1_x5: 2022/03/21 09:50:14 [DEBUG] StatefulSet is not ready: default/mozart-es-master. 0 out of 1 expected pods are ready: timestamp=2022-03-21T09:50:14.663-0700
2022-03-21T09:50:15.116-0700 [INFO]  provider.terraform-provider-helm_v2.4.1_x5: 2022/03/21 09:50:15 [DEBUG] StatefulSet is not ready: default/grq-es-master. 0 out of 1 expected pods are ready: timestamp=2022-03-21T09:50:15.116-0700
helm_release.mozart-es: Still creating... [50s elapsed]
2022-03-21T09:50:16.660-0700 [INFO]  provider.terraform-provider-helm_v2.4.1_x5: 2022/03/21 09:50:16 [DEBUG] StatefulSet is not ready: default/mozart-es-master. 0 out of 1 expected pods are ready: timestamp=2022-03-21T09:50:16.660-0700
helm_release.grq2-es: Still creating... [50s elapsed]
2022-03-21T09:50:17.123-0700 [INFO]  provider.terraform-provider-helm_v2.4.1_x5: 2022/03/21 09:50:17 [DEBUG] StatefulSet is not ready: default/grq-es-master. 0 out of 1 expected pods are ready: timestamp=2022-03-21T09:50:17.122-0700
2022-03-21T09:50:18.733-0700 [INFO]  provider.terraform-provider-helm_v2.4.1_x5: 2022/03/21 09:50:18 [DEBUG] StatefulSet is not ready: default/mozart-es-master. 0 out of 1 expected pods are ready: timestamp=2022-03-21T09:50:18.733-0700
2022-03-21T09:50:19.163-0700 [INFO]  provider.terraform-provider-helm_v2.4.1_x5: 2022/03/21 09:50:19 [DEBUG] StatefulSet is not ready: default/grq-es-master. 0 out of 1 expected pods are ready: timestamp=2022-03-21T09:50:19.163-0700
2022-03-21T09:50:20.775-0700 [INFO]  provider.terraform-provider-helm_v2.4.1_x5: 2022/03/21 09:50:20 [DEBUG] StatefulSet is not ready: default/mozart-es-master. 0 out of 1 expected pods are ready: timestamp=2022-03-21T09:50:20.775-0700
2022-03-21T09:50:21.844-0700 [INFO]  provider.terraform-provider-helm_v2.4.1_x5: 2022/03/21 09:50:21 [DEBUG] StatefulSet is not ready: default/grq-es-master. 0 out of 1 expected pods are ready: timestamp=2022-03-21T09:50:21.844-0700
2022-03-21T09:50:23.622-0700 [INFO]  provider.terraform-provider-helm_v2.4.1_x5: 2022/03/21 09:50:23 [DEBUG] StatefulSet is not ready: default/mozart-es-master. 0 out of 1 expected pods are ready: timestamp=2022-03-21T09:50:23.622-0700
2022-03-21T09:50:24.334-0700 [INFO]  provider.terraform-provider-helm_v2.4.1_x5: 2022/03/21 09:50:24 [DEBUG] StatefulSet is not ready: default/grq-es-master. 0 out of 1 expected pods are ready: timestamp=2022-03-21T09:50:24.334-0700
2022-03-21T09:50:24.863-0700 [INFO]  provider.terraform-provider-helm_v2.4.1_x5: 2022/03/21 09:50:24 [DEBUG] StatefulSet is not ready: default/mozart-es-master. 0 out of 1 expected pods are ready: timestamp=2022-03-21T09:50:24.862-0700
2022-03-21T09:50:25.243-0700 [INFO]  provider.terraform-provider-helm_v2.4.1_x5: 2022/03/21 09:50:25 [DEBUG] StatefulSet is not ready: default/grq-es-master. 0 out of 1 expected pods are ready: timestamp=2022-03-21T09:50:25.243-0700
helm_release.mozart-es: Still creating... [1m0s elapsed]
2022-03-21T09:50:26.653-0700 [INFO]  provider.terraform-provider-helm_v2.4.1_x5: 2022/03/21 09:50:26 [DEBUG] StatefulSet is not ready: default/mozart-es-master. 0 out of 1 expected pods are ready: timestamp=2022-03-21T09:50:26.653-0700
helm_release.grq2-es: Still creating... [1m0s elapsed]
2022-03-21T09:50:27.171-0700 [INFO]  provider.terraform-provider-helm_v2.4.1_x5: 2022/03/21 09:50:27 [DEBUG] StatefulSet is not ready: default/grq-es-master. 0 out of 1 expected pods are ready: timestamp=2022-03-21T09:50:27.171-0700
2022-03-21T09:50:28.756-0700 [INFO]  provider.terraform-provider-helm_v2.4.1_x5: 2022/03/21 09:50:28 [DEBUG] StatefulSet is not ready: default/mozart-es-master. 0 out of 1 expected pods are ready: timestamp=2022-03-21T09:50:28.756-0700
2022-03-21T09:50:29.138-0700 [INFO]  provider.terraform-provider-helm_v2.4.1_x5: 2022/03/21 09:50:29 [DEBUG] StatefulSet is not ready: default/grq-es-master. 0 out of 1 expected pods are ready: timestamp=2022-03-21T09:50:29.138-0700
2022-03-21T09:50:30.672-0700 [INFO]  provider.terraform-provider-helm_v2.4.1_x5: 2022/03/21 09:50:30 [DEBUG] StatefulSet is not ready: default/mozart-es-master. 0 out of 1 expected pods are ready: timestamp=2022-03-21T09:50:30.672-0700
2022-03-21T09:50:31.114-0700 [INFO]  provider.terraform-provider-helm_v2.4.1_x5: 2022/03/21 09:50:31 [DEBUG] StatefulSet is not ready: default/grq-es-master. 0 out of 1 expected pods are ready: timestamp=2022-03-21T09:50:31.114-0700
2022-03-21T09:50:32.661-0700 [INFO]  provider.terraform-provider-helm_v2.4.1_x5: 2022/03/21 09:50:32 [DEBUG] StatefulSet is not ready: default/mozart-es-master. 0 out of 1 expected pods are ready: timestamp=2022-03-21T09:50:32.660-0700
2022-03-21T09:50:33.135-0700 [INFO]  provider.terraform-provider-helm_v2.4.1_x5: 2022/03/21 09:50:33 [DEBUG] StatefulSet is not ready: default/grq-es-master. 0 out of 1 expected pods are ready: timestamp=2022-03-21T09:50:33.135-0700
2022-03-21T09:50:34.651-0700 [INFO]  provider.terraform-provider-helm_v2.4.1_x5: 2022/03/21 09:50:34 [DEBUG] StatefulSet is not ready: default/mozart-es-master. 0 out of 1 expected pods are ready: timestamp=2022-03-21T09:50:34.651-0700
2022-03-21T09:50:35.114-0700 [INFO]  provider.terraform-provider-helm_v2.4.1_x5: 2022/03/21 09:50:35 [DEBUG] StatefulSet is not ready: default/grq-es-master. 0 out of 1 expected pods are ready: timestamp=2022-03-21T09:50:35.114-0700
helm_release.mozart-es: Still creating... [1m10s elapsed]
2022-03-21T09:50:36.854-0700 [INFO]  provider.terraform-provider-helm_v2.4.1_x5: 2022/03/21 09:50:36 [DEBUG] StatefulSet is not ready: default/mozart-es-master. 0 out of 1 expected pods are ready: timestamp=2022-03-21T09:50:36.854-0700
helm_release.grq2-es: Still creating... [1m10s elapsed]
2022-03-21T09:50:37.271-0700 [INFO]  provider.terraform-provider-helm_v2.4.1_x5: 2022/03/21 09:50:37 [DEBUG] StatefulSet is not ready: default/grq-es-master. 0 out of 1 expected pods are ready: timestamp=2022-03-21T09:50:37.271-0700
2022-03-21T09:50:38.997-0700 [INFO]  provider.terraform-provider-helm_v2.4.1_x5: 2022/03/21 09:50:38 [DEBUG] StatefulSet is not ready: default/mozart-es-master. 0 out of 1 expected pods are ready: timestamp=2022-03-21T09:50:38.997-0700
2022-03-21T09:50:39.273-0700 [INFO]  provider.terraform-provider-helm_v2.4.1_x5: 2022/03/21 09:50:39 [DEBUG] StatefulSet is not ready: default/grq-es-master. 0 out of 1 expected pods are ready: timestamp=2022-03-21T09:50:39.273-0700
2022-03-21T09:50:41.370-0700 [INFO]  provider.terraform-provider-helm_v2.4.1_x5: 2022/03/21 09:50:41 [DEBUG] StatefulSet is not ready: default/grq-es-master. 0 out of 1 expected pods are ready: timestamp=2022-03-21T09:50:41.370-0700
2022-03-21T09:50:41.423-0700 [INFO]  provider.terraform-provider-helm_v2.4.1_x5: 2022/03/21 09:50:41 [DEBUG] StatefulSet is not ready: default/mozart-es-master. 0 out of 1 expected pods are ready: timestamp=2022-03-21T09:50:41.423-0700
2022-03-21T09:50:43.254-0700 [INFO]  provider.terraform-provider-helm_v2.4.1_x5: 2022/03/21 09:50:43 [DEBUG] StatefulSet is not ready: default/mozart-es-master. 0 out of 1 expected pods are ready: timestamp=2022-03-21T09:50:43.254-0700
2022-03-21T09:50:43.529-0700 [INFO]  provider.terraform-provider-helm_v2.4.1_x5: 2022/03/21 09:50:43 [DEBUG] StatefulSet is not ready: default/grq-es-master. 0 out of 1 expected pods are ready: timestamp=2022-03-21T09:50:43.529-0700
2022-03-21T09:50:44.932-0700 [INFO]  provider.terraform-provider-helm_v2.4.1_x5: 2022/03/21 09:50:44 [DEBUG] StatefulSet is not ready: default/mozart-es-master. 0 out of 1 expected pods are ready: timestamp=2022-03-21T09:50:44.932-0700
2022-03-21T09:50:45.611-0700 [INFO]  provider.terraform-provider-helm_v2.4.1_x5: 2022/03/21 09:50:45 [DEBUG] StatefulSet is not ready: default/grq-es-master. 0 out of 1 expected pods are ready: timestamp=2022-03-21T09:50:45.611-0700
helm_release.mozart-es: Still creating... [1m20s elapsed]
2022-03-21T09:50:46.753-0700 [INFO]  provider.terraform-provider-helm_v2.4.1_x5: 2022/03/21 09:50:46 [DEBUG] StatefulSet is not ready: default/mozart-es-master. 0 out of 1 expected pods are ready: timestamp=2022-03-21T09:50:46.753-0700
helm_release.grq2-es: Still creating... [1m20s elapsed]
2022-03-21T09:50:47.188-0700 [INFO]  provider.terraform-provider-helm_v2.4.1_x5: 2022/03/21 09:50:47 [DEBUG] StatefulSet is not ready: default/grq-es-master. 0 out of 1 expected pods are ready: timestamp=2022-03-21T09:50:47.182-0700
2022-03-21T09:50:48.989-0700 [INFO]  provider.terraform-provider-helm_v2.4.1_x5: 2022/03/21 09:50:48 [DEBUG] StatefulSet is not ready: default/mozart-es-master. 0 out of 1 expected pods are ready: timestamp=2022-03-21T09:50:48.989-0700
2022-03-21T09:50:49.171-0700 [INFO]  provider.terraform-provider-helm_v2.4.1_x5: 2022/03/21 09:50:49 [DEBUG] StatefulSet is not ready: default/grq-es-master. 0 out of 1 expected pods are ready: timestamp=2022-03-21T09:50:49.171-0700
2022-03-21T09:50:50.705-0700 [INFO]  provider.terraform-provider-helm_v2.4.1_x5: 2022/03/21 09:50:50 [DEBUG] StatefulSet is not ready: default/mozart-es-master. 0 out of 1 expected pods are ready: timestamp=2022-03-21T09:50:50.705-0700
2022-03-21T09:50:51.129-0700 [INFO]  provider.terraform-provider-helm_v2.4.1_x5: 2022/03/21 09:50:51 [DEBUG] StatefulSet is not ready: default/grq-es-master. 0 out of 1 expected pods are ready: timestamp=2022-03-21T09:50:51.129-0700
2022-03-21T09:50:53.083-0700 [INFO]  provider.terraform-provider-helm_v2.4.1_x5: 2022/03/21 09:50:53 [DEBUG] StatefulSet is not ready: default/mozart-es-master. 0 out of 1 expected pods are ready: timestamp=2022-03-21T09:50:53.083-0700
2022-03-21T09:50:53.151-0700 [INFO]  provider.terraform-provider-helm_v2.4.1_x5: 2022/03/21 09:50:53 [DEBUG] StatefulSet is not ready: default/grq-es-master. 0 out of 1 expected pods are ready: timestamp=2022-03-21T09:50:53.151-0700
2022-03-21T09:50:54.657-0700 [INFO]  provider.terraform-provider-helm_v2.4.1_x5: 2022/03/21 09:50:54 [DEBUG] StatefulSet is not ready: default/mozart-es-master. 0 out of 1 expected pods are ready: timestamp=2022-03-21T09:50:54.657-0700
2022-03-21T09:50:55.126-0700 [INFO]  provider.terraform-provider-helm_v2.4.1_x5: 2022/03/21 09:50:55 [DEBUG] StatefulSet is not ready: default/grq-es-master. 0 out of 1 expected pods are ready: timestamp=2022-03-21T09:50:55.126-0700
helm_release.mozart-es: Still creating... [1m30s elapsed]
2022-03-21T09:50:56.645-0700 [INFO]  provider.terraform-provider-helm_v2.4.1_x5: 2022/03/21 09:50:56 [DEBUG] StatefulSet is not ready: default/mozart-es-master. 0 out of 1 expected pods are ready: timestamp=2022-03-21T09:50:56.645-0700
helm_release.grq2-es: Still creating... [1m30s elapsed]
2022-03-21T09:50:57.130-0700 [INFO]  provider.terraform-provider-helm_v2.4.1_x5: 2022/03/21 09:50:57 [DEBUG] StatefulSet is not ready: default/grq-es-master. 0 out of 1 expected pods are ready: timestamp=2022-03-21T09:50:57.130-0700
2022-03-21T09:50:58.656-0700 [INFO]  provider.terraform-provider-helm_v2.4.1_x5: 2022/03/21 09:50:58 [DEBUG] StatefulSet is not ready: default/mozart-es-master. 0 out of 1 expected pods are ready: timestamp=2022-03-21T09:50:58.655-0700
2022-03-21T09:50:59.231-0700 [INFO]  provider.terraform-provider-helm_v2.4.1_x5: 2022/03/21 09:50:59 [DEBUG] StatefulSet is not ready: default/grq-es-master. 0 out of 1 expected pods are ready: timestamp=2022-03-21T09:50:59.231-0700
2022-03-21T09:51:00.648-0700 [INFO]  provider.terraform-provider-helm_v2.4.1_x5: 2022/03/21 09:51:00 [DEBUG] StatefulSet is not ready: default/mozart-es-master. 0 out of 1 expected pods are ready: timestamp=2022-03-21T09:51:00.648-0700
2022-03-21T09:51:01.106-0700 [INFO]  provider.terraform-provider-helm_v2.4.1_x5: 2022/03/21 09:51:01 [DEBUG] StatefulSet is not ready: default/grq-es-master. 0 out of 1 expected pods are ready: timestamp=2022-03-21T09:51:01.106-0700
2022-03-21T09:51:02.653-0700 [INFO]  provider.terraform-provider-helm_v2.4.1_x5: 2022/03/21 09:51:02 [DEBUG] StatefulSet is not ready: default/mozart-es-master. 0 out of 1 expected pods are ready: timestamp=2022-03-21T09:51:02.653-0700
2022-03-21T09:51:03.108-0700 [INFO]  provider.terraform-provider-helm_v2.4.1_x5: 2022/03/21 09:51:03 [DEBUG] StatefulSet is not ready: default/grq-es-master. 0 out of 1 expected pods are ready: timestamp=2022-03-21T09:51:03.108-0700
2022-03-21T09:51:04.643-0700 [INFO]  provider.terraform-provider-helm_v2.4.1_x5: 2022/03/21 09:51:04 [DEBUG] StatefulSet is not ready: default/mozart-es-master. 0 out of 1 expected pods are ready: timestamp=2022-03-21T09:51:04.642-0700
2022-03-21T09:51:05.104-0700 [INFO]  provider.terraform-provider-helm_v2.4.1_x5: 2022/03/21 09:51:05 [DEBUG] StatefulSet is not ready: default/grq-es-master. 0 out of 1 expected pods are ready: timestamp=2022-03-21T09:51:05.104-0700
helm_release.mozart-es: Still creating... [1m40s elapsed]
2022-03-21T09:51:06.643-0700 [INFO]  provider.terraform-provider-helm_v2.4.1_x5: 2022/03/21 09:51:06 [DEBUG] StatefulSet is not ready: default/mozart-es-master. 0 out of 1 expected pods are ready: timestamp=2022-03-21T09:51:06.643-0700
helm_release.grq2-es: Still creating... [1m40s elapsed]
2022-03-21T09:51:07.110-0700 [INFO]  provider.terraform-provider-helm_v2.4.1_x5: 2022/03/21 09:51:07 [DEBUG] StatefulSet is not ready: default/grq-es-master. 0 out of 1 expected pods are ready: timestamp=2022-03-21T09:51:07.110-0700
2022-03-21T09:51:08.642-0700 [INFO]  provider.terraform-provider-helm_v2.4.1_x5: 2022/03/21 09:51:08 [DEBUG] StatefulSet is not ready: default/mozart-es-master. 0 out of 1 expected pods are ready: timestamp=2022-03-21T09:51:08.642-0700
2022-03-21T09:51:09.111-0700 [INFO]  provider.terraform-provider-helm_v2.4.1_x5: 2022/03/21 09:51:09 [DEBUG] StatefulSet is not ready: default/grq-es-master. 0 out of 1 expected pods are ready: timestamp=2022-03-21T09:51:09.110-0700
2022-03-21T09:51:10.674-0700 [INFO]  provider.terraform-provider-helm_v2.4.1_x5: 2022/03/21 09:51:10 [DEBUG] StatefulSet is not ready: default/mozart-es-master. 0 out of 1 expected pods are ready: timestamp=2022-03-21T09:51:10.674-0700
2022-03-21T09:51:11.117-0700 [INFO]  provider.terraform-provider-helm_v2.4.1_x5: 2022/03/21 09:51:11 [DEBUG] StatefulSet is not ready: default/grq-es-master. 0 out of 1 expected pods are ready: timestamp=2022-03-21T09:51:11.117-0700
2022-03-21T09:51:12.711-0700 [INFO]  provider.terraform-provider-helm_v2.4.1_x5: 2022/03/21 09:51:12 [DEBUG] StatefulSet is not ready: default/mozart-es-master. 0 out of 1 expected pods are ready: timestamp=2022-03-21T09:51:12.706-0700
2022-03-21T09:51:13.101-0700 [INFO]  provider.terraform-provider-helm_v2.4.1_x5: 2022/03/21 09:51:13 [DEBUG] StatefulSet is not ready: default/grq-es-master. 0 out of 1 expected pods are ready: timestamp=2022-03-21T09:51:13.101-0700
2022-03-21T09:51:14.663-0700 [INFO]  provider.terraform-provider-helm_v2.4.1_x5: 2022/03/21 09:51:14 [DEBUG] StatefulSet is not ready: default/mozart-es-master. 0 out of 1 expected pods are ready: timestamp=2022-03-21T09:51:14.663-0700
2022-03-21T09:51:15.101-0700 [INFO]  provider.terraform-provider-helm_v2.4.1_x5: 2022/03/21 09:51:15 [DEBUG] StatefulSet is not ready: default/grq-es-master. 0 out of 1 expected pods are ready: timestamp=2022-03-21T09:51:15.101-0700
helm_release.mozart-es: Still creating... [1m50s elapsed]
2022-03-21T09:51:16.659-0700 [INFO]  provider.terraform-provider-helm_v2.4.1_x5: 2022/03/21 09:51:16 [DEBUG] StatefulSet is not ready: default/mozart-es-master. 0 out of 1 expected pods are ready: timestamp=2022-03-21T09:51:16.659-0700
helm_release.grq2-es: Still creating... [1m50s elapsed]
2022-03-21T09:51:17.104-0700 [INFO]  provider.terraform-provider-helm_v2.4.1_x5: 2022/03/21 09:51:17 [DEBUG] StatefulSet is not ready: default/grq-es-master. 0 out of 1 expected pods are ready: timestamp=2022-03-21T09:51:17.104-0700
2022-03-21T09:51:18.644-0700 [INFO]  provider.terraform-provider-helm_v2.4.1_x5: 2022/03/21 09:51:18 [DEBUG] StatefulSet is not ready: default/mozart-es-master. 0 out of 1 expected pods are ready: timestamp=2022-03-21T09:51:18.644-0700
2022-03-21T09:51:19.107-0700 [INFO]  provider.terraform-provider-helm_v2.4.1_x5: 2022/03/21 09:51:19 [DEBUG] StatefulSet is not ready: default/grq-es-master. 0 out of 1 expected pods are ready: timestamp=2022-03-21T09:51:19.107-0700
helm_release.mozart-es: Creation complete after 1m55s [id=mozart-es]
2022-03-21T09:51:21.097-0700 [INFO]  provider.terraform-provider-helm_v2.4.1_x5: 2022/03/21 09:51:21 [DEBUG] StatefulSet is not ready: default/grq-es-master. 0 out of 1 expected pods are ready: timestamp=2022-03-21T09:51:21.097-0700
2022-03-21T09:51:23.102-0700 [INFO]  provider.terraform-provider-helm_v2.4.1_x5: 2022/03/21 09:51:23 [DEBUG] StatefulSet is not ready: default/grq-es-master. 0 out of 1 expected pods are ready: timestamp=2022-03-21T09:51:23.102-0700
2022-03-21T09:51:25.101-0700 [INFO]  provider.terraform-provider-helm_v2.4.1_x5: 2022/03/21 09:51:25 [DEBUG] StatefulSet is not ready: default/grq-es-master. 0 out of 1 expected pods are ready: timestamp=2022-03-21T09:51:25.101-0700
helm_release.grq2-es: Still creating... [2m0s elapsed]
2022-03-21T09:51:27.107-0700 [INFO]  provider.terraform-provider-helm_v2.4.1_x5: 2022/03/21 09:51:27 [DEBUG] StatefulSet is not ready: default/grq-es-master. 0 out of 1 expected pods are ready: timestamp=2022-03-21T09:51:27.107-0700
2022-03-21T09:51:29.101-0700 [INFO]  provider.terraform-provider-helm_v2.4.1_x5: 2022/03/21 09:51:29 [DEBUG] StatefulSet is not ready: default/grq-es-master. 0 out of 1 expected pods are ready: timestamp=2022-03-21T09:51:29.101-0700
helm_release.grq2-es: Creation complete after 2m4s [id=grq2-es]

Apply complete! Resources: 30 added, 0 changed, 0 destroyed.
